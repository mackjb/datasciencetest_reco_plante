# üìã R√©f√©rence Rapide - Dev Container GPU

## üöÄ D√©marrage rapide

### Ouvrir dans VS Code
```
F1 ‚Üí "Dev Containers: Reopen in Container"
```

### V√©rifier le GPU
```bash
# Voir le GPU
nvidia-smi

# Test complet
python .devcontainer/test_gpu.py

# Test TensorFlow
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Test PyTorch
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

## üì¶ Environnement Conda

### Activer l'environnement
```bash
conda activate gpu-env
```

### Ajouter un package
```bash
# Modifier environment.yml, puis:
conda env update -f .devcontainer/environment.yml
```

### Lister les packages
```bash
conda list
pip list
```

## üéì Jupyter Lab

### D√©marrer
```bash
jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
```

### Acc√©der
```
http://localhost:8888
```

### Arr√™ter
```bash
# Ctrl+C dans le terminal
```

## üìä TensorBoard

### D√©marrer
```bash
tensorboard --logdir=./logs --host=0.0.0.0 --port=6006
```

### Acc√©der
```
http://localhost:6006
```

## üîç Monitoring GPU

### Temps r√©el
```bash
watch -n 2 nvidia-smi
```

### Avec PyTorch
```python
import torch
print(f"Allou√©e: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB")
print(f"Totale: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB")
```

### Avec TensorFlow
```python
import tensorflow as tf
gpus = tf.config.list_physical_devices('GPU')
tf.config.experimental.get_memory_info('GPU:0')
```

## üß™ Tests rapides

### TensorFlow sur GPU
```python
import tensorflow as tf

with tf.device('/GPU:0'):
    a = tf.random.normal([1000, 1000])
    b = tf.random.normal([1000, 1000])
    c = tf.matmul(a, b)
    print(f"‚úÖ Calcul r√©ussi: {c.shape}")
```

### PyTorch sur GPU
```python
import torch

device = torch.device('cuda')
a = torch.randn(1000, 1000, device=device)
b = torch.randn(1000, 1000, device=device)
c = torch.matmul(a, b)
print(f"‚úÖ Calcul r√©ussi: {c.shape}, Device: {c.device}")
```

## üêõ D√©pannage express

### GPU non d√©tect√©
```bash
# 1. V√©rifier driver sur h√¥te
nvidia-smi  # Sur Windows

# 2. V√©rifier Docker GPU
docker run --rm --gpus all nvidia/cuda:12.8.0-base-ubuntu24.04 nvidia-smi

# 3. Rebuild container
# F1 ‚Üí "Dev Containers: Rebuild Container"
```

### Erreur m√©moire GPU
```python
# TensorFlow: activer croissance m√©moire (d√©j√† fait)
import os
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

# PyTorch: vider cache
import torch
torch.cuda.empty_cache()
```

### Package manquant
```bash
# NE PAS FAIRE: pip install package (viole PEP 668)
# FAIRE: Ajouter dans environment.yml + rebuild
```

## üìÅ Fichiers importants

| Fichier | Description |
|---------|-------------|
| `Dockerfile` | Image Docker CUDA 12.8 + Conda |
| `devcontainer.json` | Configuration VS Code + GPU |
| `environment.yml` | Packages Python/Conda |
| `test_gpu.py` | Script de test complet |
| `example_gpu_test.ipynb` | Notebook de d√©monstration |
| `README.md` | Documentation compl√®te |

## üîó Commandes Docker manuelles

### Build
```bash
cd c:/repository/datascience_rpojet_DS_2
docker build -t gpu-dev-env .devcontainer/
```

### Run
```bash
docker run -it --gpus all --shm-size=4g \
  -v ${PWD}:/workspace \
  -v ~/.nv:/root/.nv \
  -p 8888:8888 -p 6006:6006 \
  gpu-dev-env
```

### Clean
```bash
# Supprimer containers arr√™t√©s
docker container prune

# Supprimer images non utilis√©es
docker image prune

# Tout nettoyer (ATTENTION!)
docker system prune -a
```

## ‚ö° Variables d'environnement cl√©s

| Variable | Valeur | Description |
|----------|--------|-------------|
| `NVIDIA_VISIBLE_DEVICES` | `all` | Tous les GPUs visibles |
| `NVIDIA_DRIVER_CAPABILITIES` | `compute,utility` | Capacit√©s GPU |
| `TF_FORCE_GPU_ALLOW_GROWTH` | `true` | M√©moire dynamique TF |
| `CUDA_CACHE_PATH` | `/root/.nv/ComputeCache` | Cache PTX |

## üìö Ressources

- **Documentation compl√®te**: `.devcontainer/README.md`
- **Test GPU**: `python .devcontainer/test_gpu.py`
- **Notebook exemple**: `.devcontainer/example_gpu_test.ipynb`
- **CUDA Docs**: https://docs.nvidia.com/cuda/
- **TensorFlow GPU**: https://www.tensorflow.org/install/gpu
- **PyTorch CUDA**: https://pytorch.org/docs/stable/notes/cuda.html

---

**Version**: CUDA 12.8.0 | TensorFlow ‚â•2.20 | PyTorch ‚â•2.5 | Python 3.12
