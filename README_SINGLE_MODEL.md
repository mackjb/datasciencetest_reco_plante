# Approche Single-Model - Classification Directe

## üéØ Concept

**UN SEUL mod√®le** EfficientNetV2B1 qui pr√©dit directement les **38 classes finales** (esp√®ce___maladie).

### Diff√©rences avec l'approche Cascade

| Aspect | Cascade (2 mod√®les) | Single Model (1 mod√®le) |
|--------|---------------------|-------------------------|
| **Architecture** | Esp√®ce ‚Üí Maladie (conditionnel) | Direct ‚Üí 38 classes |
| **Entra√Ænement** | 2 mod√®les s√©par√©s | 1 mod√®le unique |
| **Inf√©rence** | 2 passes forward | 1 passe forward |
| **Classes "healthy"** | Traitement sp√©cial | Classe normale |
| **Erreurs** | Propagation esp√®ce ‚Üí maladie | Pas de propagation |
| **Complexit√©** | Plus complexe | Plus simple |

## üèóÔ∏è Architecture

```
Input Image (256√ó256√ó3)
         ‚Üì
EfficientNetV2B1 (ImageNet)
         ‚Üì
GlobalAveragePooling
         ‚Üì
Dropout(0.5)
         ‚Üì
Dense(512, relu) + L2
         ‚Üì
Dropout(0.3)
         ‚Üì
Dense(38, softmax)
         ‚Üì
38 classes finales
```

### Classes finales (38)

```
Apple___Apple_scab
Apple___Black_rot
Apple___Cedar_apple_rust
Apple___healthy          ‚Üê 'healthy' est une classe normale!
...
Tomato___Bacterial_spot
Tomato___Early_blight
Tomato___healthy         ‚Üê 'healthy' est une classe normale!
...
```

## üìä Entra√Ænement

### Configuration

- **Backbone**: EfficientNetV2B1 (~8M params)
- **Split**: Stratifi√© avec SEED=42
  - Train: ~70%
  - Val: ~15%
  - Test: ~15%
- **Batch size**: 32
- **Image size**: 256√ó256

### Strat√©gie de Fine-tuning (2 phases)

#### Phase 1: Head Only (15 √©poques)
- Backbone EfficientNetV2B1 **gel√©**
- Entra√Ænement de la t√™te uniquement (Dense layers)
- Learning rate: 1e-3
- Label smoothing: 0.1

#### Phase 2: Fine-tuning (40 √©poques)
- D√©gel des **80 derni√®res couches** du backbone
- Learning rate: 1e-4 (10x plus petit)
- Label smoothing: 0.1
- Early stopping: patience=7
- ReduceLROnPlateau: patience=3

**Total: 55 √©poques**

## üìà Visualisations g√©n√©r√©es automatiquement

### 1. Graphiques d'entra√Ænement (`training_curves.png`)

Grille 2√ó2 avec:
- **Loss vs Epochs** (train + val)
- **Accuracy vs Epochs** (train + val)
- **AUC vs Epochs** (train + val)
- **Learning Rate vs Epochs** (log scale)

### 2. Matrices de confusion (Heatmaps)

#### `confusion_matrix_full.png`
- Matrice 38√ó38 compl√®te
- Couleur: Jaune ‚Üí Orange ‚Üí Rouge
- Diagonale = pr√©dictions correctes

#### `confusion_matrix_normalized.png`
- Normalis√©e en % par classe vraie
- Couleur: Rouge (erreurs) ‚Üí Vert (correct)
- Montre la proportion d'erreurs

#### `confusion_matrix_errors.png`
- **Diagonale exclue** (= 0)
- Montre UNIQUEMENT les erreurs
- Tr√®s sparse si bon mod√®le!

### 3. Rapport d√©taill√©

- `classification_report.csv`: Precision, Recall, F1 pour chaque classe
- `top_confusions.csv`: Top confusions d√©taill√©es
- `results.json`: M√©triques globales (accuracy, F1 macro, F1 weighted)

## üéØ M√©triques

### M√©triques globales calcul√©es

```json
{
  "accuracy": 0.XXXX,
  "f1_macro": 0.XXXX,      // Toutes classes √©gales
  "f1_weighted": 0.XXXX,   // Pond√©r√© par support (PRINCIPAL)
  "num_classes": 38,
  "num_test_samples": 8146
}
```

### Comparaison attendue avec Cascade

**Avantages du Single-Model:**
- ‚úÖ Plus simple (1 mod√®le vs 2)
- ‚úÖ Plus rapide (1 inf√©rence vs 2)
- ‚úÖ Pas de propagation d'erreur
- ‚úÖ 'healthy' trait√© uniform√©ment

**Inconv√©nients potentiels:**
- ‚ùå Moins de contraintes structurelles (esp√®ce ‚Üí maladie)
- ‚ùå Plus de classes √† apprendre simultan√©ment (38 vs 14+21)

## üöÄ Utilisation

### Entra√Ænement

```bash
python train_single_model_efficientnet.py \
  --epochs_phase1 15 \
  --epochs_phase2 40 \
  --batch_size 32 \
  --patience 7
```

### Monitoring

```bash
bash monitor_single_model.sh
```

### R√©sultats

Tous les fichiers dans `outputs/single_model_efficientnet/`:
```
single_model_efficientnet.keras     # Mod√®le final
training_history.csv                # Historique complet
training_curves.png                 # Graphiques 4-en-1
confusion_matrix_full.png           # Heatmap compl√®te
confusion_matrix_normalized.png     # Heatmap %
confusion_matrix_errors.png         # Erreurs only
classification_report.csv           # D√©tails par classe
top_confusions.csv                  # Top erreurs
results.json                        # M√©triques globales
class_mapping.json                  # Mapping classes
```

## üìù Notes importantes

1. **SEED=42** fix√© pour reproducibilit√©
2. **Mixed precision** activ√©e (FP16) pour acc√©l√©ration
3. **Label smoothing** (0.1) pour r√©gularisation
4. **Early stopping** pour √©viter overfitting
5. **Stratified split** pour garder distribution des classes

## üî¨ √Ä analyser apr√®s entra√Ænement

1. **Comparer avec Cascade**:
   - Accuracy, F1 macro, F1 weighted
   - Vitesse d'inf√©rence
   - Complexit√© du mod√®le

2. **Analyser les confusions**:
   - Erreurs intra-esp√®ce (m√™me esp√®ce, maladie diff√©rente)?
   - Erreurs inter-esp√®ces (esp√®ce diff√©rente)?
   - 'healthy' confondu avec quelles maladies?

3. **Analyser la convergence**:
   - Overfitting?
   - Sous-apprentissage?
   - Optimal stopping?

## üí° Am√©liorations possibles

- Test avec EfficientNetV2B2/B3 (plus gros)
- Data augmentation (rotation, flip, color jitter)
- Test avec d'autres backbones (ConvNeXt, SwinTransformer)
- Ensembling avec Cascade
- Focal loss pour classes d√©s√©quilibr√©es
