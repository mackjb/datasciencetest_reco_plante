import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os

from utils import render_mermaid


def render_dl_content():
    st.markdown("""
    Le Deep Learning permet d'apprendre automatiquement les features directement √† partir des pixels, 
    contrairement au Machine Learning classique qui n√©cessite une extraction manuelle de descripteurs.
    """)


    
    # --- Phase d'exploration individuelle ---
    with st.expander("üë• Phase d'Exploration Individuelle", expanded=True):
        st.markdown("""
        Dans le cadre de notre formation, **chaque membre de l'√©quipe a d'abord explor√© individuellement 
        un mod√®le pr√©-entra√Æn√©** pour se familiariser avec les techniques de Deep Learning et comprendre 
        les diff√©rents d√©fis li√©s √† :
        """)

        col_img, col_txt = st.columns([1.3, 2])

        with col_img:
            st.image(
                "Streamlit/assets/leviers_DL.png",
                use_container_width=True,
            )

        with col_txt:
            st.markdown("""
            - Le choix du backbone (architecture du r√©seau)
            - Le fine-tuning et le transfer learning
            - La gestion du d√©s√©quilibre des classes
            - L'optimisation des hyperparam√®tres
            - L'interpr√©tabilit√© des mod√®les
            """)

        st.markdown("""
        Cette phase exploratoire nous a permis de **confronter la th√©orie √† la pratique** et d'acqu√©rir 
        une compr√©hension approfondie des leviers disponibles avant de nous lancer dans l'exploration 
        structur√©e des 9 architectures.
        """)

        st.markdown("### üîÑ Transfer Learning et Comparaison des Mod√®les")
        
        st.markdown("""
        Nous avons choisi d'utiliser le **transfert d'apprentissage** car les mod√®les sont d√©j√† entra√Æn√©s 
        sur des millions d'images pour d√©tecter des motifs g√©n√©riques (contours, textures, formes). 
        C'est un **gain de temps et de ressources** consid√©rable.
        """)
        
        st.markdown("**Comparatif des Mod√®les Pr√©-entra√Æn√©s Explor√©s :**")
        
        models_comparison = {
            "Caract√©ristique": ["Ann√©e", "Auteurs/Org", "Param√®tres (M)", "Taille mod√®le (MB)", 
                               "GFLOPs (224√ó224)", "GFLOPs (256√ó256)", "Taille vecteur sortie",
                               "Top-1 Acc ImageNet", "Top-5 Acc ImageNet", "Latence CPU (ms)", 
                               "Latence GPU (ms)", "Taille entr√©e", "Profondeur (layers)"],
            "EfficientNetV2-S": [2021, "Google Brain", 21.5, "~86", 8.4, "~10.8", 1280, 
                                "83.9%", "96.7%", "60-80", "5-8", "384√ó384 (optim.)", "~150"],
            "ResNet50": [2015, "Microsoft Research", 25.6, "~102", 4.1, "~5.3", 2048,
                        "76.1%", "93.0%", "40-50", "3-5", "224√ó224", "50"],
            "YOLOv8n-cls*": [2023, "Ultralytics", 2.7, "~11", 4.2, "~5.4", 1024,
                           "69.0%", "88.3%", "25-35", "2-4", "224√ó224", "~100"],
            "DenseNet-121": [2017, "Cornell/Facebook", 8.0, "~32", 2.9, "~3.7", 1024,
                           "74.4%", "92.0%", "30-40", "3-5", "224√ó224", "121"]
        }
        df_models = pd.DataFrame(models_comparison)
        
        # Transposer pour avoir les mod√®les en colonnes
        df_models_t = df_models.set_index("Caract√©ristique").T
        
        st.dataframe(df_models_t, use_container_width=True)
        
        st.success("""
        **üèÜ Choix retenu pour l'exploration des architectures : EfficientNetV2S**
        
        EfficientNetV2S offre un **excellent compromis entre performance et efficacit√©** :
        - **Pr√©cision Top-1** de 83,9% sur ImageNet, surpassant ResNet50 (76,1%) et DenseNet-121 (74,4%)
        - **21,5M param√®tres** : moins que ResNet50 (25,6M) mais plus que DenseNet-121 (8M)
        - **Efficacit√© computationnelle** remarquable : latence GPU r√©duite (5-8 ms)
        - **Pr√©cision Top-5** de 96,7%, id√©ale pour des t√¢ches de classification exigeantes
        - Adapt√© √† nos travaux n√©cessitant rapidit√© avec des ressources limit√©es
        """)

        # Mindmap Th√©orie du Fine-Tuning
        # Interactive Mindmap Data Definition for Fine-Tuning
        mindmap_ft = {
            "id": "root",
            "text": "Th√©orie du<br/>Fine-Tuning",
            "children": [
                {
                    "id": "Fondements", 
                    "text": "<b>1. Fondements techniques</b><br/>Transfer Learning",
                    "collapsed": True,
                    "children": [
                        {"id": "Connaissances", "text": "Transfert de connaissances : Exploiter des mod√®les pr√©-entra√Æn√©s sur des millions d'images <i>ImageNet</i>"},
                        {"id": "Motifs", "text": "D√©tection de motifs g√©n√©riques : Bords, textures, formes g√©om√©triques de base"},
                        {"id": "Efficience", "text": "Gain de temps et de ressources de calcul"}
                    ]
                },
                {
                    "id": "Processus", 
                    "text": "<b>2. D√©roulement en 2 Phases</b><br/>Strat√©gie standard",
                    "collapsed": True,
                    "children": [
                        {
                            "id": "Phase_1", 
                            "text": "Phase 1 : √âchauffement<br/><i>Warm-up</i>",
                            "children": [
                                {"id": "Gel", "text": "Backbone gel√© : On ne modifie pas les poids de l'extracteur de caract√©ristiques"},
                                {"id": "Entrainement_Tete", "text": "Entra√Ænement de la t√™te uniquement : Adaptation aux nouvelles classes"}
                            ]
                        },
                        {
                            "id": "Phase_2", 
                            "text": "Phase 2 : Ajustement fin<br/><i>Fine-tuning</i>",
                            "children": [
                                {"id": "Degel", "text": "D√©gel partiel : D√©blocage des couches sup√©rieures du backbone"},
                                {"id": "Adaptation", "text": "Sp√©cialisation : Les features g√©n√©riques deviennent sp√©cifiques aux pathologies v√©g√©tales"}
                            ]
                        }
                    ]
                },
                {
                    "id": "Parametres", 
                    "text": "<b>3. Param√®tres & M√©canismes cl√©s</b>",
                    "collapsed": True,
                    "children": [
                        {"id": "Backbone", "text": "Backbone pr√©-entra√Æn√© : ex. EfficientNetV2-S choisi pour son √©quilibre performance/latence"},
                        {"id": "Learning_Rate", "text": "Learning Rate r√©duit : Indispensable en Phase 2 pour ne pas d√©truire les poids pr√©-entra√Æn√©s"},
                        {"id": "Regularisation", "text": "Label Smoothing & Gradient Clipping : Stabilisation de l'apprentissage"},
                        {"id": "Optimisation", "text": "Poids de classes : Pour g√©rer le d√©s√©quilibre du dataset"}
                    ]
                },
                {
                    "id": "Gains", 
                    "text": "<b>4. Gains & B√©n√©fices</b>",
                    "collapsed": True,
                    "children": [
                        {"id": "Performance", "text": "Pr√©cision accrue : Atteint des scores >99% inaccessibles sans fine-tuning"},
                        {"id": "Convergence", "text": "Vitesse : Convergence plus rapide qu'un entra√Ænement <i>from scratch</i>"},
                        {"id": "Robustesse", "text": "Adaptation au domaine : Passage de l'image g√©n√©rale √† la l√©sion sp√©cifique"}
                    ]
                },
                {
                    "id": "Risques", 
                    "text": "<b>5. Points de vigilance</b>",
                    "collapsed": True,
                    "children": [
                        {"id": "Overfitting", "text": "Sur-apprentissage : Si le mod√®le m√©morise au lieu de g√©n√©raliser"},
                        {"id": "Features_Generiques", "text": "Features trop g√©n√©riques : Si le fine-tuning n'est pas activ√©, la perte peut √™tre catastrophique"},
                        {"id": "Desequilibre", "text": "D√©s√©quilibre des classes : Biais vers les classes majoritaires"},
                        {"id": "Fragilite_Wild", "text": "Fragilit√© 'In-Wild' : Chute de performance hors fond uniforme"}
                    ]
                }
            ]
        }

        render_mermaid(mindmap_ft, height=600)
        st.caption("Figure : Principes et strat√©gie de Fine-Tuning appliqu√©s au projet")
    
    # --- M√©thodologie ---
    with st.expander("üéØ M√©thodologie & Crit√®res de S√©lection", expanded=True):
        st.markdown("""
        ### D√©marche structur√©e en 3 √©tapes :
        
        1. **Exploration** : 9 architectures test√©es pour comprendre le Deep Learning et ses d√©fis
        2. **√âvaluation comparative** : Restriction √† quelques architectures couvrant 3 cas d'usage
        3. **S√©lection & Recommandation** : Projection pour un d√©ploiement r√©el
        
        ### Crit√®res de s√©lection :
        
        | Cat√©gorie | Crit√®res | Justification |
        |-----------|----------|---------------|
        | **M√©tier** | Pr√©cision (Macro-F1, Accuracy) | Capacit√© √† bien pr√©dire toutes les classes |
        | | G√©n√©ralisation (√©cart val/test) | Robustesse du mod√®le (<2% = bon, >5% = overfitting) |
        | | Couverture op√©rationnelle | R√©ponse aux 3 cas d'usage m√©tier |
        | **Technique** | Co√ªt d'inf√©rence (FLOPs, latence) | Impact sur batterie et exp√©rience utilisateur |
        | | Co√ªt d'entra√Ænement (temps, GPU) | Budget cloud et it√©rations rapides |
        | | Complexit√© (param√®tres, maintenabilit√©) | Taille du mod√®le et facilit√© de maintenance |
        | **Autres** | Interpr√©tabilit√© | Capacit√© √† expliquer les pr√©dictions (Grad-CAM) |
        | | Besoins en donn√©es | Quantit√© d'images annot√©es n√©cessaire |
        """)
        
        st.info("""
        **üéØ Les 3 cas d'usage :**
        - **Cas 1** : Identification d'esp√®ce uniquement
        - **Cas 2** : Diagnostic cibl√© (esp√®ce connue ‚Üí maladie)
        - **Cas 3** : Diagnostic complet (esp√®ce + maladie inconnues)
        """)

    # Onglets principaux DL
    dl_tabs = st.tabs(["üèóÔ∏è Architectures", "üìä Performances"])
    
    with dl_tabs[0]:
        st.header("Exploration des 9 Architectures")
        
        st.markdown("""
        **Protocole exp√©rimental commun :**
        - Dataset : PlantVillage/color
        - Backbone pr√©-entra√Æn√© : **EfficientNetV2S** (ImageNet)
        - Splits identiques pour tous les mod√®les
        - Hyperparam√®tres fix√©s : learning rate, batch size, augmentation
        - M√©triques : Loss, Accuracy, Macro-F1, matrice de confusion
        """)
        
        st.divider()
        
        # Pr√©sentation des architectures
        st.markdown("### üèóÔ∏è Backbone Pr√©-entra√Æn√© D√©di√© √† Chaque Objectif")
        
        arch_info_dedicated = [
            {
                "num": "1",
                "nom": "Trois mod√®les ind√©pendants",
                "desc": "**Architecture sp√©cialis√©e** : Trois mod√®les CNN ind√©pendants, chacun d√©di√© √† une seule t√¢che (species, health, disease). Chaque mod√®le comprend un backbone pr√©-entra√Æn√© et une t√™te de classification Dense adapt√©e au nombre de classes.",
                "workflow": "Chaque mod√®le s'entra√Æne en 2 phases sur le m√™me dataset : (1) backbone gel√© avec entra√Ænement de la t√™te uniquement; (2) fine-tuning des derni√®res couches du backbone pour adapter les features ImageNet aux sp√©cificit√©s du dataset.",
                "avantages": "Simplicit√© (1 t√¢che = 1 mod√®le), absence de conflits entre t√¢ches (pas de compromis dans l'optimisation), performances maximales par t√¢che (sp√©cialisation totale), interpr√©tabilit√© facilit√©e (1 objectif clair par mod√®le).",
                "limites": "Triplication des ressources (3 backbones √† stocker et maintenir), inf√©rences multiples pour cas d'usage complexes, absence de synergie inter-t√¢ches (pas de transfert d'apprentissage entre les 3 t√™tes), temps d'entra√Ænement cumul√© plus long (3 runs).",
                "img": "figures/architectures_dl/archi1.png"
            },
            {
                "num": "2",
                "nom": "Deux mod√®les (species + disease_extended)",
                "desc": "Deux mod√®les CNN ind√©pendants : l'un pour l'esp√®ce, l'autre pour l'√©tat sanitaire complet. La classe 'healthy' est int√©gr√©e comme une maladie sp√©ciale.",
                "workflow": "Deux runs mono-t√¢che. Le mod√®le species s'entra√Æne sur toutes les images (saines + malades). Le mod√®le disease_extended s'entra√Æne √©galement sur toutes les images.",
                "avantages": "Simplicit√© (2 t√™tes), uniformit√© (deux softmax multi-classe), diagnostic complet en 2 inf√©rences (species + disease_extended), 'healthy' est un √©tat sanitaire comme les maladies.",
                "limites": "D√©s√©quilibre accru (classe 'healthy' majoritaire), perte de la m√©trique binaire explicite healthy/diseased, interpr√©tation plus ambigu√´ des pr√©dictions mixtes (ex: 40% healthy, 35% early_blight).",
                "img": "figures/architectures_dl/archi2.png"
            },
            {
                "num": "3",
                "nom": "Mod√®le unifi√© (35 classes)",
                "desc": "**Architecture unifi√©e** : Un mod√®le CNN pr√©-entra√Æn√© + 1 t√™te Dense softmax (35 classes). √âtiquette combin√©e : chaque image est √©tiquet√©e par un couple 'Esp√®ce__√âtat' (Tomato__healthy, Apple__scab‚Ä¶).",
                "workflow": "Phase 1: backbone gel√©, entra√Ænement de la t√™te uniquement. Phase 2: fine-tuning partiel des derni√®res couches du backbone. Les labels sont pr√©-combin√©s en 35 classes.",
                "avantages": "Un seul mod√®le, une seule inf√©rence : plus simple √† d√©ployer et √† utiliser. Synergie entre t√¢ches : l'apprentissage capte directement les co-d√©pendances esp√®ce‚Üîmaladie/sant√©.",
                "limites": "Moins de sp√©cialisation par t√¢che. Les classes rares peuvent √™tre sous-apprises. Peu flexible : impossible de g√©rer des paires in√©dites (nouvelle esp√®ce/maladie) sans r√©entra√Æner les 35 classes. Interpr√©tabilit√© : plus dur d'isoler l'erreur (vient-elle de l'identification d'esp√®ce ou de maladie ?).",
                "img": "figures/architectures_dl/archi3.png"
            },
            {
                "num": "4",
                "nom": "Architecture en cascade",
                "desc": "**Architecture en cascade** : Deux mod√®les CNN pr√©-entra√Æn√©s cha√Æn√©s. Un classificateur d'esp√®ce extrait un embedding et pr√©dit l'esp√®ce. Un classificateur de maladie global (21 classes, dont 'healthy') re√ßoit l'image + l'esp√®ce et applique une attention spatiale pour se focaliser sur les zones pertinentes.",
                "workflow": "Phase 1 : backbone gel√©, entra√Ænement de la t√™te. Phase 2 : fine-tuning partiel du backbone. Entra√Ænement du mod√®le maladie en 2 phases, en lui fournissant l'esp√®ce (True) en entr√©e pour stabiliser l'apprentissage. √âvaluation en CASCADE avec esp√®ce pr√©dite.",
                "avantages": "La pr√©diction d'esp√®ce guide la maladie, r√©duisant les confusions entre esp√®ces. L'attention spatiale aide √† capter les indices visuels pertinents. Modularit√© : possibilit√© d'am√©liorer s√©par√©ment esp√®ce ou maladie sans tout r√©entra√Æner.",
                "limites": "Une esp√®ce mal pr√©dite d√©grade la maladie. Le mod√®le maladie voit l'esp√®ce (True) √† l'entra√Ænement mais la pr√©dite en production. Latence accrue avec passes r√©seau successives. En cas d'esp√®ce erron√©e, une maladie impossible peut √™tre propos√©e.",
                "img": "figures/architectures_dl/archi4.png"
            }
        ]
        
        for arch in arch_info_dedicated:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                col1, col2 = st.columns([1.2, 1])
                
                with col1:
                    st.markdown(f"**Description** : {arch['desc']}")
                    st.markdown(f"**Workflow** : {arch['workflow']}")
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
                
                with col2:
                    if os.path.exists(arch['img']):
                        st.image(arch['img'], caption=f"Sch√©ma Architecture {arch['num']}", use_container_width=True)
        
        st.divider()
        st.markdown("### üîó Backbone Pr√©-entra√Æn√© Partag√© Entre Plusieurs Objectifs")
        
        arch_info_shared = [
            {
                "num": "5",
                "nom": "CNN + SVM",
                "desc": "**Architecture 'CNN + SVM'** : Un backbone CNN pr√©-entra√Æn√© (gel√©) transforme chaque image en vecteur d'embeddings (features). Des classifieurs SVM (esp√®ce, sant√©, maladie) sont entra√Æn√©s sur ces embeddings.",
                "workflow": "Sauvegarde des vecteurs + labels. Puis chargement des embeddings, entra√Ænement de trois t√™tes SVM: Esp√®ce (multi-classe), Sant√© (binaire: healthy vs diseased), Maladie (soit global multi-classe, soit par esp√®ce).",
                "avantages": "Entra√Ænement tr√®s rapide des SVM; it√©rations l√©g√®res (on r√©utilise les embeddings). Simplicit√© op√©rationnelle : s√©paration claire 'features gel√©es' / 'classifieurs'; facile de remplacer le backbone ou de r√©entra√Æner seulement les SVM.",
                "limites": "Les features restent g√©n√©riques : pas d'adaptation conjointe aux t√¢ches du dataset. Coh√©rence multi-t√¢ches limit√©e.",
                "img": "figures/architectures_dl/archi5.png"
            },
            {
                "num": "6",
                "nom": "Multi-t√¢che unifi√© (3 t√™tes)",
                "desc": "**Architecture multi-t√¢che unifi√©e** : Un seul backbone CNN pr√©-entra√Æn√© partag√© produit un embedding commun, puis trois t√™tes de classification parall√®les: Esp√®ce, Sant√©, Maladie. La t√™te 'maladie' est optimis√©e sur les images malades uniquement.",
                "workflow": "Une seule phase 't√™tes seules' avec backbone gel√© (pertes pond√©r√©es par t√™te). Pas de fine-tuning activ√©.",
                "avantages": "Les trois t√¢ches se renforcent (l'esp√®ce et la sant√© aident la maladie). Un seul backbone √† entra√Æner ; une seule inf√©rence pour obtenir esp√®ce, sant√©, maladie. Contr√¥le des compromis via pond√©rations de pertes par t√™te.",
                "limites": "Conflits d'optimisation : objectifs parfois concurrents ; sensibilit√© aux pond√©rations des pertes. Malgr√© la t√™te d√©di√©e, les maladies peu repr√©sent√©es restent difficiles. Features ImageNet peuvent rester trop g√©n√©riques (pas de fine-tuning). Couplage des t√¢ches : une mauvaise mod√©lisation de l'esp√®ce/sant√© peut impacter la maladie.",
                "img": "figures/architectures_dl/archi6.png"
            },
            {
                "num": "7",
                "nom": "Multi-t√¢che 2 t√™tes + signal sant√©",
                "desc": "**Architecture multi-t√¢che √† 2 t√™tes** : Un backbone CNN pr√©-entra√Æn√© partag√© produit un embedding commun. T√™te esp√®ce (multi-classe). T√™te maladie (multi-classe hors 'healthy', activ√©e uniquement pour √©chantillons malades). Un signal sant√© auxiliaire interne est inject√© comme feature dans la t√™te maladie.",
                "workflow": "Phase 1: entra√Ænement des t√™tes avec backbone gel√© (pond√©rations de pertes, l'√©chantillon tagu√© 'healthy' n'entra√Æne pas la t√™te maladie). Phase 2: fine-tuning partiel des couches hautes du backbone.",
                "avantages": "Une seule passe backbone pour deux t√¢ches; co√ªt d'inf√©rence r√©duit. L'injection de la probabilit√© 'malade' et le masquage de perte √©vitent que les 'healthy' perturbent la t√™te maladie. Synergie utile: l'embedding partag√© b√©n√©ficie des signaux esp√®ce et sant√© auxiliaire. Equilibre des objectifs via pond√©rations des pertes.",
                "limites": "Pas de sortie sant√© explicite: pas de score/label 'healthy vs diseased' livrable tel quel (signal interne non calibr√©). D√©pendance au signal sant√©: si le signal auxiliaire est biais√©, la t√™te maladie peut sur- ou sous-activer certaines classes. Conflits d'optimisation: sensibilit√© aux pond√©rations et au fine-tuning. Classes rares: malgr√© le masquage des 'healthy', les maladies peu repr√©sent√©es restent difficiles.",
                "img": "figures/architectures_dl/archi7.png"
            },
            {
                "num": "8",
                "nom": "Multi-t√¢che simplifi√©",
                "desc": "**Architecture multi-t√¢che simplifi√©e (2 t√™tes)** : Un seul backbone CNN pr√©-entra√Æn√© partag√©, et deux t√™tes parall√®les: Esp√®ce, Disease (incluant explicitement healthy). Pas de t√™te 'sant√©' d√©di√©e, pas de masquage : toutes les images entra√Ænent les deux t√™tes.",
                "workflow": "Phase 1: entra√Ænement des t√™tes avec backbone gel√© (pond√©rations de pertes, label smoothing). Phase 2: fine-tuning partiel du haut du backbone (option gradient clipping). Inf√©rence: une seule passe r√©seau ‚Üí deux sorties simultan√©es: Esp√®ce et Healthy/Maladie.",
                "avantages": "Simplicit√©: pas de t√™te sant√©, pas de r√®gles/mask; supervision uniforme. Efficience: un seul backbone et une seule inf√©rence pour obtenir esp√®ce + sant√©/maladie. Coh√©rence de d√©cision: healthy fait partie du m√™me espace que les maladies ‚Üí seuils et calibration unifi√©s (softmax √† 21 classes). Maintenance l√©g√®re: pipeline standardis√©.",
                "limites": "D√©s√©quilibre 'healthy': la classe healthy peut dominer et biaiser la t√™te disease_all, au d√©triment des maladies rares. Pas de conditionnement par esp√®ce: risque de confusions inter-esp√®ces. Seuils globaux: calibration potentiellement sous-optimale pour distributions tr√®s diff√©rentes selon l'esp√®ce. Shortcut possible: le mod√®le peut exploiter des corr√©lations de fond plut√¥t que des l√©sions fines.",
                "img": "figures/architectures_dl/archi8.png"
            },
            {
                "num": "9",
                "nom": "Architecture conditionn√©e",
                "desc": "**Architecture conditionn√©e (Species + Health ‚Üí Disease)** : Un backbone CNN pr√©-entra√Æn√© unique produit un embedding partag√©. T√™te esp√®ce (multi-classe). T√™te maladie (multi-classe hors 'healthy'), conditionn√©e par le vecteur de probabilit√©s d'esp√®ce et la probabilit√© interne d'√™tre malade (t√™te sant√© auxiliaire non expos√©e). Les √©chantillons 'healthy' n'entra√Ænent pas la t√™te maladie.",
                "workflow": "Phase 1: apprentissage des t√™tes avec backbone gel√©, pond√©rations de pertes. Phase 2: fine-tuning partiel des couches hautes. La t√™te maladie est optimis√©e uniquement sur les images malades (healthy masqu√©s).",
                "avantages": "Conditionnement explicite: la maladie est guid√©e par l'info d'esp√®ce et un indicateur de sant√©, r√©duisant les confusions inter-esp√®ces et focalisant sur les cas r√©ellement malades. Synergie multi-t√¢ches: l'embedding partag√© + signaux auxiliaires apportent un contexte fort. Efficience: un seul backbone; une seule inf√©rence pour obtenir esp√®ce et maladie. Contr√¥le des compromis via pond√©rations de pertes.",
                "limites": "Propagation d'erreurs: une erreur d'esp√®ce ou un biais du signal sant√© peut entra√Æner une mauvaise pr√©diction de maladie. Raccourcis/biais: le mod√®le peut sur-utiliser les a priori esp√®ce/sant√© au d√©triment d'indices visuels fins. Pas de sortie sant√© livrable: la sant√© est un signal interne. Calibrage sur 'healthy': la t√™te maladie n'est pas entra√Æn√©e sur les sains; ses sorties peuvent √™tre peu informatives pour des images r√©ellement 'healthy'.",
                "img": "figures/architectures_dl/archi9.png"
            }
        ]
        
        for arch in arch_info_shared:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                col1, col2 = st.columns([1.2, 1])
                
                with col1:
                    st.markdown(f"**Description** : {arch['desc']}")
                    st.markdown(f"**Workflow** : {arch['workflow']}")
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
                
                with col2:
                    if os.path.exists(arch['img']):
                        st.image(arch['img'], caption=f"Sch√©ma Architecture {arch['num']}", use_container_width=True)
    
    with dl_tabs[1]:
        st.header("Synth√®se des Performances")
        
        # Tableau de performances
        perf_dl = {
            "Architecture": ["Archi 1", "Archi 2", "Archi 3", "Archi 4", "Archi 5", "Archi 6", "Archi 7", "Archi 8", "Archi 9"],
            "Species Macro-F1": [0.990, 0.990, 0.990, 0.990, 0.985, 0.988, 0.990, 0.989, 0.990],
            "Species Accuracy": [0.990, 0.990, 0.990, 0.990, 0.986, 0.988, 0.990, 0.989, 0.990],
            "Disease Accuracy": [0.990, 0.988, 0.990, 0.987, 0.982, 0.975, 0.990, 0.986, 0.990],
            "FLOPs (relatif)": ["3√ó", "2√ó", "1√ó", "2√ó", "1√ó", "1√ó", "1√ó", "1√ó", "1√ó"],
            "Maintenabilit√©": ["Faible", "Moyenne", "√âlev√©e", "Faible", "Moyenne", "Moyenne", "Moyenne", "Moyenne", "Faible"]
        }
        df_perf_dl = pd.DataFrame(perf_dl)
        
        st.dataframe(df_perf_dl.style.highlight_max(subset=["Species Macro-F1", "Species Accuracy", "Disease Accuracy"], axis=0))
        
        st.divider()
        
        st.markdown("""
        ### üéØ D√©cisions et Exclusions
        
        **Architectures exclues :**
        - **Archi 4** : Cascade complexe sans gain tangible, risque de propagation d'erreurs
        - **Archi 6** : En retrait sur la maladie (0.975 vs ‚â•0.989 pour les autres)
        - **Archi 8** : Pas de b√©n√©fice mesurable vs Archi 7/9
        
        **Architectures retenues pour recommandation :**
        - **Archi 3** : Excellente simplicit√© de d√©ploiement (1 mod√®le, 1 inf√©rence)
        - **Archi 7** : Bon compromis performance/efficience
        - **Archi 9** : Conditionnement explicite, synergie maximale
        """)
        
        # Graphique comparatif
        fig_comp = go.Figure()
        fig_comp.add_trace(go.Bar(
            name='Species Macro-F1',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Species Macro-F1'],
            marker_color='lightblue'
        ))
        fig_comp.add_trace(go.Bar(
            name='Disease Accuracy',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Disease Accuracy'],
            marker_color='lightcoral'
        ))
        fig_comp.update_layout(
            title="Comparaison des Performances par Architecture",
            yaxis_range=[0.97, 1.0],
            barmode='group'
        )
        st.plotly_chart(fig_comp, use_container_width=True)


def sidebar_choice():
    st.title("üß† Deep Learning")
    render_dl_content()

