import streamlit as st
import pandas as pd
import plotly.express as px
import os


def render_ml_content():
    st.markdown("""
    L'approche classique repose sur l'**extraction manuelle de descripteurs** (Handcrafted Features) plutÃ´t que sur l'apprentissage direct des pixels. 
    Elle sert de **baseline** robuste pour comparer nos futurs modÃ¨les Deep Learning.
    """)
    
    # --- MÃ©thodologie ---
    with st.expander("ğŸ› ï¸ MÃ©thodologie & Pipeline", expanded=True):
        col_m1, col_m2 = st.columns([1.5, 1])
        
        with col_m1:
            st.markdown("""
            **Ã‰tapes clefs du pipeline robuste :**
            1. ğŸ“¸ **Collecte** : Images nettes et segmentÃ©es.
            2. ğŸ“ **Extraction** : Calcul des descripteurs (Morpho, Couleur, Texture...).
            3. ğŸ§¹ **Nettoyage** : Suppression des images corrompues (9 images avec NaN).
            4. ğŸ“ˆ **Augmentation** : Enrichissement du dataset â†’ **91 770 images finales**.
            5. âš–ï¸ **Scaling** : Normalisation **RobustScaler** (gestion des 40% d'outliers).
            6. ğŸ¯ **SÃ©lection** : Garder les features les plus discriminantes (SHAP).
            7. ğŸ¤– **ModÃ©lisation** : EntraÃ®nement des classifieurs.
            """)
            
        with col_m2:
            st.info("""
            **ğŸ¯ Exploration par l'Ã©quipe :**
            - **SVM (RBF)** : Bernadette GASMI
            - **XGBoost** : Lionel SCHNEIDER
            - **Reg. Logistique** : JB MACK
            - **Extra-Trees** : Morgan PERCHEC
            """)
        
        st.divider()
        st.info("""
        **Points clÃ©s** : 
        - Split **80/10/10** stratifiÃ©.
        - **Data Augmentation** sur le train (91 770 images finales).
        - **RobustScaler** utilisÃ© pour gÃ©rer les 40% d'outliers dÃ©tectÃ©s.
        """)

    tabs = st.tabs(["âš™ï¸ Features", "ğŸ“Š Performances", "ğŸ§  SHAP"])
    
    with tabs[0]:
        st.header("1. Extraction des Descripteurs")

        center_col = st.columns([1, 2, 1])[1]
        with center_col:
            st.image(
                "Streamlit/assets/Les datasets/CaractÃ©ristiques.drawio.png",
                caption="SynthÃ¨se des catÃ©gories de descripteurs extraits",
                width=750,
            )

        st.markdown("""
        **CatÃ©gories extraites :**
        - ğŸ“ **Morphologie** : Aire, pÃ©rimÃ¨tre, circularitÃ©, excentricitÃ©, aspect ratio, densitÃ© de contours
        - ğŸ¨ **Couleur** : Moyennes et Ã‰carts-types RGB / HSV
        - ğŸ•¸ï¸ **Texture** : Matrices de co-occurrence (GLCM) - nettetÃ©, contraste, energy, homogeneity, dissimilarity, correlation
        - ğŸ”„ **Invariants** : Moments de Hu (hu_1 Ã  hu_7)
        - ğŸ“» **FrÃ©quences** : Entropie et puissance spectrale (FFT)
        - ğŸ“ **Gradients** : Descripteurs HOG (moyenne, Ã©cart-type, entropie)
        """)

        st.markdown("""
        Ces descripteurs sont concatÃ©nÃ©s pour former un **vecteur unique par image** (34 features), 
        servant ensuite d'entrÃ©e aux algorithmes de classification.
        """)

        st.divider()
        st.subheader("Importance des Features")
        ranking_path = "results/feature_ranking.csv"
        if os.path.exists(ranking_path):
            df_rank = pd.read_csv(ranking_path).head(15).sort_values(by="final_score", ascending=True)
            fig_rank = px.bar(df_rank, x="final_score", y="feature", orientation="h",
                               title="Top 15 des Features les plus discriminantes",
                               color="final_score", color_continuous_scale="GnBu")
            st.plotly_chart(fig_rank, use_container_width=True)
        
    with tabs[1]:
        st.header("2. Analyse des Performances")
        
        st.markdown("""
        RÃ©sultats obtenus pour l'**Objectif 1** (Identification de l'espÃ¨ce) sur l'ensemble de test.
        Nous avons comparÃ© **4 modÃ¨les principaux**.
        """)
        
        perf_data = {
            "ModÃ¨le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_perf = pd.DataFrame(perf_data)
        
        col1, col2 = st.columns([1, 1.2])
        with col1:
            st.dataframe(df_perf.style.apply(lambda x: ['background-color: yellow' if x.name == 0 else '' for _ in x], axis=1))
            st.success("ğŸ† **SVM (RBF)** est le plus performant.")
        
        with col2:
            fig_perf = px.bar(df_perf, x="ModÃ¨le", y="F1-score (macro)", color="ModÃ¨le",
                               title="Comparaison des F1-Scores", text_auto='.2f')
            fig_perf.update_layout(showlegend=False)
            st.plotly_chart(fig_perf, use_container_width=True)

        cm_path = "results/Machine_Learning/svm_rbf_baseline_features_selected/plots/baseline/confusion_matrix.png"
        if os.path.exists(cm_path):
            with st.expander("ğŸ” Voir la Matrice de Confusion (SVM-RBF)"):
                st.image(cm_path, use_container_width=True)
                
    with tabs[2]:
        st.header("3. InterprÃ©tabilitÃ© SHAP")
        
        st.markdown("""
        **Observations clÃ©s :**
        - La **contour_density** domine trÃ¨s nettement l'importance globale (30% supÃ©rieure Ã  la 2Ã¨me feature)
        - Les features de **frÃ©quence spectrale** (fft_entropy) et de **couleur** (mean_R, mean_B) complÃ¨tent le trio de tÃªte
        - Chaque classe de maladie s'appuie sur un **sous-ensemble diffÃ©rent de features**
        - Les **34 features extraites sont toutes pertinentes**, aucune n'est totalement nÃ©gligeable
        """)
        
        shap_dir = "figures/shap_analysis"
        p1 = os.path.join(shap_dir, "1_global_importance.png")
        if os.path.exists(p1):
            st.image(p1, caption="Importance Globale des Features (Top 25)", use_container_width=True)
        else:
            st.warning("Graphique SHAP non trouvÃ©.")

        st.divider()
        st.subheader("ğŸ† SynthÃ¨se des RÃ©sultats par ModÃ¨le")
        st.markdown("Comparaison finale des performances sur l'Objectif 1 (Identification de l'espÃ¨ce).")
        
        full_perf_data = {
            "ModÃ¨le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "PrÃ©cision (macro)": [0.9271, 0.9051, 0.8462, 0.8607],
            "Rappel (macro)": [0.9207, 0.8654, 0.8214, 0.7405],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_full = pd.DataFrame(full_perf_data)
        df_melt = df_full.melt(id_vars="ModÃ¨le", var_name="MÃ©trique", value_name="Valeur")
        
        fig_full = px.bar(df_melt, x="ModÃ¨le", y="Valeur", color="MÃ©trique", barmode="group",
                          title="Comparaison Multi-MÃ©triques (Test Set)",
                          text_auto='.2f', color_discrete_sequence=px.colors.qualitative.Pastel)
        
        fig_full.update_layout(yaxis_range=[0.7, 1.0])
        st.plotly_chart(fig_full, use_container_width=True)
        
        st.info("ğŸ’¡ **Constat** : Le **SVM (RBF)** surpasse ses concurrents sur toutes les mÃ©triques, confirmant sa robustesse face au dÃ©sÃ©quilibre des classes.")


def sidebar_choice():
    st.title("ğŸ¤– Machine Learning")
    render_ml_content()

