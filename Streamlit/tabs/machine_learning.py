import streamlit as st
import pandas as pd
import plotly.express as px
import os

ASSETS_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "assets")


def render_ml_content():
    st.markdown("""
    L'approche classique repose sur l'**extraction manuelle de descripteurs** (Handcrafted Features) plut√¥t que sur l'apprentissage direct des pixels. 
    Elle sert de **baseline** robuste pour comparer nos futurs mod√®les Deep Learning.
    """)
    
    # --- M√©thodologie ---
    with st.expander("üõ†Ô∏è M√©thodologie & Pipeline", expanded=True):
        col_m1, col_m2 = st.columns([1.5, 1])
        
        with col_m1:
            st.markdown("""
            **√âtapes clefs du pipeline robuste :**
            1. üì∏ **Collecte** : Images nettes et segment√©es.
            2. üìê **Extraction** : Calcul des descripteurs (Morpho, Couleur, Texture...).
            3. üßπ **Nettoyage** : Suppression des images corrompues (9 images avec NaN).
            4. üìà **Augmentation** : Enrichissement du dataset ‚Üí **91 770 images finales**.
            5. ‚öñÔ∏è **Scaling** : Normalisation **RobustScaler** (gestion des 40% d'outliers).
            6. üéØ **S√©lection** : Garder les features les plus discriminantes (SHAP).
            7. ü§ñ **Mod√©lisation** : Entra√Ænement des classifieurs.
            """)
            
        with col_m2:
            st.info("""
            **üéØ Exploration par l'√©quipe :**
            - **SVM (RBF)** : Bernadette GASMI
            - **XGBoost** : Lionel SCHNEIDER
            - **Reg. Logistique** : JB MACK
            - **Extra-Trees** : Morgan PERCHEC
            """)
        
        st.divider()
        st.info("""
        **Points cl√©s** : 
        - Split **80/10/10** stratifi√©.
        - **Data Augmentation** sur le train (91 770 images finales).
        - **RobustScaler** utilis√© pour g√©rer les 40% d'outliers d√©tect√©s.
        """)

    tabs = st.tabs(["Features", "Performances", "SHAP"])
    
    with tabs[0]:
        st.header("Extraction des Descripteurs")

        col_p1, col_p2, = st.columns(2)
        with col_p1:
            st.subheader(" ")       
            st.image(
                os.path.join(ASSETS_DIR, "Les datasets/Caract√©ristiques.drawio.png"),
                caption="Synth√®se des cat√©gories de descripteurs extraits",
                width=700,
            )

        with col_p2:
            st.markdown("<br><br><br><br><br><br>", unsafe_allow_html=True)
            st.markdown("""
            **Cat√©gories extraites :**
            - **Morphologie** : Aire, p√©rim√®tre, circularit√©, excentricit√©, aspect ratio, densit√© de contours
            - **Couleur** : Moyennes et √âcarts-types RGB / HSV
            - **Texture** : Matrices de co-occurrence (GLCM) - nettet√©, contraste, energy, homogeneity, dissimilarity, correlation
            - **Invariants** : Moments de Hu (hu_1 √† hu_7)
            - **Fr√©quences** : Entropie et puissance spectrale (FFT)
            - **Gradients** : Descripteurs HOG (moyenne, √©cart-type, entropie)
            """)

            st.markdown("""
            Ces descripteurs sont concat√©n√©s pour former un **vecteur unique par image** (34 features), 
            servant ensuite d'entr√©e aux algorithmes de classification.
            """)

        st.divider()
        st.subheader("Importance des Features")
        ranking_path = "results/feature_ranking.csv"
        if os.path.exists(ranking_path):
            df_rank = pd.read_csv(ranking_path).head(15).sort_values(by="final_score", ascending=True)
            fig_rank = px.bar(df_rank, x="final_score", y="feature", orientation="h",
                               title="Top 15 des Features les plus discriminantes",
                               color="final_score", color_continuous_scale="GnBu")
            st.plotly_chart(fig_rank, width=800)
        
    with tabs[1]:
        st.header("Analyse des Performances")
        
        st.markdown("""
        R√©sultats obtenus pour l'**Objectif 1** (Identification de l'esp√®ce) sur l'ensemble de test.
        Nous avons compar√© **4 mod√®les principaux**.
        """)
        
        perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_perf = pd.DataFrame(perf_data)
        
        col1, col2 = st.columns([1, 1.2])
        with col1:
            st.dataframe(df_perf.style.apply(lambda x: ['background-color: yellow' if x.name == 0 else '' for _ in x], axis=1))
            st.success("üèÜ **SVM (RBF)** est le plus performant.")
        
        with col2:
            fig_perf = px.bar(df_perf, x="Mod√®le", y="F1-score (macro)", color="Mod√®le",
                               title="Comparaison des F1-Scores", text_auto='.2f')
            fig_perf.update_layout(showlegend=False)
            st.plotly_chart(fig_perf, use_container_width=True)

        cm_path = "results/Machine_Learning/svm_rbf_baseline_features_selected/plots/baseline/confusion_matrix.png"
        if os.path.exists(cm_path):
            with st.expander("üîç Voir la Matrice de Confusion (SVM-RBF)"):
                st.image(cm_path, use_container_width=True)
                
    with tabs[2]:
        st.header("Interpr√©tabilit√© SHAP")
        col_shap_1, col_shap_2 = st.columns(2)

        with col_shap_1:
        
            shap_dir = "figures/shap_analysis"
            p1 = os.path.join(shap_dir, "1_global_importance.png")
            if os.path.exists(p1):
                st.image(p1,  width=800)
            else:
                st.warning("Graphique SHAP non trouv√©.")
            
            st.markdown("""



            **Observations cl√©s :**
            - La **contour_density** domine tr√®s nettement l'importance globale (30% sup√©rieure √† la 2√®me feature)
            - Les features de **fr√©quence spectrale** (fft_entropy) et de **couleur** (mean_R, mean_B) compl√®tent le trio de t√™te
            - Chaque classe de maladie s'appuie sur un **sous-ensemble diff√©rent de features**
            - Les **34 features extraites sont toutes pertinentes**, aucune n'est totalement n√©gligeable
            """)

        with col_shap_2:

            shap_dir = "figures/shap_analysis"
            p2 = os.path.join(shap_dir, "3_top_features_by_class.png")
            if os.path.exists(p2):
                st.image(p2,width=700)
            else:
                st.warning("Graphique SHAP non trouv√©.")
        
            st.markdown("""
            **Observations cl√©s :**
            - L'analyse par classe r√©v√®le des signatures de features distinctes pour chaque maladie : 
            par exemple, hog_std (texture) est extr√™mement discriminant pour Apple_scab mais beaucoup moins pour les autres maladies. 
            √Ä l'inverse, contour_density pr√©sente une importance √©lev√©e et relativement uniforme pour plusieurs maladies, indiquant 
            qu'il s'agit d'une feature g√©n√©raliste importante pour d√©tecter les anomalies foliaires. 
            Cette variabilit√© confirme que diff√©rentes maladies se manifestent par des combinaisons sp√©cifiques de caract√©ristiques visuelles.
            """)
            
        st.divider()
        st.subheader("Synth√®se des R√©sultats par Mod√®le")
        st.markdown("Comparaison finale des performances sur l'Objectif 1 (Identification de l'esp√®ce).")
        
        full_perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "Pr√©cision (macro)": [0.9271, 0.9051, 0.8462, 0.8607],
            "Rappel (macro)": [0.9207, 0.8654, 0.8214, 0.7405],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_full = pd.DataFrame(full_perf_data)
        df_melt = df_full.melt(id_vars="Mod√®le", var_name="M√©trique", value_name="Valeur")
        
        fig_full = px.bar(df_melt, x="Mod√®le", y="Valeur", color="M√©trique", barmode="group",
                          title="Comparaison Multi-M√©triques (Test Set)",
                          text_auto='.2f', color_discrete_sequence=px.colors.qualitative.Pastel)
        
        fig_full.update_layout(yaxis_range=[0.7, 1.0])
        st.plotly_chart(fig_full, use_container_width=True)
        
        st.info("**Constat** : Le **SVM (RBF)** surpasse ses concurrents sur toutes les m√©triques, confirmant sa robustesse face au d√©s√©quilibre des classes.")


def sidebar_choice():
    st.title("Machine Learning")
    render_ml_content()

