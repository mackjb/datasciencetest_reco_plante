import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import time

# =========================
# CONTENU MACHINE LEARNING
# =========================
def render_ml_content():
    st.markdown("""
    L'approche classique repose sur l'**extraction manuelle de descripteurs** (Handcrafted Features) plut√¥t que sur l'apprentissage direct des pixels. 
    Elle sert de **baseline** robuste pour comparer nos futurs mod√®les Deep Learning.
    """)
    
    # --- M√©thodologie ---
    with st.expander("üõ†Ô∏è M√©thodologie & Pipeline", expanded=True):
        col_m1, col_m2 = st.columns([1.5, 1])
        
        with col_m1:
            st.markdown("""
            **√âtapes clefs du pipeline robuste :**
            1. üì∏ **Collecte** : Images nettes et segment√©es.
            2. üìê **Extraction** : Calcul des descripteurs (Morpho, Couleur, Texture...).
            3. üßπ **Nettoyage** : Suppression des images corrompues (9 images avec NaN).
            4. üìà **Augmentation** : Enrichissement du dataset ‚Üí **91 770 images finales**.
            5. ‚öñÔ∏è **Scaling** : Normalisation **RobustScaler** (gestion des 40% d'outliers).
            6. üéØ **S√©lection** : Garder les features les plus discriminantes (SHAP).
            7. ü§ñ **Mod√©lisation** : Entra√Ænement des classifieurs.
            """)
            
        with col_m2:
            st.info("""
            **üéØ Exploration par l'√©quipe :**
            - **SVM (RBF)** : Bernadette GASMI
            - **XGBoost** : Lionel SCHNEIDER
            - **Reg. Logistique** : JB MACK
            - **Extra-Trees** : Morgan PERCHEC
            """)
        
        st.divider()
        st.info("""
        **Points cl√©s** : 
        - Split **80/10/10** stratifi√©.
        - **Data Augmentation** sur le train (91 770 images finales).
        - **RobustScaler** utilis√© pour g√©rer les 40% d'outliers d√©tect√©s.
        """)

    tabs = st.tabs(["‚öôÔ∏è Features", "üìä Performances", "üß† SHAP"])
    
    with tabs[0]:
        st.header("1. Extraction des Descripteurs")
        st.markdown("""
        **Cat√©gories extraites :**
        - üìè **Morphologie** : Aire, p√©rim√®tre, circularit√©, excentricit√©, aspect ratio, densit√© de contours
        - üé® **Couleur** : Moyennes et √âcarts-types RGB / HSV
        - üï∏Ô∏è **Texture** : Matrices de co-occurrence (GLCM) - nettet√©, contraste, energy, homogeneity, dissimilarity, correlation
        - üîÑ **Invariants** : Moments de Hu (hu_1 √† hu_7)
        - üìª **Fr√©quences** : Entropie et puissance spectrale (FFT)
        - üìê **Gradients** : Descripteurs HOG (moyenne, √©cart-type, entropie)
        
        Ces descripteurs sont concat√©n√©s pour former un **vecteur unique par image** (34 features), 
        servant ensuite d'entr√©e aux algorithmes de classification.
        """)

        st.divider()
        st.subheader("Importance des Features")
        ranking_path = "results/feature_ranking.csv"
        if os.path.exists(ranking_path):
            df_rank = pd.read_csv(ranking_path).head(15).sort_values(by="final_score", ascending=True)
            fig_rank = px.bar(df_rank, x="final_score", y="feature", orientation="h",
                               title="Top 15 des Features les plus discriminantes",
                               color="final_score", color_continuous_scale="GnBu")
            st.plotly_chart(fig_rank, use_container_width=True)
        
    with tabs[1]:
        st.header("2. Analyse des Performances")
        
        st.markdown("""
        R√©sultats obtenus pour l'**Objectif 1** (Identification de l'esp√®ce) sur l'ensemble de test.
        Nous avons compar√© **4 mod√®les principaux**.
        """)
        
        perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_perf = pd.DataFrame(perf_data)
        
        col1, col2 = st.columns([1, 1.2])
        with col1:
            st.dataframe(df_perf.style.highlight_max(axis=0))
            st.success("üèÜ **SVM (RBF)** est le plus performant.")
        
        with col2:
            fig_perf = px.bar(df_perf, x="Mod√®le", y="F1-score (macro)", color="Mod√®le",
                               title="Comparaison des F1-Scores", text_auto='.2f')
            fig_perf.update_layout(showlegend=False)
            st.plotly_chart(fig_perf, use_container_width=True)

        cm_path = "results/Machine_Learning/svm_rbf_baseline_features_selected/plots/baseline/confusion_matrix.png"
        if os.path.exists(cm_path):
            with st.expander("üîç Voir la Matrice de Confusion (SVM-RBF)"):
                st.image(cm_path, use_container_width=True)
                
    with tabs[2]:
        st.header("3. Interpr√©tabilit√© SHAP")
        
        st.markdown("""
        **Observations cl√©s :**
        - La **contour_density** domine tr√®s nettement l'importance globale (30% sup√©rieure √† la 2√®me feature)
        - Les features de **fr√©quence spectrale** (fft_entropy) et de **couleur** (mean_R, mean_B) compl√®tent le trio de t√™te
        - Chaque classe de maladie s'appuie sur un **sous-ensemble diff√©rent de features**
        - Les **34 features extraites sont toutes pertinentes**, aucune n'est totalement n√©gligeable
        """)
        
        shap_dir = "figures/shap_analysis"
        p1 = os.path.join(shap_dir, "1_global_importance.png")
        if os.path.exists(p1):
            st.image(p1, caption="Importance Globale des Features (Top 25)", use_container_width=True)
        else:
            st.warning("Graphique SHAP non trouv√©.")

        st.divider()
        st.subheader("üèÜ Synth√®se des R√©sultats par Mod√®le")
        st.markdown("Comparaison finale des performances sur l'Objectif 1 (Identification de l'esp√®ce).")
        
        full_perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "Pr√©cision (macro)": [0.9271, 0.9051, 0.8462, 0.8607],
            "Rappel (macro)": [0.9207, 0.8654, 0.8214, 0.7405],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_full = pd.DataFrame(full_perf_data)
        df_melt = df_full.melt(id_vars="Mod√®le", var_name="M√©trique", value_name="Valeur")
        
        fig_full = px.bar(df_melt, x="Mod√®le", y="Valeur", color="M√©trique", barmode="group",
                          title="Comparaison Multi-M√©triques (Test Set)",
                          text_auto='.2f', color_discrete_sequence=px.colors.qualitative.Pastel)
        
        fig_full.update_layout(yaxis_range=[0.7, 1.0])
        st.plotly_chart(fig_full, use_container_width=True)
        
        st.info("üí° **Constat** : Le **SVM (RBF)** surpasse ses concurrents sur toutes les m√©triques, confirmant sa robustesse face au d√©s√©quilibre des classes.")

# =========================
# CONTENU DEEP LEARNING
# =========================
def render_dl_content():
    st.markdown("""
    Le Deep Learning permet d'apprendre automatiquement les features directement √† partir des pixels, 
    contrairement au Machine Learning classique qui n√©cessite une extraction manuelle de descripteurs.
    """)
    
    # --- Phase d'exploration individuelle ---
    with st.expander("üë• Phase d'Exploration Individuelle", expanded=False):
        st.markdown("""
        Dans le cadre de notre formation, **chaque membre de l'√©quipe a d'abord explor√© individuellement 
        un mod√®le pr√©-entra√Æn√©** pour se familiariser avec les techniques de Deep Learning et comprendre 
        les diff√©rents d√©fis li√©s √† :
        
        - Le choix du backbone (architecture du r√©seau)
        - Le fine-tuning et le transfer learning
        - La gestion du d√©s√©quilibre des classes
        - L'optimisation des hyperparam√®tres
        - L'interpr√©tabilit√© des mod√®les
        
        Cette phase exploratoire nous a permis de **confronter la th√©orie √† la pratique** et d'acqu√©rir 
        une compr√©hension approfondie des leviers disponibles avant de nous lancer dans l'exploration 
        structur√©e des 9 architectures.
        """)
        
        
        st.markdown("### üîÑ Transfer Learning et Comparaison des Mod√®les")
        
        st.markdown("""
        Nous avons choisi d'utiliser le **transfert d'apprentissage** car les mod√®les sont d√©j√† entra√Æn√©s 
        sur des millions d'images pour d√©tecter des motifs g√©n√©riques (contours, textures, formes). 
        C'est un **gain de temps et de ressources** consid√©rable.
        """)
        
        st.markdown("**Comparatif des Mod√®les Pr√©-entra√Æn√©s Explor√©s :**")
        
        models_comparison = {
            "Caract√©ristique": ["Ann√©e", "Auteurs/Org", "Param√®tres (M)", "Taille mod√®le (MB)", 
                               "GFLOPs (224√ó224)", "GFLOPs (256√ó256)", "Taille vecteur sortie",
                               "Top-1 Acc ImageNet", "Top-5 Acc ImageNet", "Latence CPU (ms)", 
                               "Latence GPU (ms)", "Taille entr√©e", "Profondeur (layers)"],
            "EfficientNetV2-S": [2021, "Google Brain", 21.5, "~86", 8.4, "~10.8", 1280, 
                                "83.9%", "96.7%", "60-80", "5-8", "384√ó384 (optim.)", "~150"],
            "ResNet50": [2015, "Microsoft Research", 25.6, "~102", 4.1, "~5.3", 2048,
                        "76.1%", "93.0%", "40-50", "3-5", "224√ó224", "50"],
            "YOLOv8n-cls*": [2023, "Ultralytics", 2.7, "~11", 4.2, "~5.4", 1024,
                           "69.0%", "88.3%", "25-35", "2-4", "224√ó224", "~100"],
            "DenseNet-121": [2017, "Cornell/Facebook", 8.0, "~32", 2.9, "~3.7", 1024,
                           "74.4%", "92.0%", "30-40", "3-5", "224√ó224", "121"]
        }
        df_models = pd.DataFrame(models_comparison)
        
        # Transposer pour avoir les mod√®les en colonnes
        df_models_t = df_models.set_index("Caract√©ristique").T
        
        st.dataframe(df_models_t, use_container_width=True)
        
        st.success("""
        **üèÜ Choix retenu pour l'exploration des architectures : EfficientNetV2S**
        
        EfficientNetV2S offre un **excellent compromis entre performance et efficacit√©** :
        - **Pr√©cision Top-1** de 83,9% sur ImageNet, surpassant ResNet50 (76,1%) et DenseNet-121 (74,4%)
        - **21,5M param√®tres** : moins que ResNet50 (25,6M) mais plus que DenseNet-121 (8M)
        - **Efficacit√© computationnelle** remarquable : latence GPU r√©duite (5-8 ms)
        - **Pr√©cision Top-5** de 96,7%, id√©ale pour des t√¢ches de classification exigeantes
        - Adapt√© √† nos travaux n√©cessitant rapidit√© avec des ressources limit√©es
        """)
    
    # --- M√©thodologie ---
    with st.expander("üéØ M√©thodologie & Crit√®res de S√©lection", expanded=True):
        st.markdown("""
        ### D√©marche structur√©e en 3 √©tapes :
        
        1. **Exploration** : 9 architectures test√©es pour comprendre le Deep Learning et ses d√©fis
        2. **√âvaluation comparative** : Restriction √† quelques architectures couvrant 3 cas d'usage
        3. **S√©lection & Recommandation** : Projection pour un d√©ploiement r√©el
        
        ### Crit√®res de s√©lection :
        
        | Cat√©gorie | Crit√®res | Justification |
        |-----------|----------|---------------|
        | **M√©tier** | Pr√©cision (Macro-F1, Accuracy) | Capacit√© √† bien pr√©dire toutes les classes |
        | | G√©n√©ralisation (√©cart val/test) | Robustesse du mod√®le (<2% = bon, >5% = overfitting) |
        | | Couverture op√©rationnelle | R√©ponse aux 3 cas d'usage m√©tier |
        | **Technique** | Co√ªt d'inf√©rence (FLOPs, latence) | Impact sur batterie et exp√©rience utilisateur |
        | | Co√ªt d'entra√Ænement (temps, GPU) | Budget cloud et it√©rations rapides |
        | | Complexit√© (param√®tres, maintenabilit√©) | Taille du mod√®le et facilit√© de maintenance |
        | **Autres** | Interpr√©tabilit√© | Capacit√© √† expliquer les pr√©dictions (Grad-CAM) |
        | | Besoins en donn√©es | Quantit√© d'images annot√©es n√©cessaire |
        """)
        
        st.info("""
        **üéØ Les 3 cas d'usage :**
        - **Cas 1** : Identification d'esp√®ce uniquement
        - **Cas 2** : Diagnostic cibl√© (esp√®ce connue ‚Üí maladie)
        - **Cas 3** : Diagnostic complet (esp√®ce + maladie inconnues)
        """)

    # Onglets principaux DL
    dl_tabs = st.tabs(["üèóÔ∏è Architectures", "üìä Performances"])
    
    with dl_tabs[0]:
        st.header("Exploration des 9 Architectures")
        
        st.markdown("""
        **Protocole exp√©rimental commun :**
        - Dataset : PlantVillage/color
        - Backbone pr√©-entra√Æn√© : **EfficientNetV2S** (ImageNet)
        - Splits identiques pour tous les mod√®les
        - Hyperparam√®tres fix√©s : learning rate, batch size, augmentation
        - M√©triques : Loss, Accuracy, Macro-F1, matrice de confusion
        """)
        
        st.divider()
        
        
        # Pr√©sentation des architectures
        arch_info = [
            {
                "num": "1",
                "nom": "Trois mod√®les ind√©pendants",
                "desc": "3 CNN sp√©cialis√©s (species, health, disease)",
                "avantages": "Simplicit√©, performances maximales par t√¢che",
                "limites": "Triplication des ressources, pas de synergie",
                "img": "figures/architectures_dl/archi1.png"
            },
            {
                "num": "2",
                "nom": "Deux mod√®les (species + disease_extended)",
                "desc": "'Healthy' int√©gr√© comme maladie sp√©ciale",
                "avantages": "Diagnostic complet en 2 inf√©rences",
                "limites": "D√©s√©quilibre accru, perte de m√©trique binaire",
                "img": "figures/architectures_dl/archi2.png"
            },
            {
                "num": "3",
                "nom": "Mod√®le unifi√© (35 classes)",
                "desc": "√âtiquette combin√©e Esp√®ce__√âtat",
                "avantages": "Un seul mod√®le, synergie entre t√¢ches",
                "limites": "Moins flexible, classes rares sous-apprises",
                "img": "figures/architectures_dl/archi3.png"
            },
            {
                "num": "4",
                "nom": "Architecture en cascade",
                "desc": "Species ‚Üí Disease avec attention spatiale",
                "avantages": "Pr√©diction guid√©e, attention spatiale",
                "limites": "Propagation d'erreurs, latence accrue",
                "img": "figures/architectures_dl/archi4.png"
            },
            {
                "num": "5",
                "nom": "CNN + SVM",
                "desc": "Embeddings CNN + classifieurs SVM",
                "avantages": "Entra√Ænement rapide, simplicit√©",
                "limites": "Features g√©n√©riques, pas d'adaptation",
                "img": "figures/architectures_dl/archi5.png"
            },
            {
                "num": "6",
                "nom": "Multi-t√¢che unifi√© (3 t√™tes)",
                "desc": "Backbone partag√© + 3 t√™tes parall√®les",
                "avantages": "Synergie, une seule inf√©rence",
                "limites": "Conflits d'optimisation, pas de fine-tuning",
                "img": "figures/architectures_dl/archi6.png"
            },
            {
                "num": "7",
                "nom": "Multi-t√¢che 2 t√™tes + signal sant√©",
                "desc": "Species + Disease avec signal sant√© auxiliaire",
                "avantages": "Synergie, masquage des 'healthy'",
                "limites": "Pas de sortie sant√© explicite",
                "img": "figures/architectures_dl/archi7.png"
            },
            {
                "num": "8",
                "nom": "Multi-t√¢che simplifi√©",
                "desc": "Species + Disease (incluant healthy)",
                "avantages": "Simplicit√©, coh√©rence de d√©cision",
                "limites": "D√©s√©quilibre 'healthy', pas de conditionnement",
                "img": "figures/architectures_dl/archi8.png"
            },
            {
                "num": "9",
                "nom": "Architecture conditionn√©e",
                "desc": "Disease conditionn√©e par Species + Health",
                "avantages": "Conditionnement explicite, synergie",
                "limites": "Propagation d'erreurs, pas de sortie sant√©",
                "img": "figures/architectures_dl/archi9.png"
            }
        ]
        
        for arch in arch_info:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.markdown(f"**Description** : {arch['desc']}")
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
                
                with col2:
                    if os.path.exists(arch['img']):
                        st.image(arch['img'], caption=f"Sch√©ma Architecture {arch['num']}", use_container_width=True)
    
    with dl_tabs[1]:
        st.header("Synth√®se des Performances")
        
        # Tableau de performances
        perf_dl = {
            "Architecture": ["Archi 1", "Archi 2", "Archi 3", "Archi 4", "Archi 5", "Archi 6", "Archi 7", "Archi 8", "Archi 9"],
            "Species Macro-F1": [0.990, 0.990, 0.990, 0.990, 0.985, 0.988, 0.990, 0.989, 0.990],
            "Species Accuracy": [0.990, 0.990, 0.990, 0.990, 0.986, 0.988, 0.990, 0.989, 0.990],
            "Disease Accuracy": [0.990, 0.988, 0.990, 0.987, 0.982, 0.975, 0.990, 0.986, 0.990],
            "FLOPs (relatif)": ["3√ó", "2√ó", "1√ó", "2√ó", "1√ó", "1√ó", "1√ó", "1√ó", "1√ó"],
            "Maintenabilit√©": ["Faible", "Moyenne", "√âlev√©e", "Faible", "Moyenne", "Moyenne", "Moyenne", "Moyenne", "Faible"]
        }
        df_perf_dl = pd.DataFrame(perf_dl)
        
        st.dataframe(df_perf_dl.style.highlight_max(subset=["Species Macro-F1", "Species Accuracy", "Disease Accuracy"], axis=0))
        
        st.divider()
        
        st.markdown("""
        ### üéØ D√©cisions et Exclusions
        
        **Architectures exclues :**
        - **Archi 4** : Cascade complexe sans gain tangible, risque de propagation d'erreurs
        - **Archi 6** : En retrait sur la maladie (0.975 vs ‚â•0.989 pour les autres)
        - **Archi 8** : Pas de b√©n√©fice mesurable vs Archi 7/9
        
        **Architectures retenues pour recommandation :**
        - **Archi 3** : Excellente simplicit√© de d√©ploiement (1 mod√®le, 1 inf√©rence)
        - **Archi 7** : Bon compromis performance/efficience
        - **Archi 9** : Conditionnement explicite, synergie maximale
        """)
        
        # Graphique comparatif
        fig_comp = go.Figure()
        fig_comp.add_trace(go.Bar(
            name='Species Macro-F1',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Species Macro-F1'],
            marker_color='lightblue'
        ))
        fig_comp.add_trace(go.Bar(
            name='Disease Accuracy',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Disease Accuracy'],
            marker_color='lightcoral'
        ))
        fig_comp.update_layout(
            title="Comparaison des Performances par Architecture",
            yaxis_range=[0.97, 1.0],
            barmode='group'
        )
        st.plotly_chart(fig_comp, use_container_width=True)

# =========================
# FONCTION PRINCIPALE
# =========================
def sidebar_choice():
    st.title("üìä Mod√©lisation")
    
    # Cr√©ation des deux sous-onglets
    main_tabs = st.tabs(["ü§ñ Machine Learning", "üß† Deep Learning"])
    
    with main_tabs[0]:
        render_ml_content()
    
    with main_tabs[1]:
        render_dl_content()
