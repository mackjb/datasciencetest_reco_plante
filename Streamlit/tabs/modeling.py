import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import time

# =========================
# CONTENU MACHINE LEARNING
# =========================
def render_ml_content():
    st.markdown("""
    L'approche classique repose sur l'**extraction manuelle de descripteurs** (Handcrafted Features) plut√¥t que sur l'apprentissage direct des pixels. 
    Elle sert de **baseline** robuste pour comparer nos futurs mod√®les Deep Learning.
    """)
    
    # --- M√©thodologie ---
    with st.expander("üõ†Ô∏è M√©thodologie & Pipeline", expanded=True):
        col_m1, col_m2 = st.columns([1.5, 1])
        
        with col_m1:
            st.markdown("""
            **√âtapes clefs du pipeline robuste :**
            1. üì∏ **Collecte** : Images nettes et segment√©es.
            2. üìê **Extraction** : Calcul des descripteurs (Morpho, Couleur, Texture...).
            3. üßπ **Nettoyage** : Suppression des images corrompues (9 images avec NaN).
            4. üìà **Augmentation** : Enrichissement du dataset ‚Üí **91 770 images finales**.
            5. ‚öñÔ∏è **Scaling** : Normalisation **RobustScaler** (gestion des 40% d'outliers).
            6. üéØ **S√©lection** : Garder les features les plus discriminantes (SHAP).
            7. ü§ñ **Mod√©lisation** : Entra√Ænement des classifieurs.
            """)
            
        with col_m2:
            st.info("""
            **üéØ Exploration par l'√©quipe :**
            - **SVM (RBF)** : Bernadette GASMI
            - **XGBoost** : Lionel SCHNEIDER
            - **Reg. Logistique** : JB MACK
            - **Extra-Trees** : Morgan PERCHEC
            """)
        
        st.divider()
        st.info("""
        **Points cl√©s** : 
        - Split **80/10/10** stratifi√©.
        - **Data Augmentation** sur le train (91 770 images finales).
        - **RobustScaler** utilis√© pour g√©rer les 40% d'outliers d√©tect√©s.
        """)

    tabs = st.tabs(["‚öôÔ∏è Features", "üìä Performances", "üß† SHAP"])
    
    with tabs[0]:
        st.header("1. Extraction des Descripteurs")
        st.markdown("""
        **Cat√©gories extraites :**
        - üìè **Morphologie** : Aire, p√©rim√®tre, circularit√©, excentricit√©, aspect ratio, densit√© de contours
        - üé® **Couleur** : Moyennes et √âcarts-types RGB / HSV
        - üï∏Ô∏è **Texture** : Matrices de co-occurrence (GLCM) - nettet√©, contraste, energy, homogeneity, dissimilarity, correlation
        - üîÑ **Invariants** : Moments de Hu (hu_1 √† hu_7)
        - üìª **Fr√©quences** : Entropie et puissance spectrale (FFT)
        - üìê **Gradients** : Descripteurs HOG (moyenne, √©cart-type, entropie)
        
        Ces descripteurs sont concat√©n√©s pour former un **vecteur unique par image** (34 features), 
        servant ensuite d'entr√©e aux algorithmes de classification.
        """)

        st.divider()
        st.subheader("Importance des Features")
        ranking_path = "results/feature_ranking.csv"
        if os.path.exists(ranking_path):
            df_rank = pd.read_csv(ranking_path).head(15).sort_values(by="final_score", ascending=True)
            fig_rank = px.bar(df_rank, x="final_score", y="feature", orientation="h",
                               title="Top 15 des Features les plus discriminantes",
                               color="final_score", color_continuous_scale="GnBu")
            st.plotly_chart(fig_rank, use_container_width=True)
        
    with tabs[1]:
        st.header("2. Analyse des Performances")
        
        st.markdown("""
        R√©sultats obtenus pour l'**Objectif 1** (Identification de l'esp√®ce) sur l'ensemble de test.
        Nous avons compar√© **4 mod√®les principaux**.
        """)
        
        perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_perf = pd.DataFrame(perf_data)
        
        col1, col2 = st.columns([1, 1.2])
        with col1:
            st.dataframe(df_perf.style.apply(lambda x: ['background-color: yellow' if x.name == 0 else '' for _ in x], axis=1))
            st.success("üèÜ **SVM (RBF)** est le plus performant.")
        
        with col2:
            fig_perf = px.bar(df_perf, x="Mod√®le", y="F1-score (macro)", color="Mod√®le",
                               title="Comparaison des F1-Scores", text_auto='.2f')
            fig_perf.update_layout(showlegend=False)
            st.plotly_chart(fig_perf, use_container_width=True)

        cm_path = "results/Machine_Learning/svm_rbf_baseline_features_selected/plots/baseline/confusion_matrix.png"
        if os.path.exists(cm_path):
            with st.expander("üîç Voir la Matrice de Confusion (SVM-RBF)"):
                st.image(cm_path, use_container_width=True)
                
    with tabs[2]:
        st.header("3. Interpr√©tabilit√© SHAP")
        
        st.markdown("""
        **Observations cl√©s :**
        - La **contour_density** domine tr√®s nettement l'importance globale (30% sup√©rieure √† la 2√®me feature)
        - Les features de **fr√©quence spectrale** (fft_entropy) et de **couleur** (mean_R, mean_B) compl√®tent le trio de t√™te
        - Chaque classe de maladie s'appuie sur un **sous-ensemble diff√©rent de features**
        - Les **34 features extraites sont toutes pertinentes**, aucune n'est totalement n√©gligeable
        """)
        
        shap_dir = "figures/shap_analysis"
        p1 = os.path.join(shap_dir, "1_global_importance.png")
        if os.path.exists(p1):
            st.image(p1, caption="Importance Globale des Features (Top 25)", use_container_width=True)
        else:
            st.warning("Graphique SHAP non trouv√©.")

        st.divider()
        st.subheader("üèÜ Synth√®se des R√©sultats par Mod√®le")
        st.markdown("Comparaison finale des performances sur l'Objectif 1 (Identification de l'esp√®ce).")
        
        full_perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "Pr√©cision (macro)": [0.9271, 0.9051, 0.8462, 0.8607],
            "Rappel (macro)": [0.9207, 0.8654, 0.8214, 0.7405],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_full = pd.DataFrame(full_perf_data)
        df_melt = df_full.melt(id_vars="Mod√®le", var_name="M√©trique", value_name="Valeur")
        
        fig_full = px.bar(df_melt, x="Mod√®le", y="Valeur", color="M√©trique", barmode="group",
                          title="Comparaison Multi-M√©triques (Test Set)",
                          text_auto='.2f', color_discrete_sequence=px.colors.qualitative.Pastel)
        
        fig_full.update_layout(yaxis_range=[0.7, 1.0])
        st.plotly_chart(fig_full, use_container_width=True)
        
        st.info("üí° **Constat** : Le **SVM (RBF)** surpasse ses concurrents sur toutes les m√©triques, confirmant sa robustesse face au d√©s√©quilibre des classes.")

# =========================
# CONTENU DEEP LEARNING
# =========================
def render_dl_content():
    st.markdown("""
    Le Deep Learning permet d'apprendre automatiquement les features directement √† partir des pixels, 
    contrairement au Machine Learning classique qui n√©cessite une extraction manuelle de descripteurs.
    """)
    
    # --- Phase d'exploration individuelle ---
    with st.expander("üë• Phase d'Exploration Individuelle", expanded=True):
        st.markdown("""
        Dans le cadre de notre formation, **chaque membre de l'√©quipe a d'abord explor√© individuellement 
        un mod√®le pr√©-entra√Æn√©** pour se familiariser avec les techniques de Deep Learning et comprendre 
        les diff√©rents d√©fis li√©s √† :
        
        - Le choix du backbone (architecture du r√©seau)
        - Le fine-tuning et le transfer learning
        - La gestion du d√©s√©quilibre des classes
        - L'optimisation des hyperparam√®tres
        - L'interpr√©tabilit√© des mod√®les
        
        Cette phase exploratoire nous a permis de **confronter la th√©orie √† la pratique** et d'acqu√©rir 
        une compr√©hension approfondie des leviers disponibles avant de nous lancer dans l'exploration 
        structur√©e des 9 architectures.
        """)
        
        
        st.markdown("### üîÑ Transfer Learning et Comparaison des Mod√®les")
        
        st.markdown("""
        Nous avons choisi d'utiliser le **transfert d'apprentissage** car les mod√®les sont d√©j√† entra√Æn√©s 
        sur des millions d'images pour d√©tecter des motifs g√©n√©riques (contours, textures, formes). 
        C'est un **gain de temps et de ressources** consid√©rable.
        """)
        
        st.markdown("**Comparatif des Mod√®les Pr√©-entra√Æn√©s Explor√©s :**")
        
        models_comparison = {
            "Caract√©ristique": ["Ann√©e", "Auteurs/Org", "Param√®tres (M)", "Taille mod√®le (MB)", 
                               "GFLOPs (224√ó224)", "GFLOPs (256√ó256)", "Taille vecteur sortie",
                               "Top-1 Acc ImageNet", "Top-5 Acc ImageNet", "Latence CPU (ms)", 
                               "Latence GPU (ms)", "Taille entr√©e", "Profondeur (layers)"],
            "EfficientNetV2-S": [2021, "Google Brain", 21.5, "~86", 8.4, "~10.8", 1280, 
                                "83.9%", "96.7%", "60-80", "5-8", "384√ó384 (optim.)", "~150"],
            "ResNet50": [2015, "Microsoft Research", 25.6, "~102", 4.1, "~5.3", 2048,
                        "76.1%", "93.0%", "40-50", "3-5", "224√ó224", "50"],
            "YOLOv8n-cls*": [2023, "Ultralytics", 2.7, "~11", 4.2, "~5.4", 1024,
                           "69.0%", "88.3%", "25-35", "2-4", "224√ó224", "~100"],
            "DenseNet-121": [2017, "Cornell/Facebook", 8.0, "~32", 2.9, "~3.7", 1024,
                           "74.4%", "92.0%", "30-40", "3-5", "224√ó224", "121"]
        }
        df_models = pd.DataFrame(models_comparison)
        
        # Transposer pour avoir les mod√®les en colonnes
        df_models_t = df_models.set_index("Caract√©ristique").T
        
        st.dataframe(df_models_t, use_container_width=True)
        
        st.success("""
        **üèÜ Choix retenu pour l'exploration des architectures : EfficientNetV2S**
        
        EfficientNetV2S offre un **excellent compromis entre performance et efficacit√©** :
        - **Pr√©cision Top-1** de 83,9% sur ImageNet, surpassant ResNet50 (76,1%) et DenseNet-121 (74,4%)
        - **21,5M param√®tres** : moins que ResNet50 (25,6M) mais plus que DenseNet-121 (8M)
        - **Efficacit√© computationnelle** remarquable : latence GPU r√©duite (5-8 ms)
        - **Pr√©cision Top-5** de 96,7%, id√©ale pour des t√¢ches de classification exigeantes
        - Adapt√© √† nos travaux n√©cessitant rapidit√© avec des ressources limit√©es
        """)
    
    # --- M√©thodologie ---
    with st.expander("üéØ M√©thodologie & Crit√®res de S√©lection", expanded=True):
        st.markdown("""
        ### D√©marche structur√©e en 3 √©tapes :
        
        1. **Exploration** : 9 architectures test√©es pour comprendre le Deep Learning et ses d√©fis
        2. **√âvaluation comparative** : Restriction √† quelques architectures couvrant 3 cas d'usage
        3. **S√©lection & Recommandation** : Projection pour un d√©ploiement r√©el
        
        ### Crit√®res de s√©lection :
        
        | Cat√©gorie | Crit√®res | Justification |
        |-----------|----------|---------------|
        | **M√©tier** | Pr√©cision (Macro-F1, Accuracy) | Capacit√© √† bien pr√©dire toutes les classes |
        | | G√©n√©ralisation (√©cart val/test) | Robustesse du mod√®le (<2% = bon, >5% = overfitting) |
        | | Couverture op√©rationnelle | R√©ponse aux 3 cas d'usage m√©tier |
        | **Technique** | Co√ªt d'inf√©rence (FLOPs, latence) | Impact sur batterie et exp√©rience utilisateur |
        | | Co√ªt d'entra√Ænement (temps, GPU) | Budget cloud et it√©rations rapides |
        | | Complexit√© (param√®tres, maintenabilit√©) | Taille du mod√®le et facilit√© de maintenance |
        | **Autres** | Interpr√©tabilit√© | Capacit√© √† expliquer les pr√©dictions (Grad-CAM) |
        | | Besoins en donn√©es | Quantit√© d'images annot√©es n√©cessaire |
        """)
        
        st.info("""
        **üéØ Les 3 cas d'usage :**
        - **Cas 1** : Identification d'esp√®ce uniquement
        - **Cas 2** : Diagnostic cibl√© (esp√®ce connue ‚Üí maladie)
        - **Cas 3** : Diagnostic complet (esp√®ce + maladie inconnues)
        """)

    # Onglets principaux DL
    dl_tabs = st.tabs(["üèóÔ∏è Architectures", "üìä Performances"])
    
    with dl_tabs[0]:
        st.header("Exploration des 9 Architectures")
        
        st.markdown("""
        **Protocole exp√©rimental commun :**
        - Dataset : PlantVillage/color
        - Backbone pr√©-entra√Æn√© : **EfficientNetV2S** (ImageNet)
        - Splits identiques pour tous les mod√®les
        - Hyperparam√®tres fix√©s : learning rate, batch size, augmentation
        - M√©triques : Loss, Accuracy, Macro-F1, matrice de confusion
        """)
        
        st.divider()
        
        
        # Pr√©sentation des architectures
        st.markdown("### üèóÔ∏è Backbone Pr√©-entra√Æn√© D√©di√© √† Chaque Objectif")
        
        arch_info_dedicated = [
            {
                "num": "1",
                "nom": "Trois mod√®les ind√©pendants",
                "desc": "**Architecture sp√©cialis√©e** : Trois mod√®les CNN ind√©pendants, chacun d√©di√© √† une seule t√¢che (species, health, disease). Chaque mod√®le comprend un backbone pr√©-entra√Æn√© et une t√™te de classification Dense adapt√©e au nombre de classes.",
                "workflow": "Chaque mod√®le s'entra√Æne en 2 phases sur le m√™me dataset : (1) backbone gel√© avec entra√Ænement de la t√™te uniquement; (2) fine-tuning des derni√®res couches du backbone pour adapter les features ImageNet aux sp√©cificit√©s du dataset.",
                "avantages": "Simplicit√© (1 t√¢che = 1 mod√®le), absence de conflits entre t√¢ches (pas de compromis dans l'optimisation), performances maximales par t√¢che (sp√©cialisation totale), interpr√©tabilit√© facilit√©e (1 objectif clair par mod√®le).",
                "limites": "Triplication des ressources (3 backbones √† stocker et maintenir), inf√©rences multiples pour cas d'usage complexes, absence de synergie inter-t√¢ches (pas de transfert d'apprentissage entre les 3 t√™tes), temps d'entra√Ænement cumul√© plus long (3 runs).",
                "img": "figures/architectures_dl/archi1.png"
            },
            {
                "num": "2",
                "nom": "Deux mod√®les (species + disease_extended)",
                "desc": "Deux mod√®les CNN ind√©pendants : l'un pour l'esp√®ce, l'autre pour l'√©tat sanitaire complet. La classe 'healthy' est int√©gr√©e comme une maladie sp√©ciale.",
                "workflow": "Deux runs mono-t√¢che. Le mod√®le species s'entra√Æne sur toutes les images (saines + malades). Le mod√®le disease_extended s'entra√Æne √©galement sur toutes les images.",
                "avantages": "Simplicit√© (2 t√™tes), uniformit√© (deux softmax multi-classe), diagnostic complet en 2 inf√©rences (species + disease_extended), 'healthy' est un √©tat sanitaire comme les maladies.",
                "limites": "D√©s√©quilibre accru (classe 'healthy' majoritaire), perte de la m√©trique binaire explicite healthy/diseased, interpr√©tation plus ambigu√´ des pr√©dictions mixtes (ex: 40% healthy, 35% early_blight).",
                "img": "figures/architectures_dl/archi2.png"
            },
            {
                "num": "3",
                "nom": "Mod√®le unifi√© (35 classes)",
                "desc": "**Architecture unifi√©e** : Un mod√®le CNN pr√©-entra√Æn√© + 1 t√™te Dense softmax (35 classes). √âtiquette combin√©e : chaque image est √©tiquet√©e par un couple 'Esp√®ce__√âtat' (Tomato__healthy, Apple__scab‚Ä¶).",
                "workflow": "Phase 1: backbone gel√©, entra√Ænement de la t√™te uniquement. Phase 2: fine-tuning partiel des derni√®res couches du backbone. Les labels sont pr√©-combin√©s en 35 classes.",
                "avantages": "Un seul mod√®le, une seule inf√©rence : plus simple √† d√©ployer et √† utiliser. Synergie entre t√¢ches : l'apprentissage capte directement les co-d√©pendances esp√®ce‚Üîmaladie/sant√©.",
                "limites": "Moins de sp√©cialisation par t√¢che. Les classes rares peuvent √™tre sous-apprises. Peu flexible : impossible de g√©rer des paires in√©dites (nouvelle esp√®ce/maladie) sans r√©entra√Æner les 35 classes. Interpr√©tabilit√© : plus dur d'isoler l'erreur (vient-elle de l'identification d'esp√®ce ou de maladie ?).",
                "img": "figures/architectures_dl/archi3.png"
            },
            {
                "num": "4",
                "nom": "Architecture en cascade",
                "desc": "**Architecture en cascade** : Deux mod√®les CNN pr√©-entra√Æn√©s cha√Æn√©s. Un classificateur d'esp√®ce extrait un embedding et pr√©dit l'esp√®ce. Un classificateur de maladie global (21 classes, dont 'healthy') re√ßoit l'image + l'esp√®ce et applique une attention spatiale pour se focaliser sur les zones pertinentes.",
                "workflow": "Phase 1 : backbone gel√©, entra√Ænement de la t√™te. Phase 2 : fine-tuning partiel du backbone. Entra√Ænement du mod√®le maladie en 2 phases, en lui fournissant l'esp√®ce (True) en entr√©e pour stabiliser l'apprentissage. √âvaluation en CASCADE avec esp√®ce pr√©dite.",
                "avantages": "La pr√©diction d'esp√®ce guide la maladie, r√©duisant les confusions entre esp√®ces. L'attention spatiale aide √† capter les indices visuels pertinents. Modularit√© : possibilit√© d'am√©liorer s√©par√©ment esp√®ce ou maladie sans tout r√©entra√Æner.",
                "limites": "Une esp√®ce mal pr√©dite d√©grade la maladie. Le mod√®le maladie voit l'esp√®ce (True) √† l'entra√Ænement mais la pr√©dite en production. Latence accrue avec passes r√©seau successives. En cas d'esp√®ce erron√©e, une maladie impossible peut √™tre propos√©e.",
                "img": "figures/architectures_dl/archi4.png"
            }
        ]
        
        for arch in arch_info_dedicated:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                col1, col2 = st.columns([1.2, 1])
                
                with col1:
                    st.markdown(f"**Description** : {arch['desc']}")
                    st.markdown(f"**Workflow** : {arch['workflow']}")
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
                
                with col2:
                    if os.path.exists(arch['img']):
                        st.image(arch['img'], caption=f"Sch√©ma Architecture {arch['num']}", use_container_width=True)
        
        st.divider()
        st.markdown("### üîó Backbone Pr√©-entra√Æn√© Partag√© Entre Plusieurs Objectifs")
        
        arch_info_shared = [
            {
                "num": "5",
                "nom": "CNN + SVM",
                "desc": "**Architecture 'CNN + SVM'** : Un backbone CNN pr√©-entra√Æn√© (gel√©) transforme chaque image en vecteur d'embeddings (features). Des classifieurs SVM (esp√®ce, sant√©, maladie) sont entra√Æn√©s sur ces embeddings.",
                "workflow": "Sauvegarde des vecteurs + labels. Puis chargement des embeddings, entra√Ænement de trois t√™tes SVM: Esp√®ce (multi-classe), Sant√© (binaire: healthy vs diseased), Maladie (soit global multi-classe, soit par esp√®ce).",
                "avantages": "Entra√Ænement tr√®s rapide des SVM; it√©rations l√©g√®res (on r√©utilise les embeddings). Simplicit√© op√©rationnelle : s√©paration claire 'features gel√©es' / 'classifieurs'; facile de remplacer le backbone ou de r√©entra√Æner seulement les SVM.",
                "limites": "Les features restent g√©n√©riques : pas d'adaptation conjointe aux t√¢ches du dataset. Coh√©rence multi-t√¢ches limit√©e.",
                "img": "figures/architectures_dl/archi5.png"
            },
            {
                "num": "6",
                "nom": "Multi-t√¢che unifi√© (3 t√™tes)",
                "desc": "**Architecture multi-t√¢che unifi√©e** : Un seul backbone CNN pr√©-entra√Æn√© partag√© produit un embedding commun, puis trois t√™tes de classification parall√®les: Esp√®ce, Sant√©, Maladie. La t√™te 'maladie' est optimis√©e sur les images malades uniquement.",
                "workflow": "Une seule phase 't√™tes seules' avec backbone gel√© (pertes pond√©r√©es par t√™te). Pas de fine-tuning activ√©.",
                "avantages": "Les trois t√¢ches se renforcent (l'esp√®ce et la sant√© aident la maladie). Un seul backbone √† entra√Æner ; une seule inf√©rence pour obtenir esp√®ce, sant√©, maladie. Contr√¥le des compromis via pond√©rations de pertes par t√™te.",
                "limites": "Conflits d'optimisation : objectifs parfois concurrents ; sensibilit√© aux pond√©rations des pertes. Malgr√© la t√™te d√©di√©e, les maladies peu repr√©sent√©es restent difficiles. Features ImageNet peuvent rester trop g√©n√©riques (pas de fine-tuning). Couplage des t√¢ches : une mauvaise mod√©lisation de l'esp√®ce/sant√© peut impacter la maladie.",
                "img": "figures/architectures_dl/archi6.png"
            },
            {
                "num": "7",
                "nom": "Multi-t√¢che 2 t√™tes + signal sant√©",
                "desc": "**Architecture multi-t√¢che √† 2 t√™tes** : Un backbone CNN pr√©-entra√Æn√© partag√© produit un embedding commun. T√™te esp√®ce (multi-classe). T√™te maladie (multi-classe hors 'healthy', activ√©e uniquement pour √©chantillons malades). Un signal sant√© auxiliaire interne est inject√© comme feature dans la t√™te maladie.",
                "workflow": "Phase 1: entra√Ænement des t√™tes avec backbone gel√© (pond√©rations de pertes, l'√©chantillon tagu√© 'healthy' n'entra√Æne pas la t√™te maladie). Phase 2: fine-tuning partiel des couches hautes du backbone.",
                "avantages": "Une seule passe backbone pour deux t√¢ches; co√ªt d'inf√©rence r√©duit. L'injection de la probabilit√© 'malade' et le masquage de perte √©vitent que les 'healthy' perturbent la t√™te maladie. Synergie utile: l'embedding partag√© b√©n√©ficie des signaux esp√®ce et sant√© auxiliaire. Equilibre des objectifs via pond√©rations des pertes.",
                "limites": "Pas de sortie sant√© explicite: pas de score/label 'healthy vs diseased' livrable tel quel (signal interne non calibr√©). D√©pendance au signal sant√©: si le signal auxiliaire est biais√©, la t√™te maladie peut sur- ou sous-activer certaines classes. Conflits d'optimisation: sensibilit√© aux pond√©rations et au fine-tuning. Classes rares: malgr√© le masquage des 'healthy', les maladies peu repr√©sent√©es restent difficiles.",
                "img": "figures/architectures_dl/archi7.png"
            },
            {
                "num": "8",
                "nom": "Multi-t√¢che simplifi√©",
                "desc": "**Architecture multi-t√¢che simplifi√©e (2 t√™tes)** : Un seul backbone CNN pr√©-entra√Æn√© partag√©, et deux t√™tes parall√®les: Esp√®ce, Disease (incluant explicitement healthy). Pas de t√™te 'sant√©' d√©di√©e, pas de masquage : toutes les images entra√Ænent les deux t√™tes.",
                "workflow": "Phase 1: entra√Ænement des t√™tes avec backbone gel√© (pond√©rations de pertes, label smoothing). Phase 2: fine-tuning partiel du haut du backbone (option gradient clipping). Inf√©rence: une seule passe r√©seau ‚Üí deux sorties simultan√©es: Esp√®ce et Healthy/Maladie.",
                "avantages": "Simplicit√©: pas de t√™te sant√©, pas de r√®gles/mask; supervision uniforme. Efficience: un seul backbone et une seule inf√©rence pour obtenir esp√®ce + sant√©/maladie. Coh√©rence de d√©cision: healthy fait partie du m√™me espace que les maladies ‚Üí seuils et calibration unifi√©s (softmax √† 21 classes). Maintenance l√©g√®re: pipeline standardis√©.",
                "limites": "D√©s√©quilibre 'healthy': la classe healthy peut dominer et biaiser la t√™te disease_all, au d√©triment des maladies rares. Pas de conditionnement par esp√®ce: risque de confusions inter-esp√®ces. Seuils globaux: calibration potentiellement sous-optimale pour distributions tr√®s diff√©rentes selon l'esp√®ce. Shortcut possible: le mod√®le peut exploiter des corr√©lations de fond plut√¥t que des l√©sions fines.",
                "img": "figures/architectures_dl/archi8.png"
            },
            {
                "num": "9",
                "nom": "Architecture conditionn√©e",
                "desc": "**Architecture conditionn√©e (Species + Health ‚Üí Disease)** : Un backbone CNN pr√©-entra√Æn√© unique produit un embedding partag√©. T√™te esp√®ce (multi-classe). T√™te maladie (multi-classe hors 'healthy'), conditionn√©e par le vecteur de probabilit√©s d'esp√®ce et la probabilit√© interne d'√™tre malade (t√™te sant√© auxiliaire non expos√©e). Les √©chantillons 'healthy' n'entra√Ænent pas la t√™te maladie.",
                "workflow": "Phase 1: apprentissage des t√™tes avec backbone gel√©, pond√©rations de pertes. Phase 2: fine-tuning partiel des couches hautes. La t√™te maladie est optimis√©e uniquement sur les images malades (healthy masqu√©s).",
                "avantages": "Conditionnement explicite: la maladie est guid√©e par l'info d'esp√®ce et un indicateur de sant√©, r√©duisant les confusions inter-esp√®ces et focalisant sur les cas r√©ellement malades. Synergie multi-t√¢ches: l'embedding partag√© + signaux auxiliaires apportent un contexte fort. Efficience: un seul backbone; une seule inf√©rence pour obtenir esp√®ce et maladie. Contr√¥le des compromis via pond√©rations de pertes.",
                "limites": "Propagation d'erreurs: une erreur d'esp√®ce ou un biais du signal sant√© peut entra√Æner une mauvaise pr√©diction de maladie. Raccourcis/biais: le mod√®le peut sur-utiliser les a priori esp√®ce/sant√© au d√©triment d'indices visuels fins. Pas de sortie sant√© livrable: la sant√© est un signal interne. Calibrage sur 'healthy': la t√™te maladie n'est pas entra√Æn√©e sur les sains; ses sorties peuvent √™tre peu informatives pour des images r√©ellement 'healthy'.",
                "img": "figures/architectures_dl/archi9.png"
            }
        ]
        
        for arch in arch_info_shared:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                col1, col2 = st.columns([1.2, 1])
                
                with col1:
                    st.markdown(f"**Description** : {arch['desc']}")
                    st.markdown(f"**Workflow** : {arch['workflow']}")
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
                
                with col2:
                    if os.path.exists(arch['img']):
                        st.image(arch['img'], caption=f"Sch√©ma Architecture {arch['num']}", use_container_width=True)
    
    with dl_tabs[1]:
        st.header("Synth√®se des Performances")
        
        # Tableau de performances
        perf_dl = {
            "Architecture": ["Archi 1", "Archi 2", "Archi 3", "Archi 4", "Archi 5", "Archi 6", "Archi 7", "Archi 8", "Archi 9"],
            "Species Macro-F1": [0.990, 0.990, 0.990, 0.990, 0.985, 0.988, 0.990, 0.989, 0.990],
            "Species Accuracy": [0.990, 0.990, 0.990, 0.990, 0.986, 0.988, 0.990, 0.989, 0.990],
            "Disease Accuracy": [0.990, 0.988, 0.990, 0.987, 0.982, 0.975, 0.990, 0.986, 0.990],
            "FLOPs (relatif)": ["3√ó", "2√ó", "1√ó", "2√ó", "1√ó", "1√ó", "1√ó", "1√ó", "1√ó"],
            "Maintenabilit√©": ["Faible", "Moyenne", "√âlev√©e", "Faible", "Moyenne", "Moyenne", "Moyenne", "Moyenne", "Faible"]
        }
        df_perf_dl = pd.DataFrame(perf_dl)
        
        st.dataframe(df_perf_dl.style.highlight_max(subset=["Species Macro-F1", "Species Accuracy", "Disease Accuracy"], axis=0))
        
        st.divider()
        
        st.markdown("""
        ### üéØ D√©cisions et Exclusions
        
        **Architectures exclues :**
        - **Archi 4** : Cascade complexe sans gain tangible, risque de propagation d'erreurs
        - **Archi 6** : En retrait sur la maladie (0.975 vs ‚â•0.989 pour les autres)
        - **Archi 8** : Pas de b√©n√©fice mesurable vs Archi 7/9
        
        **Architectures retenues pour recommandation :**
        - **Archi 3** : Excellente simplicit√© de d√©ploiement (1 mod√®le, 1 inf√©rence)
        - **Archi 7** : Bon compromis performance/efficience
        - **Archi 9** : Conditionnement explicite, synergie maximale
        """)
        
        # Graphique comparatif
        fig_comp = go.Figure()
        fig_comp.add_trace(go.Bar(
            name='Species Macro-F1',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Species Macro-F1'],
            marker_color='lightblue'
        ))
        fig_comp.add_trace(go.Bar(
            name='Disease Accuracy',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Disease Accuracy'],
            marker_color='lightcoral'
        ))
        fig_comp.update_layout(
            title="Comparaison des Performances par Architecture",
            yaxis_range=[0.97, 1.0],
            barmode='group'
        )
        st.plotly_chart(fig_comp, use_container_width=True)

# =========================
# FONCTION PRINCIPALE
# =========================
def sidebar_choice():
    st.title("üìä Mod√©lisation")
    
    # Cr√©ation des deux sous-onglets
    main_tabs = st.tabs(["ü§ñ Machine Learning", "üß† Deep Learning"])
    
    with main_tabs[0]:
        render_ml_content()
    
    with main_tabs[1]:
        render_dl_content()
