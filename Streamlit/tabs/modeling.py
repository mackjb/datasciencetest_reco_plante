import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import time

# =========================
# CONTENU MACHINE LEARNING
# =========================
def render_ml_content():
    st.markdown("""
    L'approche classique repose sur l'**extraction manuelle de descripteurs** (Handcrafted Features) plut√¥t que sur l'apprentissage direct des pixels. 
    Elle sert de **baseline** robuste pour comparer nos futurs mod√®les Deep Learning.
    """)
    
    # --- M√©thodologie ---
    with st.expander("üõ†Ô∏è M√©thodologie & Pipeline", expanded=True):
        col_m1, col_m2 = st.columns([1.5, 1])
        
        with col_m1:
            st.markdown("""
            **√âtapes clefs du pipeline robuste :**
            1. üì∏ **Collecte** : Images nettes et segment√©es.
            2. üìê **Extraction** : Calcul des descripteurs (Morpho, Couleur, Texture...).
            3. üßπ **Nettoyage** : Suppression des images corrompues (9 images avec NaN).
            4. üìà **Augmentation** : Enrichissement du dataset ‚Üí **91 770 images finales**.
            5. ‚öñÔ∏è **Scaling** : Normalisation **RobustScaler** (gestion des 40% d'outliers).
            6. üéØ **S√©lection** : Garder les features les plus discriminantes (SHAP).
            7. ü§ñ **Mod√©lisation** : Entra√Ænement des classifieurs.
            """)
            
        with col_m2:
            st.info("""
            **üéØ Exploration par l'√©quipe :**
            - **SVM (RBF)** : Bernadette GASMI
            - **XGBoost** : Lionel SCHNEIDER
            - **Reg. Logistique** : JB MACK
            - **Extra-Trees** : Morgan PERCHEC
            """)
        
        st.divider()
        st.info("""
        **Points cl√©s** : 
        - Split **80/10/10** stratifi√©.
        - **Data Augmentation** sur le train (91 770 images finales).
        - **RobustScaler** utilis√© pour g√©rer les 40% d'outliers d√©tect√©s.
        """)

    tabs = st.tabs(["‚öôÔ∏è Features", "üìä Performances", "üß† SHAP"])
    
    with tabs[0]:
        st.header("1. Extraction des Descripteurs")
        st.markdown("""
        **Cat√©gories extraites :**
        - üìè **Morphologie** : Aire, p√©rim√®tre, circularit√©, excentricit√©, aspect ratio, densit√© de contours
        - üé® **Couleur** : Moyennes et √âcarts-types RGB / HSV
        - üï∏Ô∏è **Texture** : Matrices de co-occurrence (GLCM) - nettet√©, contraste, energy, homogeneity, dissimilarity, correlation
        - üîÑ **Invariants** : Moments de Hu (hu_1 √† hu_7)
        - üìª **Fr√©quences** : Entropie et puissance spectrale (FFT)
        - üìê **Gradients** : Descripteurs HOG (moyenne, √©cart-type, entropie)
        
        Ces descripteurs sont concat√©n√©s pour former un **vecteur unique par image** (34 features), 
        servant ensuite d'entr√©e aux algorithmes de classification.
        """)

        st.divider()
        st.subheader("Importance des Features")
        ranking_path = "results/feature_ranking.csv"
        if os.path.exists(ranking_path):
            df_rank = pd.read_csv(ranking_path).head(15).sort_values(by="final_score", ascending=True)
            fig_rank = px.bar(df_rank, x="final_score", y="feature", orientation="h",
                               title="Top 15 des Features les plus discriminantes",
                               color="final_score", color_continuous_scale="GnBu")
            st.plotly_chart(fig_rank, use_container_width=True)
        
    with tabs[1]:
        st.header("2. Analyse des Performances")
        
        st.markdown("""
        R√©sultats obtenus pour l'**Objectif 1** (Identification de l'esp√®ce) sur l'ensemble de test.
        Nous avons compar√© **4 mod√®les principaux**.
        """)
        
        perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_perf = pd.DataFrame(perf_data)
        
        col1, col2 = st.columns([1, 1.2])
        with col1:
            st.dataframe(df_perf.style.highlight_max(axis=0))
            st.success("üèÜ **SVM (RBF)** est le plus performant.")
        
        with col2:
            fig_perf = px.bar(df_perf, x="Mod√®le", y="F1-score (macro)", color="Mod√®le",
                               title="Comparaison des F1-Scores", text_auto='.2f')
            fig_perf.update_layout(showlegend=False)
            st.plotly_chart(fig_perf, use_container_width=True)

        cm_path = "results/Machine_Learning/svm_rbf_baseline_features_selected/plots/baseline/confusion_matrix.png"
        if os.path.exists(cm_path):
            with st.expander("üîç Voir la Matrice de Confusion (SVM-RBF)"):
                st.image(cm_path, use_container_width=True)
                
    with tabs[2]:
        st.header("3. Interpr√©tabilit√© SHAP")
        
        st.markdown("""
        **Observations cl√©s :**
        - La **contour_density** domine tr√®s nettement l'importance globale (30% sup√©rieure √† la 2√®me feature)
        - Les features de **fr√©quence spectrale** (fft_entropy) et de **couleur** (mean_R, mean_B) compl√®tent le trio de t√™te
        - Chaque classe de maladie s'appuie sur un **sous-ensemble diff√©rent de features**
        - Les **34 features extraites sont toutes pertinentes**, aucune n'est totalement n√©gligeable
        """)
        
        shap_dir = "figures/shap_analysis"
        p1 = os.path.join(shap_dir, "1_global_importance.png")
        if os.path.exists(p1):
            st.image(p1, caption="Importance Globale des Features (Top 25)", use_container_width=True)
        else:
            st.warning("Graphique SHAP non trouv√©.")

        st.divider()
        st.subheader("üèÜ Synth√®se des R√©sultats par Mod√®le")
        st.markdown("Comparaison finale des performances sur l'Objectif 1 (Identification de l'esp√®ce).")
        
        full_perf_data = {
            "Mod√®le": ["SVM (RBF)", "XGBoost", "Reg. Logistique", "Extra-Trees"],
            "Accuracy": [0.9370, 0.9038, 0.8615, 0.8310],
            "Pr√©cision (macro)": [0.9271, 0.9051, 0.8462, 0.8607],
            "Rappel (macro)": [0.9207, 0.8654, 0.8214, 0.7405],
            "F1-score (macro)": [0.9237, 0.8839, 0.8328, 0.7863]
        }
        df_full = pd.DataFrame(full_perf_data)
        df_melt = df_full.melt(id_vars="Mod√®le", var_name="M√©trique", value_name="Valeur")
        
        fig_full = px.bar(df_melt, x="Mod√®le", y="Valeur", color="M√©trique", barmode="group",
                          title="Comparaison Multi-M√©triques (Test Set)",
                          text_auto='.2f', color_discrete_sequence=px.colors.qualitative.Pastel)
        
        fig_full.update_layout(yaxis_range=[0.7, 1.0])
        st.plotly_chart(fig_full, use_container_width=True)
        
        st.info("üí° **Constat** : Le **SVM (RBF)** surpasse ses concurrents sur toutes les m√©triques, confirmant sa robustesse face au d√©s√©quilibre des classes.")

# =========================
# CONTENU DEEP LEARNING
# =========================
def render_dl_content():
    st.markdown("""
    Le Deep Learning permet d'apprendre automatiquement les features directement √† partir des pixels, 
    contrairement au Machine Learning classique qui n√©cessite une extraction manuelle de descripteurs.
    """)
    
    # --- M√©thodologie ---
    with st.expander("üéØ M√©thodologie & Crit√®res de S√©lection", expanded=True):
        st.markdown("""
        ### D√©marche structur√©e en 3 √©tapes :
        
        1. **Exploration** : 9 architectures test√©es pour comprendre le Deep Learning et ses d√©fis
        2. **√âvaluation comparative** : Restriction √† quelques architectures couvrant 3 cas d'usage
        3. **S√©lection & Recommandation** : Projection pour un d√©ploiement r√©el
        
        ### Crit√®res de s√©lection :
        
        | Cat√©gorie | Crit√®res | Justification |
        |-----------|----------|---------------|
        | **M√©tier** | Pr√©cision (Macro-F1, Accuracy) | Capacit√© √† bien pr√©dire toutes les classes |
        | | G√©n√©ralisation (√©cart val/test) | Robustesse du mod√®le (<2% = bon, >5% = overfitting) |
        | | Couverture op√©rationnelle | R√©ponse aux 3 cas d'usage m√©tier |
        | **Technique** | Co√ªt d'inf√©rence (FLOPs, latence) | Impact sur batterie et exp√©rience utilisateur |
        | | Co√ªt d'entra√Ænement (temps, GPU) | Budget cloud et it√©rations rapides |
        | | Complexit√© (param√®tres, maintenabilit√©) | Taille du mod√®le et facilit√© de maintenance |
        | **Autres** | Interpr√©tabilit√© | Capacit√© √† expliquer les pr√©dictions (Grad-CAM) |
        | | Besoins en donn√©es | Quantit√© d'images annot√©es n√©cessaire |
        """)
        
        st.info("""
        **üéØ Les 3 cas d'usage :**
        - **Cas 1** : Identification d'esp√®ce uniquement
        - **Cas 2** : Diagnostic cibl√© (esp√®ce connue ‚Üí maladie)
        - **Cas 3** : Diagnostic complet (esp√®ce + maladie inconnues)
        """)

    # Onglets principaux DL
    dl_tabs = st.tabs(["üèóÔ∏è Architectures", "üìä Performances", "üß¨ D√©mos Interactives"])
    
    with dl_tabs[0]:
        st.header("Exploration des 9 Architectures")
        
        st.markdown("""
        **Protocole exp√©rimental commun :**
        - Dataset : PlantVillage/color
        - Backbone pr√©-entra√Æn√© : **EfficientNetV2S** (ImageNet)
        - Splits identiques pour tous les mod√®les
        - Hyperparam√®tres fix√©s : learning rate, batch size, augmentation
        - M√©triques : Loss, Accuracy, Macro-F1, matrice de confusion
        """)
        
        st.divider()
        
        # Pr√©sentation des architectures
        arch_info = [
            {
                "num": "1",
                "nom": "Trois mod√®les ind√©pendants",
                "desc": "3 CNN sp√©cialis√©s (species, health, disease)",
                "avantages": "Simplicit√©, performances maximales par t√¢che",
                "limites": "Triplication des ressources, pas de synergie"
            },
            {
                "num": "2",
                "nom": "Deux mod√®les (species + disease_extended)",
                "desc": "'Healthy' int√©gr√© comme maladie sp√©ciale",
                "avantages": "Diagnostic complet en 2 inf√©rences",
                "limites": "D√©s√©quilibre accru, perte de m√©trique binaire"
            },
            {
                "num": "3",
                "nom": "Mod√®le unifi√© (35 classes)",
                "desc": "√âtiquette combin√©e Esp√®ce__√âtat",
                "avantages": "Un seul mod√®le, synergie entre t√¢ches",
                "limites": "Moins flexible, classes rares sous-apprises"
            },
            {
                "num": "4",
                "nom": "Architecture en cascade",
                "desc": "Species ‚Üí Disease avec attention spatiale",
                "avantages": "Pr√©diction guid√©e, attention spatiale",
                "limites": "Propagation d'erreurs, latence accrue"
            },
            {
                "num": "5",
                "nom": "CNN + SVM",
                "desc": "Embeddings CNN + classifieurs SVM",
                "avantages": "Entra√Ænement rapide, simplicit√©",
                "limites": "Features g√©n√©riques, pas d'adaptation"
            },
            {
                "num": "6",
                "nom": "Multi-t√¢che unifi√© (3 t√™tes)",
                "desc": "Backbone partag√© + 3 t√™tes parall√®les",
                "avantages": "Synergie, une seule inf√©rence",
                "limites": "Conflits d'optimisation, pas de fine-tuning"
            },
            {
                "num": "7",
                "nom": "Multi-t√¢che 2 t√™tes + signal sant√©",
                "desc": "Species + Disease avec signal sant√© auxiliaire",
                "avantages": "Synergie, masquage des 'healthy'",
                "limites": "Pas de sortie sant√© explicite"
            },
            {
                "num": "8",
                "nom": "Multi-t√¢che simplifi√©",
                "desc": "Species + Disease (incluant healthy)",
                "avantages": "Simplicit√©, coh√©rence de d√©cision",
                "limites": "D√©s√©quilibre 'healthy', pas de conditionnement"
            },
            {
                "num": "9",
                "nom": "Architecture conditionn√©e",
                "desc": "Disease conditionn√©e par Species + Health",
                "avantages": "Conditionnement explicite, synergie",
                "limites": "Propagation d'erreurs, pas de sortie sant√©"
            }
        ]
        
        for arch in arch_info:
            with st.expander(f"Architecture {arch['num']} : {arch['nom']}"):
                st.markdown(f"**Description** : {arch['desc']}")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"‚úÖ **Avantages** : {arch['avantages']}")
                with col2:
                    st.markdown(f"‚ö†Ô∏è **Limites** : {arch['limites']}")
    
    with dl_tabs[1]:
        st.header("Synth√®se des Performances")
        
        # Tableau de performances
        perf_dl = {
            "Architecture": ["Archi 1", "Archi 2", "Archi 3", "Archi 4", "Archi 5", "Archi 6", "Archi 7", "Archi 8", "Archi 9"],
            "Species Macro-F1": [0.990, 0.990, 0.990, 0.990, 0.985, 0.988, 0.990, 0.989, 0.990],
            "Species Accuracy": [0.990, 0.990, 0.990, 0.990, 0.986, 0.988, 0.990, 0.989, 0.990],
            "Disease Accuracy": [0.990, 0.988, 0.990, 0.987, 0.982, 0.975, 0.990, 0.986, 0.990],
            "FLOPs (relatif)": ["3√ó", "2√ó", "1√ó", "2√ó", "1√ó", "1√ó", "1√ó", "1√ó", "1√ó"],
            "Maintenabilit√©": ["Faible", "Moyenne", "√âlev√©e", "Faible", "Moyenne", "Moyenne", "Moyenne", "Moyenne", "Faible"]
        }
        df_perf_dl = pd.DataFrame(perf_dl)
        
        st.dataframe(df_perf_dl.style.highlight_max(subset=["Species Macro-F1", "Species Accuracy", "Disease Accuracy"], axis=0))
        
        st.divider()
        
        st.markdown("""
        ### üéØ D√©cisions et Exclusions
        
        **Architectures exclues :**
        - **Archi 4** : Cascade complexe sans gain tangible, risque de propagation d'erreurs
        - **Archi 6** : En retrait sur la maladie (0.975 vs ‚â•0.989 pour les autres)
        - **Archi 8** : Pas de b√©n√©fice mesurable vs Archi 7/9
        
        **Architectures retenues pour recommandation :**
        - **Archi 3** : Excellente simplicit√© de d√©ploiement (1 mod√®le, 1 inf√©rence)
        - **Archi 7** : Bon compromis performance/efficience
        - **Archi 9** : Conditionnement explicite, synergie maximale
        """)
        
        # Graphique comparatif
        fig_comp = go.Figure()
        fig_comp.add_trace(go.Bar(
            name='Species Macro-F1',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Species Macro-F1'],
            marker_color='lightblue'
        ))
        fig_comp.add_trace(go.Bar(
            name='Disease Accuracy',
            x=df_perf_dl['Architecture'],
            y=df_perf_dl['Disease Accuracy'],
            marker_color='lightcoral'
        ))
        fig_comp.update_layout(
            title="Comparaison des Performances par Architecture",
            yaxis_range=[0.97, 1.0],
            barmode='group'
        )
        st.plotly_chart(fig_comp, use_container_width=True)
    
    with dl_tabs[2]:
        st.header("üß¨ D√©mos Interactives")
        
        st.info("""
        üí° **Les d√©mos interactives compl√®tes sont disponibles dans l'onglet "üß† Deep Learning" de la sidebar.**
        
        Vous y trouverez :
        - **Archi 3** : 6 images de plantes malades avec diagnostic de maladies
        - **Archi 9** : 6 images de plantes saines avec identification d'esp√®ces
        - Visualisation Grad-CAM pour l'interpr√©tabilit√©
        """)
        
        st.markdown("""
        ### Aper√ßu des Architectures Retenues
        
        #### üèÜ Architecture 3 : Solution Edge/Mobile
        - **Type** : Mod√®le unifi√© (35 classes combin√©es Esp√®ce__√âtat)
        - **Avantages** : Un seul mod√®le, une seule inf√©rence, d√©ploiement simplifi√©
        - **Performance** : Species Macro-F1 = 0.990, Disease Accuracy = 0.990
        - **Cas d'usage** : Id√©al pour applications mobiles (smartphones, tablettes)
        
        #### üöÄ Architecture 9 : Solution Production Cloud
        - **Type** : Architecture conditionn√©e (Disease guid√©e par Species + Health)
        - **Avantages** : Conditionnement explicite, synergie maximale entre t√¢ches
        - **Performance** : Species Macro-F1 = 0.990, Disease Accuracy = 0.990
        - **Cas d'usage** : D√©ploiement cloud avec ressources importantes
        """)

# =========================
# FONCTION PRINCIPALE
# =========================
def sidebar_choice():
    st.title("üìä Mod√©lisation")
    
    # Cr√©ation des deux sous-onglets
    main_tabs = st.tabs(["ü§ñ Machine Learning", "üß† Deep Learning"])
    
    with main_tabs[0]:
        render_ml_content()
    
    with main_tabs[1]:
        render_dl_content()
