# TODO

JBM : JB
SL : Lionel
MP : Morgan
BG : Bernadette


dataframe √† la granularit√© Classe
- [X] Nombre de classification, images par classe pour plantvillage dans un df
- [SL] Nettoyer le graphique histograme pour lister les effectis par classe plantvillage
- [SL] Compl√©ter le df plantvillage avec les r√©solution et les extension (.jpg .png ...)

dataframe √† la granularit√© Images
- [MP] Parcourir toutes les images (segment√©es) et compter les pixel diff√©rentes du background (noir plantvillage, blanc flavia)
- [] Pourcentage des pixels non background sur la bordure 1 pixel de l'image 
- [] Choisir une m√©trique de d√©tection d'exposition de la photo, Ratio de pixels ‚Äúclipp√©s‚Äù sur une image, Moyenne et √©cart-type de la luminance, Entropie de l‚Äôhistogramme, M√©triques no-reference (NR-IQA)
- [JBM] Extraire les segments avec SAM et confronter les m√©triques plus haut 



üéØ Objectif g√©n√©ral du projet :

Utiliser le Machine Learning pour classifier efficacement des esp√®ces v√©g√©tales (Flavia) et d√©tecter des maladies (PlantVillage) √† partir d‚Äôimages, en r√©alisant une exploration rigoureuse des donn√©es, une visualisation pertinente, un pr√©traitement adapt√©, et un feature engineering efficace.

‚∏ª

üöß Backlog projet ML (Dataset Flavia & PlantVillage)

‚úÖ Partie 1 : Pr√©paration & Pr√©traitement des donn√©es
	[]	1.1 Acquisition et structuration des donn√©es
	[X]	T√©l√©charger et v√©rifier les datasets Flavia et PlantVillage.
	[X]	Cr√©er une structure claire des dossiers (par esp√®ce et maladie).
	[X]	√âvaluer la qualit√© initiale des images (format, taille).
	[]	1.2 Nettoyage et normalisation des images
	[]	Redimensionnement uniforme √† 256x256 pixels.
	[]	Filtrage Gaussien (sigma et noyau selon recommandations pr√©c√©dentes).
	[]	1.4 Augmentation des donn√©es (Data Augmentation)
	[]	Rotations, sym√©tries horizontales et verticales.
	[]	L√©gers zooms et translations.
	[]	Validation visuelle rapide.


	[]	Normalisation des pixels ([0,1]).
	[]	1.3 Gestion des images probl√©matiques
	[]	Identifier et supprimer des images corrompues ou non repr√©sentatives visuellement.
	[]	V√©rifier visuellement les √©chantillons.


‚∏ª

‚úÖ Partie 2 : Exploration des donn√©es (EDA)
	[]	2.1 Analyse descriptive des datasets
	[]	Nombre d‚Äôimages par esp√®ce/maladie.
	[]	Identification de d√©s√©quilibres (classes majoritaires/minoritaires).
	[]	2.2 Exploration statistique rapide des caract√©ristiques extraites
	[]	Calculer moyennes, m√©dianes, variances des caract√©ristiques initiales (forme, couleur, texture).
	[]	Identifier rapidement les √©ventuels NA (valeurs manquantes).
	[]	2.3 Traitement des valeurs manquantes (NA) et aberrantes (Outliers)
	[]	Imputation simple par m√©diane des NA.
	[]	D√©tection des outliers (Isolation Forest recommand√©).
	[]	Validation rapide par statistiques descriptives post-nettoyage.

‚∏ª

‚úÖ Partie 3 : Data Visualisation (EDA visuelle)
	[]	3.1 Visualisation des distributions de classes
	[]	Histogrammes / barplots du nombre d‚Äôimages par classe.
	[]	3.2 Visualisation de caract√©ristiques cl√©s
	[]	Boxplots par esp√®ce/maladie (Forme, Texture, Couleur).
	[]	Identification visuelle rapide d‚Äôoutliers via boxplot.
	[]	3.3 R√©duction de dimensionnalit√© (PCA / t-SNE) (optionnel mais recommand√©)
	[]	PCA simple pour visualiser rapidement la s√©paration des esp√®ces et maladies en 2D.
	[]	t-SNE si temps disponible pour une meilleure visualisation des groupes.

‚∏ª

‚úÖ Partie 4 : Feature Engineering
	[]	4.1 Extraction des caract√©ristiques initiales (Baseline)
	[]	Forme : Moments de Hu, Fourier descriptors, Solidity.
	[]	Texture : GLCM (contraste, √©nergie, homog√©n√©it√©), Local Binary Patterns (LBP).
	[]	Couleur : HSV (moyenne, std, histogrammes).
	[]	Venation : Densit√© contours (Canny).
	[]	4.2 Extraction des caract√©ristiques avanc√©es (am√©lioration)
	[]	Forme : Eccentricit√©, ratio Aire/P√©rim√®tre.
	[]	Texture : Filtres de Gabor.
	[]	Couleur : Skewness, Kurtosis en HSV/LAB.
	[]	Venation : √âventuellement Sobel/Laplacien avanc√©s.
	[]	4.3 S√©lection des meilleures caract√©ristiques
	[]	Utiliser Random Forest pour s√©lectionner les caract√©ristiques les plus importantes.
	[]	V√©rifier les scores d‚Äôimportance des features.
	[]	4.4 Validation du Feature Engineering
	[]	Tester rapidement (10-fold cross-validation) avec SVM ou Random Forest pour comparer performances initiales avant optimisation.

‚∏ª

üö© Livrables finaux attendus √† ce stade du projet :

‚úîÔ∏è 1. Un rapport d‚ÄôEDA (Exploratory Data Analysis) clair avec des visualisations :
	[]	Statistiques descriptives des datasets.
	[]	Visualisations (boxplots, PCA, distributions).

‚úîÔ∏è 2. Un pipeline clair et r√©utilisable de pr√©traitement des donn√©es :
	[]	Code document√© pour traitement NA et outliers.
	[]	Code pour extraction compl√®te et standardis√©e des features.

‚úîÔ∏è 3. Une matrice finale des caract√©ristiques extraites pr√™te √† √™tre utilis√©e en mod√®le ML.