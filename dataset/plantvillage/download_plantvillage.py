import os
import shutil
import sys
import subprocess
from pathlib import Path
import zipfile
from typing import Optional
import kagglehub
from PIL import Image, ImageDraw

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent / 'src'))
from helpers import PROJECT_ROOT




def duplicate_dataset_limited(src_dir, dst_dir, max_files_per_class=5):
    """
    Copie la structure de dossiers de src_dir vers dst_dir en ne gardant que max_files_per_class fichiers image par sous-dossier.
    
    Args:
        src_dir (str): chemin vers dataset source
        dst_dir (str): chemin vers dataset destination
        max_files_per_class (int): nombre max d'images √† copier par sous-dossier
    """
    os.makedirs(dst_dir, exist_ok=True)
    
    for root, dirs, files in os.walk(src_dir):
        # Calcul chemin relatif depuis src_dir
        rel_path = os.path.relpath(root, src_dir)
        # Nouveau chemin dans dst_dir
        target_dir = os.path.join(dst_dir, rel_path)
        os.makedirs(target_dir, exist_ok=True)
        
        # Filtrer uniquement fichiers images jpg/jpeg/png (en minuscules)
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        image_files = sorted(image_files)[:max_files_per_class]  # Prendre les 5 premi√®res
        
        for file in image_files:
            src_file = os.path.join(root, file)
            dst_file = os.path.join(target_dir, file)
            shutil.copy2(src_file, dst_file)  # copie avec m√©tadonn√©es

    print(f"Copie termin√©e dans {dst_dir} (max {max_files_per_class} images par dossier)")



def move_dataset_if_exists(src: Path, dst: Path) -> None:
    """
    Si src existe, le d√©place vers dst.
    - Cr√©e les dossiers parents de dst si n√©cessaire.
    - Supprime dst existant pour √©viter les conflits.
    """
    if src.exists():
        dst.parent.mkdir(parents=True, exist_ok=True)
        # if dst.exists():
        #     shutil.rmtree(dst)
        shutil.move(str(src), str(dst))
        print(f"‚úÖ D√©plac√© :\n  {src}\n‚Üí {dst}")
    else:
        print(f"‚ö†Ô∏è  R√©pertoire source introuvable : {src}")


def _has_kaggle_credentials() -> bool:
    """V√©rifie la pr√©sence de ~/.kaggle/kaggle.json"""
    return (Path.home() / ".kaggle" / "kaggle.json").is_file()


def download_with_kaggle_cli(dataset_handle: str, out_dir: Path) -> Optional[Path]:
    """
    Tente de t√©l√©charger via la CLI Kaggle si dispo et si identifiants pr√©sents.
    Retourne le chemin d'extraction si succ√®s, sinon None.
    """
    if shutil.which("kaggle") is None:
        print("‚ÑπÔ∏è  CLI Kaggle introuvable (pip install kaggle).")
        return None
    if not _has_kaggle_credentials():
        print("‚ÑπÔ∏è  Identifiants Kaggle manquants (~/.kaggle/kaggle.json).")
        return None

    out_dir.mkdir(parents=True, exist_ok=True)
    zip_path = out_dir / "plantvillage.zip"
    try:
        print("‚¨áÔ∏è  T√©l√©chargement via Kaggle CLI‚Ä¶")
        subprocess.run(
            [
                "kaggle",
                "datasets",
                "download",
                "-d",
                dataset_handle,
                "-p",
                str(out_dir),
                "-o",
            ],
            check=True,
        )
        # Trouver le .zip t√©l√©charg√©
        # La CLI nomme souvent le zip avec le slug du dataset
        candidates = list(out_dir.glob("*.zip"))
        if not candidates:
            print("‚ö†Ô∏è  Aucun fichier ZIP trouv√© apr√®s le t√©l√©chargement CLI.")
            return None
        zip_path = candidates[0]
        print(f"üì¶ ZIP t√©l√©charg√©: {zip_path}")

        # Extraire
        extract_dir = out_dir / "extracted"
        extract_dir.mkdir(parents=True, exist_ok=True)
        with zipfile.ZipFile(zip_path, 'r') as zf:
            zf.extractall(extract_dir)
        print(f"‚úÖ Archive extraite dans: {extract_dir}")
        return extract_dir
    except subprocess.CalledProcessError as e:
        print(f"‚ùå √âchec Kaggle CLI: {e}")
        return None


def create_minimal_dataset(dst_dataset: Path, classes=("sample_class_a", "sample_class_b"), images_per_class: int = 5) -> None:
    """
    Cr√©e un mini-dataset local avec quelques images factices pour permettre aux pipelines
    de fonctionner sans connexion Kaggle.
    """
    dst_dataset.mkdir(parents=True, exist_ok=True)
    w, h = 256, 256
    for idx, cls in enumerate(classes):
        cls_dir = dst_dataset / cls
        cls_dir.mkdir(parents=True, exist_ok=True)
        for i in range(images_per_class):
            img = Image.new("RGB", (w, h), color=(50 + idx * 100, 150, 50 + i * 5))
            draw = ImageDraw.Draw(img)
            draw.text((10, 10), f"{cls} #{i+1}", fill=(255, 255, 255))
            img.save(cls_dir / f"img_{i+1:02d}.png")
    print(f"‚úÖ Mini-dataset cr√©√©: {dst_dataset}")

if __name__ == "__main__":
    project_root = PROJECT_ROOT
    dst = project_root / "dataset" / "plantvillage" / "data"
    dst_dataset = dst / "plantvillage_5images"
    force = os.environ.get("FORCE_DOWNLOAD", "").lower() in ("1", "true", "yes", "on")

    # Idempotence: si d√©j√† pr√™t, sortir
    if dst_dataset.exists() and not force:
        print(f"‚ö†Ô∏è  Le dataset r√©duit existe d√©j√† √† : {dst_dataset}")
        sys.exit(0)

    # Si on force, on nettoie la destination pour √©viter les collisions de move()
    if force and dst.exists():
        print(f"‚ôªÔ∏è  FORCE_DOWNLOAD actif: suppression de {dst}")
        shutil.rmtree(dst)

    dataset_handle = "abdallahalidev/plantvillage-dataset"

    # √âtape 1: tenter KaggleHub
    download_path = None
    try:
        print("‚¨áÔ∏è  T√©l√©chargement via KaggleHub‚Ä¶")
        download_path = Path(kagglehub.dataset_download(dataset_handle))
        print("Path to dataset files:", download_path)
        dst.parent.mkdir(parents=True, exist_ok=True)
        move_dataset_if_exists(download_path, dst)
    except Exception as e:
        print(f"‚ùå KaggleHub a √©chou√©: {e}")
        # √âtape 2: tenter Kaggle CLI si possible
        cli_extract = download_with_kaggle_cli(dataset_handle, dst)
        if cli_extract is not None:
            # D√©placer le contenu extrait dans dst si besoin
            # Si la structure extraite contient d√©j√† le dossier "plantvillage dataset", on d√©place la racine
            try:
                move_dataset_if_exists(cli_extract, dst)
            except Exception as e2:
                print(f"‚ö†Ô∏è  Impossible de d√©placer depuis la CLI: {e2}")
        else:
            print("‚ö†Ô∏è  Utilisation d'un mini-dataset local de secours (pas d'acc√®s Kaggle).")
            dst.mkdir(parents=True, exist_ok=True)
            create_minimal_dataset(dst_dataset, images_per_class=5)
            sys.exit(0)

    # √âtape 3: d√©terminer la racine des images dans le dossier d√©plac√©
    src_candidate1 = dst / "plantvillage dataset"
    if src_candidate1.exists():
        src_dataset = src_candidate1
    else:
        src_dataset = dst

    # Si des sous-dossiers existent avec des images, dupliquer un √©chantillon
    has_subdirs = any((src_dataset / d).is_dir() for d in os.listdir(src_dataset)) if src_dataset.exists() else False
    if src_dataset.exists() and has_subdirs:
        duplicate_dataset_limited(src_dataset, dst_dataset, max_files_per_class=5)
    else:
        # En dernier recours, cr√©er un mini jeu factice
        create_minimal_dataset(dst_dataset, images_per_class=5)

