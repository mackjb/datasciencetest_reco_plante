{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192c238a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# IMPORTS\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/conda_env/lib/python3.11/site-packages/pandas/__init__.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _dependency \u001b[38;5;129;01min\u001b[39;00m _hard_dependencies:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_dependency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m     16\u001b[39m         _missing_dependencies.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/conda_env/lib/python3.11/site-packages/numpy/__init__.py:454\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m ta\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m matrixlib \u001b[38;5;28;01mas\u001b[39;00m _mat\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scimath \u001b[38;5;28;01mas\u001b[39;00m emath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/conda_env/lib/python3.11/site-packages/numpy/lib/__init__.py:18\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_newdoc\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Private submodules\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# load module names. See https://github.com/networkx/networkx/issues/5838\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     _arraypad_impl,\n\u001b[32m     20\u001b[39m     _arraysetops_impl,\n\u001b[32m     21\u001b[39m     _arrayterator_impl,\n\u001b[32m     22\u001b[39m     _function_base_impl,\n\u001b[32m     23\u001b[39m     _histograms_impl,\n\u001b[32m     24\u001b[39m     _index_tricks_impl,\n\u001b[32m     25\u001b[39m     _nanfunctions_impl,\n\u001b[32m     26\u001b[39m     _npyio_impl,\n\u001b[32m     27\u001b[39m     _polynomial_impl,\n\u001b[32m     28\u001b[39m     _shape_base_impl,\n\u001b[32m     29\u001b[39m     _stride_tricks_impl,\n\u001b[32m     30\u001b[39m     _twodim_base_impl,\n\u001b[32m     31\u001b[39m     _type_check_impl,\n\u001b[32m     32\u001b[39m     _ufunclike_impl,\n\u001b[32m     33\u001b[39m     _utils_impl,\n\u001b[32m     34\u001b[39m     _version,\n\u001b[32m     35\u001b[39m     array_utils,\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mformat\u001b[39m,\n\u001b[32m     37\u001b[39m     introspect,\n\u001b[32m     38\u001b[39m     mixins,\n\u001b[32m     39\u001b[39m     npyio,\n\u001b[32m     40\u001b[39m     scimath,\n\u001b[32m     41\u001b[39m     stride_tricks,\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# numpy.lib namespace members\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_arrayterator_impl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Arrayterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1032\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1131\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# IMPORTS\n",
    "# ------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------------------\n",
    "FEATURES_PATH = \"/workspaces/datasciencetest_reco_plante/dataset/plantvillage/csv/clean_data_plantvillage_segmented_all_with_features.csv\"\n",
    "SEED = 42\n",
    "\n",
    "xgb_configs = {\n",
    "    \"Baseline\": {\"n_estimators\": 200, \"learning_rate\": 0.1, \"max_depth\": 6},\n",
    "    \"Deep Trees\": {\"n_estimators\": 300, \"learning_rate\": 0.05, \"max_depth\": 10},\n",
    "    \"Shallow Trees\": {\"n_estimators\": 500, \"learning_rate\": 0.01, \"max_depth\": 3}\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CHARGEMENT DES DONNEES\n",
    "# ------------------------------------------------------\n",
    "df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "# Labels\n",
    "label_col = 'nom_maladie'\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[label_col])\n",
    "n_classes = len(le.classes_)\n",
    "print(\"Classes d√©tect√©es :\", le.classes_)\n",
    "\n",
    "# Features num√©riques\n",
    "numeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n",
    "exclude_cols = ['width_img', 'height_img', 'is_black']  # √† adapter selon besoin\n",
    "numeric_columns = [c for c in numeric_columns if c not in exclude_cols]\n",
    "\n",
    "# Remplir les NaN num√©riques par la m√©diane\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "# X final\n",
    "X = df[numeric_columns].values\n",
    "\n",
    "print(\"Shape de X :\", X.shape)\n",
    "print(\"Shape de y :\", y.shape)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# SCALER\n",
    "# ------------------------------------------------------\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# PIPELINES\n",
    "# ------------------------------------------------------\n",
    "pipelines = {\n",
    "    \"XGBoost\": X_scaled,\n",
    "    \"XGBoost + PCA\": PCA(n_components=min(50, X_scaled.shape[1]), random_state=SEED).fit_transform(X_scaled),\n",
    "    \"XGBoost + LDA\": LDA(n_components=min(n_classes-1, X_scaled.shape[1])).fit(X_scaled, y).transform(X_scaled)\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# FONCTION D'EVALUATION\n",
    "# ------------------------------------------------------\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    support = np.bincount(y_true)\n",
    "    return acc, f1_macro, f1_weighted, precision, recall, f1_per_class, support\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# BOUCLE PRINCIPALE : pipelines x configs\n",
    "# ------------------------------------------------------\n",
    "results = []\n",
    "class_results = []\n",
    "\n",
    "for config_name, params in xgb_configs.items():\n",
    "    print(f\"\\n===== Configuration : {config_name} =====\")\n",
    "    \n",
    "    for pipe_name, X_proc in pipelines.items():\n",
    "        print(f\"\\nüöÄ Pipeline: {pipe_name}\")\n",
    "        \n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_proc, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "        \n",
    "        # Validation crois√©e 5-fold\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        f1_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            smote = SMOTE(random_state=SEED)\n",
    "            X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)\n",
    "            \n",
    "            model = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=SEED, n_jobs=-1, **params)\n",
    "            model.fit(X_tr_bal, y_tr_bal)\n",
    "            \n",
    "            y_val_pred = model.predict(X_val)\n",
    "            f1_fold = f1_score(y_val, y_val_pred, average=\"weighted\")\n",
    "            f1_scores.append(f1_fold)\n",
    "        \n",
    "        f1_mean, f1_std = np.mean(f1_scores), np.std(f1_scores)\n",
    "        \n",
    "        # R√©entra√Ænement sur tout le train + SMOTE\n",
    "        smote = SMOTE(random_state=SEED)\n",
    "        X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluation globale et par classe\n",
    "        acc, f1_macro, f1_weighted, precision, recall, f1_per_class, support = evaluate_metrics(y_test, y_test_pred)\n",
    "        \n",
    "        # Stockage r√©sultats globaux\n",
    "        results.append({\n",
    "            \"Pipeline\": pipe_name,\n",
    "            \"Config\": config_name,\n",
    "            \"CV_F1_mean\": f1_mean,\n",
    "            \"CV_F1_std\": f1_std,\n",
    "            \"Test_Accuracy\": acc,\n",
    "            \"Test_F1_macro\": f1_macro,\n",
    "            \"Test_F1_weighted\": f1_weighted,\n",
    "            \"Model\": model,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_test_pred\n",
    "        })\n",
    "        \n",
    "        # Tableau par classe\n",
    "        for i, classe in enumerate(le.classes_):\n",
    "            class_results.append({\n",
    "                \"Pipeline\": pipe_name,\n",
    "                \"Config\": config_name,\n",
    "                \"Classe\": classe,\n",
    "                \"Precision\": precision[i],\n",
    "                \"Recall\": recall[i],\n",
    "                \"F1_score\": f1_per_class[i],\n",
    "                \"Support\": support[i]\n",
    "            })\n",
    "        \n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap=\"Blues\")\n",
    "        plt.title(f\"Matrice de confusion - {pipe_name} ({config_name})\")\n",
    "        plt.xlabel(\"Pr√©dictions\")\n",
    "        plt.ylabel(\"Vraies classes\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Graph des classes les moins bien pr√©dites\n",
    "        class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "        class_acc_df = pd.DataFrame({\"Classe\": le.classes_, \"Accuracy\": class_acc}).sort_values(by=\"Accuracy\")\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.barplot(x=\"Accuracy\", y=\"Classe\", data=class_acc_df, palette=\"Reds_r\")\n",
    "        plt.xlim(0,1)\n",
    "        plt.title(f\"Classes les moins bien pr√©dites - {pipe_name} ({config_name})\")\n",
    "        plt.show()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Tableau comparatif global\n",
    "# ------------------------------------------------------\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Test_F1_weighted\", ascending=False)\n",
    "print(\"\\nüìä R√©sultats globaux :\")\n",
    "print(results_df[[\"Pipeline\",\"Config\",\"CV_F1_mean\",\"CV_F1_std\",\"Test_Accuracy\",\"Test_F1_macro\",\"Test_F1_weighted\"]])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Tableau r√©capitulatif par classe\n",
    "# ------------------------------------------------------\n",
    "class_results_df = pd.DataFrame(class_results)\n",
    "print(\"\\nüìä R√©sultats par classe :\")\n",
    "print(class_results_df)\n",
    "\n",
    "# Optionnel : exporter\n",
    "results_df.to_csv(\"global_results.csv\", index=False)\n",
    "class_results_df.to_csv(\"class_results.csv\", index=False)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Top 20 features pour le meilleur mod√®le XGBoost classique\n",
    "# ------------------------------------------------------\n",
    "best_model_row = results_df.iloc[0]\n",
    "if best_model_row[\"Pipeline\"] == \"XGBoost\":\n",
    "    best_model = best_model_row[\"Model\"]\n",
    "    importances = best_model.feature_importances_\n",
    "    feat_df = pd.DataFrame({\"Feature\": numeric_columns, \"Importance\": importances}).sort_values(by=\"Importance\", ascending=False)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=feat_df.head(20))\n",
    "    plt.title(f\"Top 20 features - {best_model_row['Pipeline']} ({best_model_row['Config']})\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
