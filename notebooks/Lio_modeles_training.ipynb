{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd062900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# IMPORT DES LIBRAIRIES\n",
    "# ------------------------------------------------------\n",
    "\n",
    "import pandas as pd               # pour lire et manipuler les donn√©es tabulaires (features.csv)\n",
    "import numpy as np                # pour manipuler des tableaux num√©riques\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold  # split dataset + CV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler  # normalisation\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score  # m√©triques d'√©valuation\n",
    "from xgboost import XGBClassifier  # mod√®le XGBoost\n",
    "from imblearn.over_sampling import SMOTE  # pour g√©rer le d√©s√©quilibre\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # pour √©viter les warnings inutiles\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CONFIGURATION GENERALE (√† modifier selon ton dataset)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "FEATURES_PATH = \"data/features.csv\"   # ‚ö†Ô∏è chemin du fichier CSV contenant tes features\n",
    "TARGET_COLUMN = \"label\"               # ‚ö†Ô∏è nom de la colonne contenant la classe cible\n",
    "SEED = 42                             # graine al√©atoire pour reproductibilit√©\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CHARGEMENT DU DATASET\n",
    "# ------------------------------------------------------\n",
    "\n",
    "print(\"üì• Chargement du dataset...\")\n",
    "df = pd.read_csv(FEATURES_PATH)       # lecture du CSV dans un DataFrame pandas\n",
    "\n",
    "# S√©paration features (X) et labels (y)\n",
    "X = df.drop(columns=[TARGET_COLUMN]).values  # toutes les colonnes sauf la cible\n",
    "y = df[TARGET_COLUMN].values                 # la colonne cible (labels)\n",
    "\n",
    "print(f\"‚úÖ Dataset charg√© : {X.shape[0]} √©chantillons et {X.shape[1]} features.\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DEFINIR LES SCALERS A TESTER\n",
    "# ------------------------------------------------------\n",
    "# Chaque scaler applique une m√©thode de normalisation diff√©rente\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),  # moyenne = 0, variance = 1\n",
    "    \"MinMaxScaler\": MinMaxScaler(),      # toutes les valeurs entre 0 et 1\n",
    "    \"RobustScaler\": RobustScaler()       # moins sensible aux valeurs extr√™mes\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DEFINIR LES CONFIGURATIONS XGBOOST A TESTER\n",
    "# ------------------------------------------------------\n",
    "configs = {\n",
    "    \"Baseline\": {\"n_estimators\": 200, \"learning_rate\": 0.1, \"max_depth\": 6},\n",
    "    \"Deep Trees\": {\"n_estimators\": 300, \"learning_rate\": 0.05, \"max_depth\": 10},\n",
    "    \"Shallow Trees\": {\"n_estimators\": 500, \"learning_rate\": 0.01, \"max_depth\": 3}\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# FONCTION D'EVALUATION DU MODELE\n",
    "# ------------------------------------------------------\n",
    "def evaluate(y_true, y_pred, dataset_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Calcule et affiche Accuracy, F1-score et ROC-AUC (si applicable).\n",
    "    \"\"\"\n",
    "    # Accuracy = proportion de pr√©dictions correctes\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # F1-score pond√©r√© = √©quilibre entre pr√©cision et rappel\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # ROC-AUC = aire sous la courbe ROC (‚ö†Ô∏è calculable seulement en binaire)\n",
    "    try:\n",
    "        auc = roc_auc_score(pd.get_dummies(y_true), pd.get_dummies(y_pred), average=\"weighted\")\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    # Affichage des r√©sultats\n",
    "    print(f\"üìä {dataset_name} | Accuracy = {acc:.4f}, F1 = {f1:.4f}\", end=\"\")\n",
    "    if auc is not None:\n",
    "        print(f\", ROC-AUC = {auc:.4f}\")\n",
    "    else:\n",
    "        print(\" (ROC-AUC non calculable - multi-classes d√©tect√©)\")\n",
    "\n",
    "    return acc, f1, auc\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# BOUCLE PRINCIPALE DE TEST\n",
    "# ------------------------------------------------------\n",
    "\n",
    "results = []  # liste o√π on stocke tous les r√©sultats\n",
    "\n",
    "# Boucle sur les SCALERS\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Application du scaler sur les features\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split du dataset en TRAIN (80%) et TEST (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, stratify=y, random_state=SEED\n",
    "    )\n",
    "\n",
    "    # Boucle sur les CONFIGS XGBoost\n",
    "    for config_name, params in configs.items():\n",
    "        print(f\"\\nüöÄ Test avec {scaler_name} + Config = {config_name}\")\n",
    "\n",
    "        # Cr√©ation du mod√®le avec les param√®tres choisis\n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=SEED,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "        # VARIANTE 3 : Validation crois√©e (K-Fold)\n",
    "        # ------------------------------------------------------\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        f1_scores = []  # stocke les scores F1 de chaque fold\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "            # S√©paration du TRAIN et VALIDATION pour ce fold\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # VARIANTE 4 : Gestion d√©s√©quilibre avec SMOTE\n",
    "            # ------------------------------------------------------\n",
    "            smote = SMOTE(random_state=SEED)  # cr√©ation de l'objet SMOTE\n",
    "            X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)  # oversampling des classes rares\n",
    "\n",
    "            # Entra√Ænement du mod√®le sur donn√©es r√©√©quilibr√©es\n",
    "            model.fit(X_tr_bal, y_tr_bal)\n",
    "\n",
    "            # Pr√©dictions sur la validation\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            # Score F1 pour ce fold\n",
    "            f1_fold = f1_score(y_val, y_val_pred, average=\"weighted\")\n",
    "            f1_scores.append(f1_fold)\n",
    "\n",
    "            print(f\"   Fold {fold+1} : F1 = {f1_fold:.4f}\")\n",
    "\n",
    "        # Moyenne des scores de validation crois√©e\n",
    "        print(f\"   ‚û°Ô∏è Moyenne F1 CV = {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "        # 18. EVALUATION FINALE SUR LE TEST SET\n",
    "        # ------------------------------------------------------\n",
    "        # R√©entra√Ænement du mod√®le sur tout le TRAIN r√©√©quilibr√©\n",
    "        smote = SMOTE(random_state=SEED)\n",
    "        X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        # Pr√©dictions sur le test set\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluation compl√®te\n",
    "        acc, f1, auc = evaluate(y_test, y_test_pred, dataset_name=\"Test final\")\n",
    "\n",
    "        # Stockage du r√©sultat dans la liste\n",
    "        results.append({\n",
    "            \"Scaler\": scaler_name,\n",
    "            \"Config\": config_name,\n",
    "            \"CV_F1_mean\": np.mean(f1_scores),\n",
    "            \"CV_F1_std\": np.std(f1_scores),\n",
    "            \"Test_Accuracy\": acc,\n",
    "            \"Test_F1\": f1,\n",
    "            \"Test_AUC\": auc\n",
    "        })\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# AFFICHAGE DU TABLEAU FINAL DES RESULTATS\n",
    "# ------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Tableau comparatif des r√©sultats (toutes variantes) :\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
