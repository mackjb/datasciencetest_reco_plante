{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665af2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# IMPORT DES LIBRAIRIES\n",
    "# ------------------------------------------------------\n",
    "import pandas as pd               # pour lire et manipuler des donn√©es tabulaires (CSV)\n",
    "import numpy as np                # pour manipuler des tableaux num√©riques\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold  # pour split train/test et validation crois√©e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler  # normalisation des donn√©es\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score  # m√©triques pour √©valuer les mod√®les\n",
    "from xgboost import XGBClassifier  # mod√®le XGBoost (boosting gradient)\n",
    "from imblearn.over_sampling import SMOTE  # pour r√©√©quilibrer les classes rares\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # √©viter les warnings qui alourdissent la console\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CONFIGURATION GENERALE\n",
    "# ------------------------------------------------------\n",
    "FEATURES_PATH = \"data/features.csv\"   # chemin vers le CSV contenant les donn√©es\n",
    "TARGET_COLUMN = \"label\"               # nom de la colonne cible (√† pr√©dire)\n",
    "SEED = 42                             # graine al√©atoire pour que les r√©sultats soient reproductibles\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CHARGEMENT DU DATASET\n",
    "# ------------------------------------------------------\n",
    "print(\"üì• Chargement du dataset...\")\n",
    "df = pd.read_csv(FEATURES_PATH)  # lecture du CSV dans un DataFrame\n",
    "\n",
    "# S√©paration des features (X) et de la cible (y)\n",
    "X = df.drop(columns=[TARGET_COLUMN]).values  # toutes les colonnes sauf la cible\n",
    "y = df[TARGET_COLUMN].values                 # colonne cible\n",
    "\n",
    "print(f\"‚úÖ Dataset charg√© : {X.shape[0]} √©chantillons et {X.shape[1]} features.\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# SCALERS\n",
    "# ------------------------------------------------------\n",
    "# Les scalers transforment les donn√©es pour qu‚Äôelles soient sur la m√™me √©chelle\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),  # moyenne = 0, variance = 1\n",
    "    \"MinMaxScaler\": MinMaxScaler(),      # min = 0, max = 1\n",
    "    \"RobustScaler\": RobustScaler()       # moins sensible aux outliers\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# CONFIGURATIONS XGBOOST\n",
    "# ------------------------------------------------------\n",
    "configs = {\n",
    "    \"Baseline\": {\"n_estimators\": 200, \"learning_rate\": 0.1, \"max_depth\": 6},  # mod√®le standard\n",
    "    \"Deep Trees\": {\"n_estimators\": 300, \"learning_rate\": 0.05, \"max_depth\": 10},  # arbres profonds\n",
    "    \"Shallow Trees\": {\"n_estimators\": 500, \"learning_rate\": 0.01, \"max_depth\": 3}  # arbres peu profonds\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# FONCTION D'EVALUATION\n",
    "# ------------------------------------------------------\n",
    "def evaluate(y_true, y_pred, dataset_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Calcule et affiche :\n",
    "    - Accuracy : proportion de bonnes pr√©dictions\n",
    "    - F1-score : √©quilibre entre pr√©cision et rappel, pond√©r√© pour multi-classes\n",
    "    - ROC-AUC : performance du mod√®le pour chaque classe (si binaire ou multi-classes en one-hot)\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)  # proportion de bonnes pr√©dictions\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")  # F1-score pond√©r√© pour multi-classes\n",
    "\n",
    "    # ROC-AUC : utile pour voir la qualit√© de s√©paration des classes\n",
    "    try:\n",
    "        auc = roc_auc_score(pd.get_dummies(y_true), pd.get_dummies(y_pred), average=\"weighted\")\n",
    "    except:\n",
    "        auc = None  # si multi-classes et non applicable\n",
    "\n",
    "    # Affichage des m√©triques\n",
    "    print(f\"üìä {dataset_name} | Accuracy = {acc:.4f}, F1 = {f1:.4f}\", end=\"\")\n",
    "    if auc is not None:\n",
    "        print(f\", ROC-AUC = {auc:.4f}\")\n",
    "    else:\n",
    "        print(\" (ROC-AUC non calculable - multi-classes d√©tect√©)\")\n",
    "\n",
    "    return acc, f1, auc\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# BOUCLE PRINCIPALE\n",
    "# ------------------------------------------------------\n",
    "results = []  # liste pour stocker les r√©sultats\n",
    "\n",
    "# 1Ô∏è‚É£ Boucle sur chaque scaler\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Normalisation des donn√©es pour que toutes les features soient comparables\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split TRAIN/TEST (80%/20%) avec stratification pour conserver la proportion des classes\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, stratify=y, random_state=SEED\n",
    "    )\n",
    "\n",
    "    # 2Ô∏è‚É£ Boucle sur chaque configuration XGBoost\n",
    "    for config_name, params in configs.items():\n",
    "        print(f\"\\nüöÄ Test avec {scaler_name} + Config = {config_name}\")\n",
    "\n",
    "        # Cr√©ation du mod√®le XGBoost avec param√®tres choisis\n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,  # pour √©viter warnings\n",
    "            eval_metric=\"logloss\",    # m√©trique interne pour XGBoost\n",
    "            random_state=SEED,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "        # 3Ô∏è‚É£ Validation crois√©e (Stratified K-Fold)\n",
    "        # ------------------------------------------------------\n",
    "        # S√©pare les donn√©es d'entra√Ænement en K folds pour √©valuer le mod√®le de mani√®re robuste\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        f1_scores = []  # stocke les F1-score pour chaque fold\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "            # S√©parer le fold courant en TRAIN et VALIDATION\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            # ------------------------------------------------------\n",
    "            # 4Ô∏è‚É£ R√©√©quilibrage des classes avec SMOTE\n",
    "            # ------------------------------------------------------\n",
    "            smote = SMOTE(random_state=SEED)          # objet SMOTE\n",
    "            X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)  # cr√©ation de nouvelles instances pour classes rares\n",
    "\n",
    "            # Entra√Ænement du mod√®le sur donn√©es √©quilibr√©es\n",
    "            model.fit(X_tr_bal, y_tr_bal)\n",
    "\n",
    "            # Pr√©dictions sur le fold de validation\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            # Calcul du F1-score pour ce fold\n",
    "            f1_fold = f1_score(y_val, y_val_pred, average=\"weighted\")\n",
    "            f1_scores.append(f1_fold)\n",
    "\n",
    "            print(f\"   Fold {fold+1} : F1 = {f1_fold:.4f}\")\n",
    "\n",
    "        # Moyenne et √©cart type des scores F1 sur tous les folds\n",
    "        print(f\"   ‚û°Ô∏è Moyenne F1 CV = {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "        # 5Ô∏è‚É£ √âvaluation finale sur le TEST set\n",
    "        # ------------------------------------------------------\n",
    "        smote = SMOTE(random_state=SEED)\n",
    "        X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)  # r√©√©quilibrage sur tout le TRAIN\n",
    "        model.fit(X_train_bal, y_train_bal)  # r√©entra√Ænement sur tout le TRAIN\n",
    "\n",
    "        y_test_pred = model.predict(X_test)  # pr√©diction sur le TEST set\n",
    "\n",
    "        # √âvaluation des m√©triques sur le TEST set\n",
    "        acc, f1, auc = evaluate(y_test, y_test_pred, dataset_name=\"Test final\")\n",
    "\n",
    "        # Stockage des r√©sultats pour comparatif\n",
    "        results.append({\n",
    "            \"Scaler\": scaler_name,\n",
    "            \"Config\": config_name,\n",
    "            \"CV_F1_mean\": np.mean(f1_scores),\n",
    "            \"CV_F1_std\": np.std(f1_scores),\n",
    "            \"Test_Accuracy\": acc,\n",
    "            \"Test_F1\": f1,\n",
    "            \"Test_AUC\": auc\n",
    "        })\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# AFFICHAGE DES RESULTATS\n",
    "# ------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Tableau comparatif des r√©sultats (toutes variantes) :\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
