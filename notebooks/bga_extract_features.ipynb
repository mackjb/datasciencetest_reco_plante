{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230915b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Trouve dynamiquement la racine du projet (contenant .gitignore)\n",
    "cwd = Path.cwd()\n",
    "PROJECT_ROOT = next(p for p in (cwd, *cwd.parents) if (p / \".gitignore\").exists())\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir d√©j√† d√©fini\n",
    "# root_dir_5_img = PROJECT_ROOT/\"dataset\"/\"plantvillage\"/\"data\"/\"plantvillage_5images\"/\"segmented\"\n",
    "root_dir_img = PROJECT_ROOT/\"dataset\"/\"plantvillage\"/\"data\"/\"plantvillage dataset\"/\"segmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11070384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.measure import moments_hu\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298eb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data = pd.read_csv(\"Plant_V_Seg_clean.csv\")\n",
    "df_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b72607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea90f7",
   "metadata": {},
   "source": [
    "D√©finitions des fonctions qui extraient des caract√©ristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027d64d",
   "metadata": {},
   "source": [
    "Les caract√©ristiques extraites pour chaque image sont :\n",
    "Caract√©ristiques de forme\n",
    "Caract√©ristiques de couleur\n",
    "Caract√©ristiques de texture\n",
    "Caract√©ristiques de Densit√© de contours\n",
    "Caract√©ristiques des Moments de Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 1 : Caract√©ristiques de forme \n",
    "def extract_shape_features(gray_img, binary_thresh=127):\n",
    "    \"\"\"\n",
    "    Extrait les principales caract√©ristiques de forme √† partir d'une image\n",
    "    en niveaux de gris ou binaire.\n",
    "    \n",
    "    Params:\n",
    "    - gray_img : np.ndarray, image cv2 (grayscale ou BGR)\n",
    "    - binary_thresh : int, seuil pour la binarisation si l'image n'est pas d√©j√† binaire\n",
    "    \n",
    "    Retourne un dict avec :\n",
    "    - dimensions (w x h en pixels)\n",
    "    - aire\n",
    "    - p√©rim√®tre\n",
    "    - circularit√©\n",
    "    - excentricit√©\n",
    "    - aspect_ratio\n",
    "    \"\"\"\n",
    "    # 1. Si couleur, conversion en niveaux de gris\n",
    "    if gray_img.ndim == 3:\n",
    "        gray = cv2.cvtColor(gray_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = gray_img.copy()\n",
    "    \n",
    "    # 2. Binarisation (si image non binaire)\n",
    "    _, binary = cv2.threshold(gray, binary_thresh, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 3. Recherche des contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    # 4. Plus grand contour (suppos√© √™tre la feuille)\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # 5. Calcul de l'aire et du p√©rim√®tre\n",
    "    aire = cv2.contourArea(cnt)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    \n",
    "    # 6. Circularit√© : 4œÄ¬∑A / P¬≤\n",
    "    circularity = (4 * np.pi * aire) / (perimeter**2) if perimeter > 0 else 0\n",
    "    \n",
    "    # 7. Bo√Æte englobante et aspect ratio\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w) / float(h) if h > 0 else 0\n",
    "    \n",
    "    # 8. Excentricit√© via regionprops (sur masque labellis√©)\n",
    "    lbl = label(binary > 0)  # √©tiquette des composantes\n",
    "    props = regionprops(lbl)\n",
    "    if props:\n",
    "        # on prend la r√©gion la plus large (en surface) pour la feuille\n",
    "        largest_region = max(props, key=lambda p: p.area)\n",
    "        eccentricity = largest_region.eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "    \n",
    "    # 9. R√©sultat\n",
    "    return {\n",
    "        \"dimensions\": f\"{w}x{h}\",\n",
    "        \"aire\": float(aire),\n",
    "        \"p√©rim√®tre\": float(perimeter),\n",
    "        \"circularit√©\": float(circularity),\n",
    "        \"excentricit√©\": float(eccentricity),\n",
    "        \"aspect_ratio\": float(aspect_ratio)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 2 : Caract√©ristiques de couleur RGB (moyennes par image) car charge trop importante le PC  plante\n",
    "def extract_color_features(rgb_img):\n",
    "    R, G, B = rgb_img[:, :, 0], rgb_img[:, :, 1], rgb_img[:, :, 2]\n",
    "    return {\n",
    "        \"mean_R\": np.mean(R), \"mean_G\": np.mean(G), \"mean_B\": np.mean(B),\n",
    "        \"std_R\": np.std(R), \"std_G\": np.std(G), \"std_B\": np.std(B)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 3 : Texture via GLCM - (Matrice de Co-occurrence de Niveaux de Gris)\n",
    "def extract_texture_features(gray_img):\n",
    "    glcm = graycomatrix(gray_img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return {\n",
    "        \"contrast\": graycoprops(glcm, 'contrast')[0, 0],\n",
    "        \"energy\": graycoprops(glcm, 'energy')[0, 0],\n",
    "        \"homogeneity\": graycoprops(glcm, 'homogeneity')[0, 0],\n",
    "        \"dissimilarite\": graycoprops(glcm, 'dissimilarity')[0, 0],\n",
    "        \"Correlation\": graycoprops(glcm, 'correlation')[0, 0],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction 4 : Densit√© de contours ===\n",
    "def extract_contour_density(gray_img):\n",
    "    edges = cv2.Canny(gray_img, 100, 200)\n",
    "    return {\"contour_density\": np.sum(edges > 0) / gray_img.size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction 5 : Moments de Hu ===\n",
    "def extract_hu_moments(gray_img):\n",
    "    moments = cv2.moments(gray_img)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    hu_log = -np.sign(hu) * np.log10(np.abs(hu) + 1e-10)\n",
    "    return {\"hu_moment\": hu_log.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaaa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 6 - \n",
    "def extract_hsv_features(rgb):\n",
    "    \"\"\"\n",
    "    Extrait les moyennes des composantes HSV (Hue, Saturation, Value)\n",
    "    pour une image donn√©e.\n",
    "\n",
    "    Param√®tre :\n",
    "        image_path (str) : chemin vers l'image\n",
    "\n",
    "    Retour :\n",
    "        dict : {\n",
    "            \"mean_H\": float,  # moyenne de la teinte (0‚Äì179)\n",
    "            \"mean_S\": float,  # moyenne de la saturation (0‚Äì255)\n",
    "            \"mean_V\": float   # moyenne de la valeur/luminosit√© (0‚Äì255)\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convertir en espace HSV\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # 2. S√©parer les canaux\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # 3. Calculer les moyennes\n",
    "    return {\n",
    "        \"mean_H\": float(np.mean(h)),\n",
    "        \"mean_S\": float(np.mean(s)),\n",
    "        \"mean_V\": float(np.mean(v))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42396a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 7 - Calcule la nettet√© d'une image via la variance du Laplacien sur l'image convertie en niveaux de gris.\n",
    "def extract_sharpness_laplacian(image_path):\n",
    "    \"\"\"\n",
    "    Calcule la nettet√© d'une image via la variance du Laplacien sur l'image\n",
    "    convertie en niveaux de gris.\n",
    "\n",
    "    Param√®tre :\n",
    "        image_path (str) : chemin vers l'image\n",
    "\n",
    "    Retour :\n",
    "        dict : {\n",
    "            \"nettet√©\": float  # variance du Laplacien\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 1. Charger l'image et convertir en niveaux de gris\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    gray = np.array(img)\n",
    "\n",
    "    # 2. Appliquer le filtre Laplacien\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "    # 3. Calculer la variance du r√©sultat (mesure de nettet√©)\n",
    "    var_laplacian = float(np.var(lap))\n",
    "\n",
    "    return {\"nettet√©\": var_laplacian}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# V√©rifie √©ventuellement les lignes dupliqu√©es dans le DataFrame final (m√™mes features + m√™me label).\n",
    "def detect_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    V√©rifie les lignes dupliqu√©es dans le DataFrame (m√™mes valeurs de colonnes).\n",
    "    \"\"\"\n",
    "    print(\"\\nüîé V√©rification des doublons de lignes dans le DataFrame...\")\n",
    "    duplicated_rows = df[df.duplicated()]\n",
    "    if not duplicated_rows.empty:\n",
    "        print(f\" {len(duplicated_rows)} lignes dupliqu√©es trouv√©es.\")\n",
    "        return duplicated_rows\n",
    "    else:\n",
    "        print(\" Aucun doublon de ligne trouv√©.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454746e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction principale d'extraction ===\n",
    "\n",
    "def extract_all_features(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # 1. Chargement et conversion en RGB (format PIL)\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = img.resize(target_size)\n",
    "        rgb = np.array(img)  # uint8 [0,255]\n",
    "        \n",
    "        # 2. Conversion en niveaux de gris pour les fonctions qui en ont besoin\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)  # uint8 [0,255]\n",
    "        \n",
    "        # 3. Extraction des features par bloc (aucune normalisation)\n",
    "        shape = extract_shape_features(gray) or {}\n",
    "        color = extract_color_features(rgb)\n",
    "        texture = extract_texture_features(gray)\n",
    "        contour = extract_contour_density(gray)\n",
    "        hu = extract_hu_moments(gray)\n",
    "        features_HSV = extract_hsv_features(rgb)\n",
    "        nettete = extract_sharpness_laplacian(image_path)\n",
    "\n",
    "        # 4. Fusion des dictionnaires\n",
    "        all_features = {**shape, **color, **texture, **contour, **features_HSV, **nettete}\n",
    "        if hu and \"hu_moment\" in hu:\n",
    "            all_features.update({f\"hu_{i+1}\": hu[\"hu_moment\"][i] for i in range(7)})\n",
    "\n",
    "        return all_features\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sur {image_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_dataframe(df_raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construit un DataFrame de features √† partir de df_raw_data en appelant extract_all_features\n",
    "\n",
    "    Param√®tres\n",
    "    ----------\n",
    "    df_raw_data : pd.DataFrame\n",
    "        DataFrame contenant les colonnes :\n",
    "        - nom_plante, nom_maladie, Est_Saine, Image_Path, width, height, is_black, md5\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    pd.DataFrame\n",
    "        DataFrame pr√©par√© contenant :\n",
    "        - ID_Image (int)\n",
    "        - Est_Saine, is_black (int)\n",
    "        - aspect_ratio (float), aire (int)\n",
    "        - one-hot encodage pour nom_plante et nom_maladie\n",
    "        - toutes les features extraites par extract_all_features\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    for _, row in df_raw_data.iterrows():\n",
    "        img_path = row['Image_Path']\n",
    "        try:\n",
    "            feats = extract_all_features(img_path)\n",
    "            if feats is None:\n",
    "                continue\n",
    "\n",
    "            entry = {\n",
    "                'ID_Image': len(entries) + 1,\n",
    "                'nom_plante': row['nom_plante'],\n",
    "                'nom_maladie': row['nom_maladie'] if pd.notna(row['nom_maladie']) else 'Aucune',\n",
    "                'Est_Saine': int(row['Est_Saine']),\n",
    "                'Image_Path': img_path,\n",
    "                'width_img': int(row['width_img']),\n",
    "                'height_img': int(row['height_img']),\n",
    "                'is_black': int(row['is_black']),\n",
    "                'md5': row['md5']\n",
    "            }\n",
    "            entry.update(feats)\n",
    "            entries.append(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"[Erreur] {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "\n",
    "    # Post-traitement des features\n",
    "    df['Est_Saine'] = df['Est_Saine'].astype(int)\n",
    "    df['is_black'] = df['is_black'].astype(int)\n",
    "\n",
    "    df = pd.get_dummies(\n",
    "        df,\n",
    "        columns=['nom_plante', 'nom_maladie'],\n",
    "        prefix=['plant', 'disease'],\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "    to_drop = ['md5', 'width_img', 'height_img']\n",
    "    df.drop(columns=[col for col in to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Appliquer √† dataset ===\n",
    "reco_plant = build_feature_dataframe(df_raw_data)\n",
    "print(reco_plant.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df70f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_plant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_plant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c714fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = reco_plant[reco_plant['aire'].isna()]['ID_Image'].tolist()\n",
    "print(\"Pas de contours pour ces images :\", missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filtrer le DataFrame\n",
    "missing_df = reco_plant[reco_plant['ID_Image'].isin(missing_ids)]\n",
    "\n",
    "# 3. Pr√©parer la grille d'affichage (3 colonnes)\n",
    "n = len(missing_df)\n",
    "cols = 3\n",
    "rows = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "\n",
    "# 4. Parcourir et afficher\n",
    "for ax, (_, row) in zip(axes.flatten(), missing_df.iterrows()):\n",
    "    img_id = row['ID_Image']\n",
    "    path   = row['Image_Path']\n",
    "    # Charger l'image\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        ax.text(0.5, 0.5, f\"Fichier non trouv√©\\n{path}\", \n",
    "                ha='center', va='center', color='red')\n",
    "    else:\n",
    "        # Convertir BGR ‚Üí RGB pour matplotlib\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "    ax.set_title(f\"ID_Image = {img_id}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# 5. Masquer les subplots vides\n",
    "for ax in axes.flatten()[n:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66039217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage du DataFrame pour retirer ces lignes\n",
    "df_clean = reco_plant[~reco_plant['ID_Image'].isin(missing_ids)].reset_index(drop=True)\n",
    "\n",
    "# 3. (Optionnel) V√©rifier qu‚Äôils ont bien disparu\n",
    "print(\"Ancien nombre de lignes :\", len(reco_plant))\n",
    "print(\"Nouveau nombre de lignes :\", len(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"Plant_V_Seg_all_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
