{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230915b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Trouve dynamiquement la racine du projet (contenant .gitignore)\n",
    "cwd = Path.cwd()\n",
    "PROJECT_ROOT = next(p for p in (cwd, *cwd.parents) if (p / \".gitignore\").exists())\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir déjà défini\n",
    "# root_dir_5_img = PROJECT_ROOT/\"dataset\"/\"plantvillage\"/\"data\"/\"plantvillage_5images\"/\"segmented\"\n",
    "root_dir_img = PROJECT_ROOT/\"dataset\"/\"plantvillage\"/\"data\"/\"plantvillage dataset\"/\"segmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11070384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.measure import moments_hu\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298eb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data = pd.read_csv(\"Plant_V_Seg_clean.csv\")\n",
    "df_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b72607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea90f7",
   "metadata": {},
   "source": [
    "Définitions des fonctions qui extraient des caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027d64d",
   "metadata": {},
   "source": [
    "Les caractéristiques extraites pour chaque image sont :\n",
    "Caractéristiques de forme\n",
    "Caractéristiques de couleur\n",
    "Caractéristiques de texture\n",
    "Caractéristiques de Densité de contours\n",
    "Caractéristiques des Moments de Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 1 : Caractéristiques de forme \n",
    "def extract_shape_features(gray_img, binary_thresh=127):\n",
    "    \"\"\"\n",
    "    Extrait les principales caractéristiques de forme à partir d'une image\n",
    "    en niveaux de gris ou binaire.\n",
    "    \n",
    "    Params:\n",
    "    - gray_img : np.ndarray, image cv2 (grayscale ou BGR)\n",
    "    - binary_thresh : int, seuil pour la binarisation si l'image n'est pas déjà binaire\n",
    "    \n",
    "    Retourne un dict avec :\n",
    "    - dimensions (w x h en pixels)\n",
    "    - aire\n",
    "    - périmètre\n",
    "    - circularité\n",
    "    - excentricité\n",
    "    - aspect_ratio\n",
    "    \"\"\"\n",
    "    # 1. Si couleur, conversion en niveaux de gris\n",
    "    if gray_img.ndim == 3:\n",
    "        gray = cv2.cvtColor(gray_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = gray_img.copy()\n",
    "    \n",
    "    # 2. Binarisation (si image non binaire)\n",
    "    _, binary = cv2.threshold(gray, binary_thresh, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 3. Recherche des contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    # 4. Plus grand contour (supposé être la feuille)\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # 5. Calcul de l'aire et du périmètre\n",
    "    aire = cv2.contourArea(cnt)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    \n",
    "    # 6. Circularité : 4π·A / P²\n",
    "    circularity = (4 * np.pi * aire) / (perimeter**2) if perimeter > 0 else 0\n",
    "    \n",
    "    # 7. Boîte englobante et aspect ratio\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w) / float(h) if h > 0 else 0\n",
    "    \n",
    "    # 8. Excentricité via regionprops (sur masque labellisé)\n",
    "    lbl = label(binary > 0)  # étiquette des composantes\n",
    "    props = regionprops(lbl)\n",
    "    if props:\n",
    "        # on prend la région la plus large (en surface) pour la feuille\n",
    "        largest_region = max(props, key=lambda p: p.area)\n",
    "        eccentricity = largest_region.eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "    \n",
    "    # 9. Résultat\n",
    "    return {\n",
    "        \"dimensions\": f\"{w}x{h}\",\n",
    "        \"aire\": float(aire),\n",
    "        \"périmètre\": float(perimeter),\n",
    "        \"circularité\": float(circularity),\n",
    "        \"excentricité\": float(eccentricity),\n",
    "        \"aspect_ratio\": float(aspect_ratio)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 2 : Caractéristiques de couleur RGB (moyennes par image) car charge trop importante le PC  plante\n",
    "def extract_color_features(rgb_img):\n",
    "    R, G, B = rgb_img[:, :, 0], rgb_img[:, :, 1], rgb_img[:, :, 2]\n",
    "    return {\n",
    "        \"mean_R\": np.mean(R), \"mean_G\": np.mean(G), \"mean_B\": np.mean(B),\n",
    "        \"std_R\": np.std(R), \"std_G\": np.std(G), \"std_B\": np.std(B)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 3 : Texture via GLCM - (Matrice de Co-occurrence de Niveaux de Gris)\n",
    "def extract_texture_features(gray_img):\n",
    "    glcm = graycomatrix(gray_img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return {\n",
    "        \"contrast\": graycoprops(glcm, 'contrast')[0, 0],\n",
    "        \"energy\": graycoprops(glcm, 'energy')[0, 0],\n",
    "        \"homogeneity\": graycoprops(glcm, 'homogeneity')[0, 0],\n",
    "        \"dissimilarite\": graycoprops(glcm, 'dissimilarity')[0, 0],\n",
    "        \"Correlation\": graycoprops(glcm, 'correlation')[0, 0],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction 4 : Densité de contours ===\n",
    "def extract_contour_density(gray_img):\n",
    "    edges = cv2.Canny(gray_img, 100, 200)\n",
    "    return {\"contour_density\": np.sum(edges > 0) / gray_img.size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction 5 : Moments de Hu ===\n",
    "def extract_hu_moments(gray_img):\n",
    "    moments = cv2.moments(gray_img)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    hu_log = -np.sign(hu) * np.log10(np.abs(hu) + 1e-10)\n",
    "    return {\"hu_moment\": hu_log.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaaa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 6 - \n",
    "def extract_hsv_features(rgb):\n",
    "    \"\"\"\n",
    "    Extrait les moyennes des composantes HSV (Hue, Saturation, Value)\n",
    "    pour une image donnée.\n",
    "\n",
    "    Paramètre :\n",
    "        image_path (str) : chemin vers l'image\n",
    "\n",
    "    Retour :\n",
    "        dict : {\n",
    "            \"mean_H\": float,  # moyenne de la teinte (0–179)\n",
    "            \"mean_S\": float,  # moyenne de la saturation (0–255)\n",
    "            \"mean_V\": float   # moyenne de la valeur/luminosité (0–255)\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convertir en espace HSV\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # 2. Séparer les canaux\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # 3. Calculer les moyennes\n",
    "    return {\n",
    "        \"mean_H\": float(np.mean(h)),\n",
    "        \"mean_S\": float(np.mean(s)),\n",
    "        \"mean_V\": float(np.mean(v))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42396a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction 7 - Calcule la netteté d'une image via la variance du Laplacien sur l'image convertie en niveaux de gris.\n",
    "def extract_sharpness_laplacian(image_path):\n",
    "    \"\"\"\n",
    "    Calcule la netteté d'une image via la variance du Laplacien sur l'image\n",
    "    convertie en niveaux de gris.\n",
    "\n",
    "    Paramètre :\n",
    "        image_path (str) : chemin vers l'image\n",
    "\n",
    "    Retour :\n",
    "        dict : {\n",
    "            \"netteté\": float  # variance du Laplacien\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 1. Charger l'image et convertir en niveaux de gris\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    gray = np.array(img)\n",
    "\n",
    "    # 2. Appliquer le filtre Laplacien\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "    # 3. Calculer la variance du résultat (mesure de netteté)\n",
    "    var_laplacian = float(np.var(lap))\n",
    "\n",
    "    return {\"netteté\": var_laplacian}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vérifie éventuellement les lignes dupliquées dans le DataFrame final (mêmes features + même label).\n",
    "def detect_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Vérifie les lignes dupliquées dans le DataFrame (mêmes valeurs de colonnes).\n",
    "    \"\"\"\n",
    "    print(\"\\n🔎 Vérification des doublons de lignes dans le DataFrame...\")\n",
    "    duplicated_rows = df[df.duplicated()]\n",
    "    if not duplicated_rows.empty:\n",
    "        print(f\" {len(duplicated_rows)} lignes dupliquées trouvées.\")\n",
    "        return duplicated_rows\n",
    "    else:\n",
    "        print(\" Aucun doublon de ligne trouvé.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454746e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fonction principale d'extraction ===\n",
    "\n",
    "def extract_all_features(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # 1. Chargement et conversion en RGB (format PIL)\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = img.resize(target_size)\n",
    "        rgb = np.array(img)  # uint8 [0,255]\n",
    "        \n",
    "        # 2. Conversion en niveaux de gris pour les fonctions qui en ont besoin\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)  # uint8 [0,255]\n",
    "        \n",
    "        # 3. Extraction des features par bloc (aucune normalisation)\n",
    "        shape = extract_shape_features(gray) or {}\n",
    "        color = extract_color_features(rgb)\n",
    "        texture = extract_texture_features(gray)\n",
    "        contour = extract_contour_density(gray)\n",
    "        hu = extract_hu_moments(gray)\n",
    "        features_HSV = extract_hsv_features(rgb)\n",
    "        nettete = extract_sharpness_laplacian(image_path)\n",
    "\n",
    "        # 4. Fusion des dictionnaires\n",
    "        all_features = {**shape, **color, **texture, **contour, **features_HSV, **nettete}\n",
    "        if hu and \"hu_moment\" in hu:\n",
    "            all_features.update({f\"hu_{i+1}\": hu[\"hu_moment\"][i] for i in range(7)})\n",
    "\n",
    "        return all_features\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sur {image_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_dataframe(df_raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construit un DataFrame de features à partir de df_raw_data en appelant extract_all_features\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df_raw_data : pd.DataFrame\n",
    "        DataFrame contenant les colonnes :\n",
    "        - nom_plante, nom_maladie, Est_Saine, Image_Path, width, height, is_black, md5\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    pd.DataFrame\n",
    "        DataFrame préparé contenant :\n",
    "        - ID_Image (int)\n",
    "        - Est_Saine, is_black (int)\n",
    "        - aspect_ratio (float), aire (int)\n",
    "        - one-hot encodage pour nom_plante et nom_maladie\n",
    "        - toutes les features extraites par extract_all_features\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    for _, row in df_raw_data.iterrows():\n",
    "        img_path = row['Image_Path']\n",
    "        try:\n",
    "            feats = extract_all_features(img_path)\n",
    "            if feats is None:\n",
    "                continue\n",
    "\n",
    "            entry = {\n",
    "                'ID_Image': len(entries) + 1,\n",
    "                'nom_plante': row['nom_plante'],\n",
    "                'nom_maladie': row['nom_maladie'] if pd.notna(row['nom_maladie']) else 'Aucune',\n",
    "                'Est_Saine': int(row['Est_Saine']),\n",
    "                'Image_Path': img_path,\n",
    "                'width_img': int(row['width_img']),\n",
    "                'height_img': int(row['height_img']),\n",
    "                'is_black': int(row['is_black']),\n",
    "                'md5': row['md5']\n",
    "            }\n",
    "            entry.update(feats)\n",
    "            entries.append(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"[Erreur] {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "\n",
    "    # Post-traitement des features\n",
    "    df['Est_Saine'] = df['Est_Saine'].astype(int)\n",
    "    df['is_black'] = df['is_black'].astype(int)\n",
    "\n",
    "    df = pd.get_dummies(\n",
    "        df,\n",
    "        columns=['nom_plante', 'nom_maladie'],\n",
    "        prefix=['plant', 'disease'],\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "    to_drop = ['md5', 'width_img', 'height_img']\n",
    "    df.drop(columns=[col for col in to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Appliquer à dataset ===\n",
    "reco_plant = build_feature_dataframe(df_raw_data)\n",
    "print(reco_plant.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df70f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_plant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_plant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c714fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = reco_plant[reco_plant['aire'].isna()]['ID_Image'].tolist()\n",
    "print(\"Pas de contours pour ces images :\", missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filtrer le DataFrame\n",
    "missing_df = reco_plant[reco_plant['ID_Image'].isin(missing_ids)]\n",
    "\n",
    "# 3. Préparer la grille d'affichage (3 colonnes)\n",
    "n = len(missing_df)\n",
    "cols = 3\n",
    "rows = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "\n",
    "# 4. Parcourir et afficher\n",
    "for ax, (_, row) in zip(axes.flatten(), missing_df.iterrows()):\n",
    "    img_id = row['ID_Image']\n",
    "    path   = row['Image_Path']\n",
    "    # Charger l'image\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        ax.text(0.5, 0.5, f\"Fichier non trouvé\\n{path}\", \n",
    "                ha='center', va='center', color='red')\n",
    "    else:\n",
    "        # Convertir BGR → RGB pour matplotlib\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "    ax.set_title(f\"ID_Image = {img_id}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# 5. Masquer les subplots vides\n",
    "for ax in axes.flatten()[n:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66039217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage du DataFrame pour retirer ces lignes\n",
    "df_clean = reco_plant[~reco_plant['ID_Image'].isin(missing_ids)].reset_index(drop=True)\n",
    "\n",
    "# 3. (Optionnel) Vérifier qu’ils ont bien disparu\n",
    "print(\"Ancien nombre de lignes :\", len(reco_plant))\n",
    "print(\"Nouveau nombre de lignes :\", len(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"Plant_V_Seg_all_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
