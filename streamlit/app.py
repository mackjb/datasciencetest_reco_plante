import streamlit as st
from pathlib import Path
import sys
import pandas as pd
import numpy as np
import altair as alt
from PIL import Image
import time
import joblib
import json
from sklearn.preprocessing import LabelEncoder

# Chemin racine du projet (1 niveau au-dessus de ce fichier : streamlit/app.py)
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from generate_clean_with_feature_csv import extract_all_features

# -------------------------
# Config
# -------------------------
st.set_page_config(
    page_title="Reconnaissance des plantes",
    page_icon="üåø",
    layout="wide"
)

# -------------------------
# State
# -------------------------
def init_state():
    if "demo_mode" not in st.session_state:
        st.session_state.demo_mode = False
    if "step" not in st.session_state:
        st.session_state.step = 0

# -------------------------
# Helpers
# -------------------------
@st.cache_data
def load_assets():
    """
    Chargement des assets : csv, images exemples, labels, etc.
    Retourne des objets Python (df, dict, listes...)
    """
    # Exemple :
    # df_features = pd.read_csv("data/features.csv")
    data_path = PROJECT_ROOT / "dataset/plantvillage/csv/fe_v1_clean_data_plantvillage_segmented_all_with_features.csv"
    df_features = None
    if data_path.exists():
        df_features = pd.read_csv(data_path)
    return df_features


@st.cache_data
def load_ml_artifacts():
    base = PROJECT_ROOT / "mlruns_MP_TESTS/207635128570842590/7b71c5048a294231a9fceac5b502176b"
    artifacts = {
        "metrics": {},
        "confusion_png": None,
        "per_class_f1_png": None,
        "classification_report": None,
    }

    if not base.exists():
        return artifacts

    metrics_dir = base / "metrics"
    for name in [
        "test_f1_macro",
        "test_balanced_accuracy",
        "cv_f1_macro_mean",
        "cv_bal_acc_mean",
    ]:
        path = metrics_dir / name
        if path.exists():
            try:
                value = float(path.read_text().strip())
                artifacts["metrics"][name] = value
            except Exception:
                continue

    cm_png = base / "artifacts/eval/confusion_matrix_norm.png"
    if cm_png.exists():
        artifacts["confusion_png"] = str(cm_png)

    f1_png = base / "artifacts/eval/per_class_f1.png"
    if f1_png.exists():
        artifacts["per_class_f1_png"] = str(f1_png)

    report_txt = base / "artifacts/eval/classification_report.txt"
    if report_txt.exists():
        try:
            artifacts["classification_report"] = report_txt.read_text(encoding="utf-8")
        except Exception:
            artifacts["classification_report"] = report_txt.read_text(errors="ignore")

    return artifacts


@st.cache_resource
def load_xgb_model():
    model_path = PROJECT_ROOT / "mlruns_MP_TESTS/207635128570842590/7b71c5048a294231a9fceac5b502176b/artifacts/model/model.pkl"
    if not model_path.exists():
        return None
    try:
        return joblib.load(model_path)
    except Exception:
        return None


@st.cache_data
def load_feature_names():
    feats_path = PROJECT_ROOT / "mlruns_MP_TESTS/207635128570842590/7b71c5048a294231a9fceac5b502176b/artifacts/data/features.json"
    if feats_path.exists():
        try:
            return json.loads(feats_path.read_text(encoding="utf-8"))
        except Exception:
            pass
    return []


@st.cache_data
def load_species_label_encoder():
    df = load_assets()
    if df is None or "nom_plante" not in df.columns:
        return None
    le = LabelEncoder()
    le.fit(df["nom_plante"].astype(str))
    return le


def build_features_from_image(pil_image: Image.Image) -> pd.DataFrame:
    """Extraire les features tabulaires √† partir d'une image PIL.

    Utilise la m√™me logique que le pipeline de feature engineering (224x224 + extract_all_features).
    """
    w, h = pil_image.size
    img_resized = pil_image.resize((224, 224))
    rgb = np.array(img_resized.convert("RGB"))
    feats = extract_all_features(rgb)

    feature_names = load_feature_names()
    if not feature_names:
        feature_names = sorted(feats.keys())

    # Compl√©ter avec des m√©tadonn√©es simples si attendues par le mod√®le
    if "width_img" in feature_names:
        feats["width_img"] = float(w)
    if "height_img" in feature_names:
        feats["height_img"] = float(h)

    row = {name: float(feats.get(name, 0.0)) for name in feature_names}
    return pd.DataFrame([row], columns=feature_names)


def header(title, subtitle=None):
    col1, col2 = st.columns([0.75, 0.25])
    with col1:
        st.title(title)
        if subtitle:
            st.caption(subtitle)
    with col2:
        st.markdown("")


# -------------------------
# Pages
# -------------------------
def page_home():
    header("üåø Reconnaissance des plantes", "D√©mo Streamlit pour la soutenance")

    st.markdown("""
**Objectif :** √† partir d‚Äôune photo de feuille :
- Identifier l‚Äôesp√®ce
- D√©terminer si la plante est saine ou malade
- Identifier la maladie si n√©cessaire
""")

    c1, c2, c3 = st.columns(3)
    c1.info("üìå **Contexte** : diagnostic rapide & assistance terrain")
    c2.info("üß† **IA** : ML (features) vs DL (CNN / transfert)")
    c3.info("üöÄ **D√©ploiement** : app interactive ‚Üí usage r√©el")

    st.markdown("---")
    st.subheader("üéØ Message cl√©")
    st.write("Dataset contr√¥l√© (type PlantVillage) ‚Üí tr√®s bon score, mais attention √† la g√©n√©ralisation en conditions r√©elles.")


def page_eda(df_features):
    header("üìä Exploration des donn√©es", "Comprendre le dataset et ses biais")

    if df_features is None or len(df_features) == 0:
        st.warning("Dataset PlantVillage non charg√©. V√©rifie le chemin du CSV dans load_assets().")
        return

    df = df_features.copy()
    if "nom_plante" not in df.columns or "nom_maladie" not in df.columns:
        st.warning("Le CSV charg√© ne contient pas les colonnes attendues 'nom_plante' et 'nom_maladie'.")
        return

    df_classes = df.assign(
        label=lambda d: d["nom_plante"].astype(str) + "___" + d["nom_maladie"].astype(str)
    )

    n_images = len(df)
    n_species = df["nom_plante"].nunique()
    n_diseases = df["nom_maladie"].nunique()
    n_classes = df_classes["label"].nunique()

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Images", f"{n_images:,}".replace(",", " "))
    c2.metric("Esp√®ces", int(n_species))
    c3.metric("Maladies", int(n_diseases))
    c4.metric("Classes (esp√®ce + maladie)", int(n_classes))

    st.markdown("---")

    st.subheader("Explorer le dataset")
    objective = st.radio(
        "Angle d‚Äôanalyse",
        ["R√©partition des classes", "Sain vs Malade", "Exemples d‚Äôimages"],
        horizontal=True,
    )

    if objective == "R√©partition des classes":
        st.caption("Distribution des classes PlantVillage (esp√®ce + maladie).")

        species_filter = st.multiselect(
            "Filtrer par esp√®ce",
            options=sorted(df["nom_plante"].unique().tolist()),
            default=[],
        )

        df_counts = df_classes.groupby(["nom_plante", "label"]).size().reset_index(name="count")

        if species_filter:
            df_counts = df_counts[df_counts["nom_plante"].isin(species_filter)]

        if df_counts.empty:
            st.info("Aucune donn√©e pour le filtre s√©lectionn√©.")
        else:
            height = min(700, 20 * len(df_counts))
            chart = (
                alt.Chart(df_counts)
                .mark_bar()
                .encode(
                    x=alt.X("count:Q", title="Nombre d'images"),
                    y=alt.Y("label:N", sort="-x", title="Classe"),
                    color=alt.Color("nom_plante:N", title="Esp√®ce"),
                    tooltip=["label", "count"],
                )
                .properties(height=height)
                .interactive()
            )
            st.altair_chart(chart, use_container_width=True)

    elif objective == "Sain vs Malade":
        st.caption("R√©partition des √©tiquettes saines / malades.")

        if "Est_Saine" not in df.columns:
            st.warning("La colonne 'Est_Saine' est absente du CSV.")
        else:
            df_health = df.copy()
            df_health["etat"] = np.where(df_health["Est_Saine"] == 1, "Saine", "Malade")
            counts = df_health["etat"].value_counts().reset_index()
            counts.columns = ["etat", "count"]

            col1, col2 = st.columns(2)
            with col1:
                st.dataframe(counts, use_container_width=True)
            with col2:
                chart = (
                    alt.Chart(counts)
                    .mark_bar()
                    .encode(
                        x=alt.X("etat:N", title="√âtat"),
                        y=alt.Y("count:Q", title="Nombre d'images"),
                        color="etat:N",
                        tooltip=["etat", "count"],
                    )
                )
                st.altair_chart(chart, use_container_width=True)

    else:
        st.caption("√âchantillon d'images pour une classe PlantVillage (jeu r√©duit 5 images par classe).")
        root = PROJECT_ROOT / "dataset/plantvillage/data/plantvillage_5images"
        if not root.exists():
            st.warning("Le r√©pertoire d'images d'exemple n'est pas disponible.")
        else:
            species = st.selectbox("Esp√®ce", sorted(df["nom_plante"].unique().tolist()))
            subset = df[df["nom_plante"] == species]
            maladies = sorted(subset["nom_maladie"].unique().tolist())
            maladie = st.selectbox("Maladie / statut", maladies)

            folder_name = f"{species}___{maladie}"
            class_dir = root / folder_name

            if not class_dir.exists():
                st.warning(f"Dossier d'images introuvable pour {folder_name}.")
            else:
                exts = ["*.jpg", "*.jpeg", "*.png", "*.JPG", "*.JPEG", "*.PNG"]
                image_paths = []
                for pattern in exts:
                    image_paths.extend(class_dir.glob(pattern))
                image_paths = sorted(image_paths)

                if not image_paths:
                    st.warning("Aucune image trouv√©e dans ce dossier.")
                else:
                    max_n = min(len(image_paths), 5)
                    n_show = st.slider("Nombre d'images √† afficher", 1, max_n, max_n)
                    selected = image_paths[:n_show]
                    cols = st.columns(min(5, n_show))
                    for img_path, col in zip(selected, cols):
                        with col:
                            st.image(str(img_path), caption=img_path.name, use_container_width=True)

    st.warning("‚ö†Ô∏è Dataset PlantVillage en conditions contr√¥l√©es (fond uniforme, √©clairage stable) ‚Üí risque de baisse de performance sur photos terrain.")


def page_modeling():
    header("‚öôÔ∏è Mod√©lisation ML vs DL", "Choix m√©thodologiques et r√©sultats")

    objective = st.radio(
        "Objectif",
        ["Objectif 1 ‚Äî Esp√®ce", "Objectif 2 ‚Äî Sant√©", "Objectif 3 ‚Äî Maladie"],
        horizontal=True
    )

    case = st.selectbox(
        "Cas d‚Äôusage (sc√©nario produit)",
        [
            "Cas 1 ‚Äî Identifier l‚Äôesp√®ce",
            "Cas 2 ‚Äî Esp√®ce connue ‚Üí diagnostiquer la maladie",
            "Cas 3 ‚Äî Diagnostic complet"
        ]
    )

    c1, c2, c3 = st.columns(3)
    if objective.startswith("Objectif 1"):
        c1.metric("Type", "Multi-classe")
        c2.metric("Classes", "14 esp√®ces")
        c3.metric("Focus", "Macro-F1 / confusion")
    elif objective.startswith("Objectif 2"):
        c1.metric("Type", "Binaire")
        c2.metric("Classes", "2 (healthy / diseased)")
        c3.metric("Focus", "Recall / F1")
    else:
        c1.metric("Type", "Multi-classe")
        c2.metric("Classes", "20 maladies")
        c3.metric("Risque", "d√©s√©quilibre / confusion")

    st.markdown("---")

    mode = st.radio(
        "Approche",
        ["Machine Learning (features engineering)", "Deep Learning (transfer learning)"],
        horizontal=True
    )

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ML (features)")
        st.caption("Pipeline : features ‚Üí mod√®le (LogReg / ExtraTrees / XGBoost / SVM-RBF).")
        st.progress(0.92)  # visuel
        st.markdown("""
- ‚úÖ Rapide √† entra√Æner
- ‚úÖ Interpr√©table (jusqu‚Äô√† un certain point)
- ‚ö†Ô∏è D√©pend fortement de la qualit√© des features
""")

    with col2:
        st.subheader("DL (CNN / transfert)")
        st.caption("Pipeline : images ‚Üí backbone pr√©-entra√Æn√© ‚Üí fine-tuning.")
        st.progress(0.99)  # visuel
        st.markdown("""
- ‚úÖ Tr√®s performant sur images
- ‚úÖ Moins besoin de features manuelles
- ‚ö†Ô∏è Peut apprendre des biais (fond, conditions studio)
""")

    st.info(f"üìå Cas s√©lectionn√© : **{case}** ‚Ä¢ Approche affich√©e : **{mode}**")
    st.markdown("---")

    st.subheader("R√©sultats ML tabulaire (features PlantVillage)")
    artifacts = load_ml_artifacts()
    metrics = artifacts.get("metrics", {})

    col_a, col_b, col_c = st.columns(3)
    if metrics:
        test_f1 = metrics.get("test_f1_macro")
        test_bal = metrics.get("test_balanced_accuracy")
        cv_f1 = metrics.get("cv_f1_macro_mean")
        if test_f1 is not None:
            col_a.metric("F1 macro (test)", f"{test_f1:.3f}")
        else:
            col_a.metric("F1 macro (test)", "‚Äì")
        if test_bal is not None:
            col_b.metric("Balanced acc. (test)", f"{test_bal:.3f}")
        else:
            col_b.metric("Balanced acc. (test)", "‚Äì")
        if cv_f1 is not None:
            col_c.metric("F1 macro (CV moy.)", f"{cv_f1:.3f}")
        else:
            col_c.metric("F1 macro (CV moy.)", "‚Äì")
    else:
        col_a.metric("F1 macro (test)", "‚Äì")
        col_b.metric("Balanced acc. (test)", "‚Äì")
        col_c.metric("F1 macro (CV moy.)", "‚Äì")

    st.caption("Mod√®le affich√© : XGBoost (meilleur run MLflow sur PlantVillage tabulaire).")

    tab_cm, tab_f1, tab_rep = st.tabs([
        "Matrice de confusion",
        "F1 par classe",
        "Rapport de classification",
    ])

    with tab_cm:
        if artifacts.get("confusion_png"):
            st.image(
                artifacts["confusion_png"],
                caption="Matrice de confusion normalis√©e (PlantVillage)",
                use_container_width=True,
            )
        else:
            st.info("Image de matrice de confusion non trouv√©e dans les artefacts MLflow.")

    with tab_f1:
        if artifacts.get("per_class_f1_png"):
            st.image(
                artifacts["per_class_f1_png"],
                caption="F1-score par classe (PlantVillage)",
                use_container_width=True,
            )
        else:
            st.info("Figure de F1 par classe non trouv√©e dans les artefacts MLflow.")

    with tab_rep:
        report = artifacts.get("classification_report")
        if report:
            st.text(report)
        else:
            st.info("Fichier classification_report.txt non trouv√© dans les artefacts MLflow.")


def page_predict():
    header("ü§ñ D√©mo de pr√©diction", "Upload ‚Üí pr√©diction ‚Üí top-3 ‚Üí d√©cision")

    model = load_xgb_model()
    label_encoder = load_species_label_encoder()

    if model is None or label_encoder is None:
        st.error("Mod√®le XGBoost ou label encoder introuvable. V√©rifie les artefacts MLflow et le CSV.")
        return

    st.subheader("R√©glages (dynamique)")
    threshold = st.slider("Seuil de confiance", 0.0, 1.0, 0.70, 0.01)

    bg = st.selectbox("What-if : fond (d√©mo robustesse)", ["Aucun", "Noir", "Blanc", "Saumon", "Vert"])
    bg_map = {
        "Noir": (0, 0, 0),
        "Blanc": (255, 255, 255),
        "Saumon": (250, 128, 114),
        "Vert": (0, 140, 60),
    }

    st.markdown("---")

    uploaded = st.file_uploader("Uploader une image de feuille", type=["jpg", "jpeg", "png"])
    if not uploaded:
        st.info("Charge une image pour lancer la d√©mo.")
        return

    img = Image.open(uploaded).convert("RGB")

    # Simulation changement de fond (visuel ‚Äúwow‚Äù)
    if bg != "Aucun":
        w, h = img.size
        background = Image.new("RGB", (w, h), bg_map[bg])
        alpha = st.slider("Intensit√© effet fond (d√©mo)", 0.0, 1.0, 0.25, 0.05)
        img_to_show = Image.blend(img, background, alpha=alpha)
    else:
        img_to_show = img

    col1, col2 = st.columns([0.55, 0.45])
    with col1:
        st.image(img_to_show, caption="Image (√©ventuellement modifi√©e)", use_container_width=True)

    with col2:
        st.subheader("R√©sultats")
        st.caption("Mod√®le : XGBoost tabulaire (classification d'esp√®ce √† partir de features).")

        if st.button("Pr√©dire"):
            with st.spinner("Extraction des features (tabulaires)‚Ä¶"):
                X = build_features_from_image(img_to_show)

            try:
                with st.spinner("Inf√©rence mod√®le XGBoost‚Ä¶"):
                    proba = model.predict_proba(X)[0]
                    class_indices = np.argsort(proba)[::-1]
                    classes_encoded = np.asarray(model.classes_).astype(int)
            except Exception as e:
                st.error(f"Erreur pendant l'inf√©rence : {e}")
                return

            k = min(3, len(class_indices))
            idx_topk = class_indices[:k]
            species_ids = classes_encoded[idx_topk]
            labels = label_encoder.inverse_transform(species_ids)
            topk = list(zip(labels, proba[idx_topk]))

            st.markdown("### Top-3 pr√©dictions (esp√®ce)")
            for label, p in topk:
                st.write(f"**{label}** ‚Äî {p:.2f}")
                st.progress(float(p))

            best_label, best_p = topk[0]
            st.markdown("---")
            if best_p < threshold:
                st.warning("Confiance insuffisante ‚Üí demander une autre photo / zoom / segmentation.")
            else:
                st.success(f"D√©cision : **{best_label}** (p={best_p:.2f})")


def page_gradcam():
    header("üîç Interpr√©tabilit√© (Grad-CAM)", "Expliquer pourquoi le mod√®le pr√©dit √ßa")

    st.markdown("""
Ici, tu vas montrer :
- image originale
- heatmap (Grad-CAM)
- commentaire : ‚Äúle mod√®le regarde bien la feuille‚Äù ou ‚Äúbiais fond‚Äù
""")

    show = st.checkbox("Afficher des exemples Grad-CAM", value=False)
    if not show:
        return

    root = PROJECT_ROOT / "reports/gradcam"
    if not root.exists():
        st.info("Mettre des exemples dans `reports/gradcam/<exemple>/original.png` et `reports/gradcam/<exemple>/gradcam.png` (copi√©s depuis ton Drive).")
        return

    example_dirs = [d for d in sorted(root.iterdir()) if d.is_dir()]
    if not example_dirs:
        st.info("Aucun sous-dossier trouv√© dans `reports/gradcam`. Cr√©e par exemple `reports/gradcam/tomate_bien_predite/` avec `original.png` et `gradcam.png`.")
        return

    for ex_dir in example_dirs:
        orig = ex_dir / "original.png"
        heat = ex_dir / "gradcam.png"
        if not (orig.exists() and heat.exists()):
            continue

        st.markdown(f"### Exemple : {ex_dir.name}")
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Image originale**")
            st.image(str(orig), use_container_width=True)
        with col2:
            st.write("**Heatmap Grad-CAM**")
            st.image(str(heat), use_container_width=True)


def page_limits():
    header("‚ö†Ô∏è Limites & perspectives", "Posture r√©aliste et axes d‚Äôam√©lioration")

    st.subheader("Limites")
    st.markdown("""
- Dataset tr√®s ‚Äústudio‚Äù ‚Üí g√©n√©ralisation limit√©e sur photos terrain
- D√©s√©quilibre des classes ‚Üí biais possible
- Fond / √©clairage peuvent influencer la pr√©diction
""")

    st.subheader("Perspectives")
    st.markdown("""
- Ajouter des donn√©es ‚Äúin the wild‚Äù (terrain)
- Segmentation pour isoler la feuille
- Augmentations plus r√©alistes (fonds vari√©s, illumination)
- Tester d‚Äôautres backbones / ViT + validation plus robuste
""")


def page_about():
    header("‚ÑπÔ∏è √Ä propos")
    st.markdown("""
- Projet : Reconnaissance plantes (esp√®ce / sant√© / maladie)
- Stack : Python ‚Ä¢ scikit-learn ‚Ä¢ TensorFlow/Keras ‚Ä¢ Streamlit
- Objectif soutenance : d√©montrer pipeline + choix + limites + d√©mo produit
""")


# -------------------------
# App Router
# -------------------------
def main():
    df_features = load_assets()
    init_state()

    st.sidebar.title("Navigation")
    st.sidebar.toggle("üé¨ Mode soutenance (d√©mo guid√©e)", key="demo_mode")
    st.sidebar.markdown("---")

    pages = [
        "üè† Accueil",
        "üìä Exploration des donn√©es",
        "‚öôÔ∏è Mod√©lisation ML vs DL",
        "ü§ñ D√©mo de pr√©diction",
        "üîç Interpr√©tabilit√© (Grad-CAM)",
        "‚ö†Ô∏è Limites & perspectives",
        "‚ÑπÔ∏è √Ä propos"
    ]

    if st.session_state.demo_mode:
        colA, colB = st.sidebar.columns([0.7, 0.3])
        with colA:
            st.sidebar.write(f"√âtape : **{pages[st.session_state.step]}**")
        with colB:
            if st.sidebar.button("Next ‚û°Ô∏è"):
                st.session_state.step = (st.session_state.step + 1) % len(pages)

        st.sidebar.progress((st.session_state.step + 1) / len(pages))
        page = pages[st.session_state.step]
    else:
        page = st.sidebar.radio("Menu", pages)

    # Routing
    if page == "üè† Accueil":
        page_home()
    elif page == "üìä Exploration des donn√©es":
        page_eda(df_features)
    elif page == "‚öôÔ∏è Mod√©lisation ML vs DL":
        page_modeling()
    elif page == "ü§ñ D√©mo de pr√©diction":
        page_predict()
    elif page == "üîç Interpr√©tabilit√© (Grad-CAM)":
        page_gradcam()
    elif page == "‚ö†Ô∏è Limites & perspectives":
        page_limits()
    else:
        page_about()


if __name__ == "__main__":
    main()
